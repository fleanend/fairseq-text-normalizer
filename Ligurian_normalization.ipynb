{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fleanend/fairseq-text-normalizer/blob/main/Ligurian_normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW5-mp4rH5XM"
      },
      "source": [
        "# Train\n",
        "\n",
        "Download the code repo and install it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rIvaqFLIrHg",
        "outputId": "a17e7372-e138-4fd1-e728-8620f832142b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq-text-normalizer'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 29 (delta 6), reused 22 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (29/29), done.\n",
            "/content/fairseq-text-normalizer\n",
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 33399, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 33399 (delta 0), reused 0 (delta 0), pack-reused 33397\u001b[K\n",
            "Receiving objects: 100% (33399/33399), 23.28 MiB | 30.68 MiB/s, done.\n",
            "Resolving deltas: 100% (24405/24405), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fairseq==0.10.2\n",
            "  Downloading fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (0.29.32)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (1.21.6)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 68.7 MB/s \n",
            "\u001b[?25hCollecting hydra-core\n",
            "  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 75.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (4.64.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (2022.6.2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (1.15.1)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==0.10.2) (4.9.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==0.10.2) (0.8.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==0.10.2) (2.21)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 73.0 MB/s \n",
            "\u001b[?25hCollecting omegaconf~=2.2\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq==0.10.2) (21.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq==0.10.2) (5.10.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf~=2.2->hydra-core->fairseq==0.10.2) (6.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core->fairseq==0.10.2) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core->fairseq==0.10.2) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq==0.10.2) (4.1.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144576 sha256=e475f72e5e0a84d08a2a69e8445eddc26deb4871770b30867f27642de3911fb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, dataclasses, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 colorama-0.4.6 dataclasses-0.6 fairseq-0.10.2 hydra-core-1.2.0 omegaconf-2.2.3 portalocker-2.6.0 sacrebleu-2.3.1\n",
            "Cloning into 'fastwer'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 33 (delta 9), reused 26 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pybind11\n",
            "  Downloading pybind11-2.10.1-py3-none-any.whl (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 29.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.10.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastwer\n",
            "  Downloading fastwer-0.1.3.tar.gz (4.6 kB)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.7/dist-packages (from fastwer) (2.10.1)\n",
            "Building wheels for collected packages: fastwer\n",
            "  Building wheel for fastwer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastwer: filename=fastwer-0.1.3-cp37-cp37m-linux_x86_64.whl size=663369 sha256=70a454631ce35ac3956caeee034f48e0e3577e969805e139b855fa43f1a50cbe\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/b6/93/419e758f0c0176d311602763520bcfdec18107be1f15186fe6\n",
            "Successfully built fastwer\n",
            "Installing collected packages: fastwer\n",
            "Successfully installed fastwer-0.1.3\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/fleanend/fairseq-text-normalizer.git\"\n",
        "%cd fairseq-text-normalizer\n",
        "!sh setup.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "161kLOTtNO31"
      },
      "source": [
        "Download dataset and set it up for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY3sqYXJNToU",
        "outputId": "b456a25a-206e-400c-d57f-1af9487d7c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'normalized_ligurian_corpus'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects:   6% (1/15)\u001b[K\rremote: Counting objects:  13% (2/15)\u001b[K\rremote: Counting objects:  20% (3/15)\u001b[K\rremote: Counting objects:  26% (4/15)\u001b[K\rremote: Counting objects:  33% (5/15)\u001b[K\rremote: Counting objects:  40% (6/15)\u001b[K\rremote: Counting objects:  46% (7/15)\u001b[K\rremote: Counting objects:  53% (8/15)\u001b[K\rremote: Counting objects:  60% (9/15)\u001b[K\rremote: Counting objects:  66% (10/15)\u001b[K\rremote: Counting objects:  73% (11/15)\u001b[K\rremote: Counting objects:  80% (12/15)\u001b[K\rremote: Counting objects:  86% (13/15)\u001b[K\rremote: Counting objects:  93% (14/15)\u001b[K\rremote: Counting objects: 100% (15/15)\u001b[K\rremote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects:   7% (1/13)\u001b[K\rremote: Compressing objects:  15% (2/13)\u001b[K\rremote: Compressing objects:  23% (3/13)\u001b[K\rremote: Compressing objects:  30% (4/13)\u001b[K\rremote: Compressing objects:  38% (5/13)\u001b[K\rremote: Compressing objects:  46% (6/13)\u001b[K\rremote: Compressing objects:  53% (7/13)\u001b[K\rremote: Compressing objects:  61% (8/13)\u001b[K\rremote: Compressing objects:  69% (9/13)\u001b[K\rremote: Compressing objects:  76% (10/13)\u001b[K\rremote: Compressing objects:  84% (11/13)\u001b[K\rremote: Compressing objects:  92% (12/13)\u001b[K\rremote: Compressing objects: 100% (13/13)\u001b[K\rremote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "Unpacking objects:   6% (1/15)   \rUnpacking objects:  13% (2/15)   \rUnpacking objects:  20% (3/15)   \rUnpacking objects:  26% (4/15)   \rUnpacking objects:  33% (5/15)   \rUnpacking objects:  40% (6/15)   \rUnpacking objects:  46% (7/15)   \rUnpacking objects:  53% (8/15)   \rUnpacking objects:  60% (9/15)   \rUnpacking objects:  66% (10/15)   \rUnpacking objects:  73% (11/15)   \rremote: Total 15 (delta 1), reused 15 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects:  80% (12/15)   \rUnpacking objects:  86% (13/15)   \rUnpacking objects:  93% (14/15)   \rUnpacking objects: 100% (15/15)   \rUnpacking objects: 100% (15/15), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ConseggioLigure/normalized_ligurian_corpus.git\n",
        "%cp normalized_ligurian_corpus/monolingual/monolingual.txt data/raw/mono.new\n",
        "%cp normalized_ligurian_corpus/parallel/casaccia.raw data/raw/norm-casaccia.casaccia\n",
        "%cp normalized_ligurian_corpus/parallel/casaccia.norm data/raw/norm-casaccia.norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNbIJ6xXOTVi"
      },
      "source": [
        "Actually train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LEmEZXfIbxE",
        "outputId": "f10f7926-2d03-490b-cb9d-51561ce1af3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 34.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Cloning Moses github repository (for tokenization scripts)...\n",
            "Cloning into 'mosesdecoder'...\n",
            "remote: Enumerating objects: 148097, done.\u001b[K\n",
            "remote: Counting objects: 100% (525/525), done.\u001b[K\n",
            "remote: Compressing objects: 100% (229/229), done.\u001b[K\n",
            "remote: Total 148097 (delta 323), reused 441 (delta 292), pack-reused 147572\u001b[K\n",
            "Receiving objects: 100% (148097/148097), 129.88 MiB | 17.36 MiB/s, done.\n",
            "Resolving deltas: 100% (114349/114349), done.\n",
            "pre-processing data...\n",
            "old new\n",
            "train.tags.old-new.old\n",
            "train.tags.old-new.tok.old\n",
            "\n",
            "train.tags.old-new.new\n",
            "train.tags.old-new.tok.new\n",
            "\n",
            "norm casaccia\n",
            "train.tags.norm-casaccia.norm\n",
            "train.tags.norm-casaccia.tok.norm\n",
            "\n",
            "train.tags.norm-casaccia.casaccia\n",
            "train.tags.norm-casaccia.tok.casaccia\n",
            "\n",
            "pre-processing mono\n",
            "\n",
            "creating train, valid, test...\n",
            "old-new\n",
            "norm-casaccia\n",
            "encoding train/valid/test with learned BPE...\n",
            "len vocab on 79...\n",
            "BPE_TOKENS on 82...\n",
            "learning joint BPE over all.tokenized.old-new/tmp/train.old-new...\n",
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=all.tokenized.old-new/tmp/train.old-new --model_prefix=./sentencepiece_old-new.bpe --vocab_size=82 --character_coverage=1.0 --model_type=bpe\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: all.tokenized.old-new/tmp/train.old-new\n",
            "  input_format: \n",
            "  model_prefix: ./sentencepiece_old-new.bpe\n",
            "  model_type: BPE\n",
            "  vocab_size: 82\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 1\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(181) LOG(INFO) Loading corpus: all.tokenized.old-new/tmp/train.old-new\n",
            "trainer_interface.cc(406) LOG(INFO) Loaded all 1400 sentences\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(427) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(536) LOG(INFO) all chars count=41591\n",
            "trainer_interface.cc(557) LOG(INFO) Alphabet size=79\n",
            "trainer_interface.cc(558) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(590) LOG(INFO) Done! preprocessed 1400 sentences.\n",
            "trainer_interface.cc(596) LOG(INFO) Tokenizing input sentences with whitespace: 1400\n",
            "trainer_interface.cc(607) LOG(INFO) Done! 2365\n",
            "trainer_interface.cc(685) LOG(INFO) Saving model: ./sentencepiece_old-new.bpe.model\n",
            "trainer_interface.cc(697) LOG(INFO) Saving vocabs: ./sentencepiece_old-new.bpe.vocab\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "len vocab on 79...\n",
            "BPE_TOKENS on 82...\n",
            "learning joint BPE over all.tokenized.norm-casaccia/tmp/train.norm-casaccia...\n",
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=all.tokenized.norm-casaccia/tmp/train.norm-casaccia --model_prefix=./sentencepiece_norm-casaccia.bpe --vocab_size=82 --character_coverage=1.0 --model_type=bpe\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: all.tokenized.norm-casaccia/tmp/train.norm-casaccia\n",
            "  input_format: \n",
            "  model_prefix: ./sentencepiece_norm-casaccia.bpe\n",
            "  model_type: BPE\n",
            "  vocab_size: 82\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 1\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(181) LOG(INFO) Loading corpus: all.tokenized.norm-casaccia/tmp/train.norm-casaccia\n",
            "trainer_interface.cc(406) LOG(INFO) Loaded all 1400 sentences\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(427) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(536) LOG(INFO) all chars count=41642\n",
            "trainer_interface.cc(557) LOG(INFO) Alphabet size=79\n",
            "trainer_interface.cc(558) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(590) LOG(INFO) Done! preprocessed 1400 sentences.\n",
            "trainer_interface.cc(596) LOG(INFO) Tokenizing input sentences with whitespace: 1400\n",
            "trainer_interface.cc(607) LOG(INFO) Done! 2286\n",
            "trainer_interface.cc(685) LOG(INFO) Saving model: ./sentencepiece_norm-casaccia.bpe.model\n",
            "trainer_interface.cc(697) LOG(INFO) Saving vocabs: ./sentencepiece_norm-casaccia.bpe.vocab\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "final preprocessing...\n",
            "2022-11-08 08:17:22 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/all.tokenized.old-new', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='old', srcdict=None, target_lang='new', task='translation', tensorboard_logdir=None, testpref='all.tokenized.old-new/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='all.tokenized.old-new/train', user_dir=None, validpref='all.tokenized.old-new/valid', workers=1)\n",
            "2022-11-08 08:17:22 | INFO | fairseq_cli.preprocess | [old] Dictionary: 88 types\n",
            "2022-11-08 08:17:22 | INFO | fairseq_cli.preprocess | [old] all.tokenized.old-new/train.old: 1400 sents, 42991 tokens, 0.0% replaced by <unk>\n",
            "2022-11-08 08:17:22 | INFO | fairseq_cli.preprocess | [old] Dictionary: 88 types\n",
            "2022-11-08 08:17:22 | INFO | fairseq_cli.preprocess | [old] all.tokenized.old-new/valid.old: 200 sents, 6175 tokens, 0.0% replaced by <unk>\n",
            "2022-11-08 08:17:22 | INFO | fairseq_cli.preprocess | [old] Dictionary: 88 types\n",
            "2022-11-08 08:17:22 | INFO | fairseq_cli.preprocess | [old] all.tokenized.old-new/test.old: 200 sents, 6124 tokens, 0.0% replaced by <unk>\n",
            "2022-11-08 08:17:22 | INFO | fairseq_cli.preprocess | [new] Dictionary: 88 types\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-preprocess\", line 8, in <module>\n",
            "    sys.exit(cli_main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 394, in cli_main\n",
            "    main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 286, in main\n",
            "    make_all(args.target_lang, tgt_dict)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 252, in make_all\n",
            "    make_dataset(vocab, args.trainpref, \"train\", lang, num_workers=args.workers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 248, in make_dataset\n",
            "    make_binary_dataset(vocab, input_prefix, output_prefix, lang, num_workers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 181, in make_binary_dataset\n",
            "    100 * sum(replaced.values()) / n_seq_tok[1],\n",
            "ZeroDivisionError: division by zero\n",
            "2022-11-08 08:17:24 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/all.tokenized.norm-casaccia', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='norm', srcdict=None, target_lang='casaccia', task='translation', tensorboard_logdir=None, testpref='all.tokenized.norm-casaccia/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='all.tokenized.norm-casaccia/train', user_dir=None, validpref='all.tokenized.norm-casaccia/valid', workers=1)\n",
            "2022-11-08 08:17:24 | INFO | fairseq_cli.preprocess | [norm] Dictionary: 88 types\n",
            "2022-11-08 08:17:24 | INFO | fairseq_cli.preprocess | [norm] all.tokenized.norm-casaccia/train.norm: 700 sents, 21368 tokens, 0.0% replaced by <unk>\n",
            "2022-11-08 08:17:24 | INFO | fairseq_cli.preprocess | [norm] Dictionary: 88 types\n",
            "2022-11-08 08:17:24 | INFO | fairseq_cli.preprocess | [norm] all.tokenized.norm-casaccia/valid.norm: 100 sents, 3169 tokens, 0.0% replaced by <unk>\n",
            "2022-11-08 08:17:24 | INFO | fairseq_cli.preprocess | [norm] Dictionary: 88 types\n",
            "2022-11-08 08:17:24 | INFO | fairseq_cli.preprocess | [norm] all.tokenized.norm-casaccia/test.norm: 100 sents, 2963 tokens, 0.0% replaced by <unk>\n",
            "2022-11-08 08:17:24 | INFO | fairseq_cli.preprocess | [casaccia] Dictionary: 88 types\n",
            "2022-11-08 08:17:24 | INFO | fairseq_cli.preprocess | [casaccia] all.tokenized.norm-casaccia/train.casaccia: 700 sents, 21674 tokens, 0.0% replaced by <unk>\n",
            "2022-11-08 08:17:24 | INFO | fairseq_cli.preprocess | [casaccia] Dictionary: 88 types\n",
            "2022-11-08 08:17:24 | INFO | fairseq_cli.preprocess | [casaccia] all.tokenized.norm-casaccia/valid.casaccia: 100 sents, 3225 tokens, 0.0% replaced by <unk>\n",
            "2022-11-08 08:17:24 | INFO | fairseq_cli.preprocess | [casaccia] Dictionary: 88 types\n",
            "2022-11-08 08:17:24 | INFO | fairseq_cli.preprocess | [casaccia] all.tokenized.norm-casaccia/test.casaccia: 100 sents, 3006 tokens, 0.0% replaced by <unk>\n",
            "2022-11-08 08:17:24 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/all.tokenized.norm-casaccia\n",
            "2022-11-08 08:17:26 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, batch_size=20, batch_size_valid=20, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/all.tokenized.norm-casaccia', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=256, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=256, decoder_layerdrop=0, decoder_layers=4, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=256, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=256, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=30, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=250, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/fconv', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none')\n",
            "2022-11-08 08:17:26 | INFO | fairseq.tasks.translation | [norm] dictionary: 88 types\n",
            "2022-11-08 08:17:26 | INFO | fairseq.tasks.translation | [casaccia] dictionary: 88 types\n",
            "2022-11-08 08:17:26 | INFO | fairseq.data.data_utils | loaded 100 examples from: data-bin/all.tokenized.norm-casaccia/valid.norm-casaccia.norm\n",
            "2022-11-08 08:17:26 | INFO | fairseq.data.data_utils | loaded 100 examples from: data-bin/all.tokenized.norm-casaccia/valid.norm-casaccia.casaccia\n",
            "2022-11-08 08:17:26 | INFO | fairseq.tasks.translation | data-bin/all.tokenized.norm-casaccia valid norm-casaccia 100 examples\n",
            "2022-11-08 08:17:26 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(88, 256, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(88, 256, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=256, out_features=88, bias=False)\n",
            "  )\n",
            ")\n",
            "2022-11-08 08:17:26 | INFO | fairseq_cli.train | task: translation (TranslationTask)\n",
            "2022-11-08 08:17:26 | INFO | fairseq_cli.train | model: transformer (TransformerModel)\n",
            "2022-11-08 08:17:26 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)\n",
            "2022-11-08 08:17:26 | INFO | fairseq_cli.train | num. model params: 7396352 (num. trained: 7396352)\n",
            "2022-11-08 08:17:29 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
            "2022-11-08 08:17:29 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2022-11-08 08:17:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-11-08 08:17:29 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n",
            "2022-11-08 08:17:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-11-08 08:17:29 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2022-11-08 08:17:29 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 20\n",
            "2022-11-08 08:17:29 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/fconv/checkpoint_last.pt\n",
            "2022-11-08 08:17:29 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2022-11-08 08:17:29 | INFO | fairseq.data.data_utils | loaded 700 examples from: data-bin/all.tokenized.norm-casaccia/train.norm-casaccia.norm\n",
            "2022-11-08 08:17:29 | INFO | fairseq.data.data_utils | loaded 700 examples from: data-bin/all.tokenized.norm-casaccia/train.norm-casaccia.casaccia\n",
            "2022-11-08 08:17:29 | INFO | fairseq.tasks.translation | data-bin/all.tokenized.norm-casaccia train norm-casaccia 700 examples\n",
            "2022-11-08 08:17:29 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16\n",
            "epoch 001:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:17:29 | INFO | fairseq.trainer | begin training epoch 1\n",
            "/usr/local/lib/python3.7/dist-packages/fairseq/utils.py:342: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "epoch 001:  98% 43/44 [00:04<00:00, 20.19it/s]2022-11-08 08:17:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.05it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:17:34 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.102 | nll_loss 8.058 | ppl 266.42 | wps 39051.3 | wpb 537.5 | bsz 16.7 | num_updates 44\n",
            "2022-11-08 08:17:34 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:17:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint1.pt (epoch 1 @ 44 updates, score 8.102) (writing took 0.649671316999985 seconds)\n",
            "2022-11-08 08:17:35 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2022-11-08 08:17:35 | INFO | train | epoch 001 | loss 10.045 | nll_loss 10.019 | ppl 1037.37 | wps 6883.1 | ups 14.02 | wpb 492.6 | bsz 15.9 | num_updates 44 | lr 1.10989e-05 | gnorm 7.825 | clip 100 | train_wall 5 | wall 5\n",
            "epoch 002:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:17:35 | INFO | fairseq.trainer | begin training epoch 2\n",
            "epoch 002:  98% 43/44 [00:02<00:00, 20.14it/s]2022-11-08 08:17:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.42it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:17:37 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 5.764 | nll_loss 5.552 | ppl 46.91 | wps 33501.1 | wpb 537.5 | bsz 16.7 | num_updates 88 | best_loss 5.764\n",
            "2022-11-08 08:17:37 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:17:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint2.pt (epoch 2 @ 88 updates, score 5.764) (writing took 0.7783380680000107 seconds)\n",
            "2022-11-08 08:17:38 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2022-11-08 08:17:38 | INFO | train | epoch 002 | loss 6.965 | nll_loss 6.848 | ppl 115.17 | wps 6492.8 | ups 13.18 | wpb 492.6 | bsz 15.9 | num_updates 88 | lr 2.20978e-05 | gnorm 2.912 | clip 100 | train_wall 2 | wall 9\n",
            "epoch 003:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:17:38 | INFO | fairseq.trainer | begin training epoch 3\n",
            "epoch 003:  98% 43/44 [00:02<00:00, 19.73it/s, loss=8.183, nll_loss=8.094, ppl=273.31, wps=6783, ups=13.82, wpb=491.5, bsz=15.9, num_updates=100, lr=2.50975e-05, gnorm=4.89, clip=100, train_wall=8, wall=10]2022-11-08 08:17:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.02it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:17:41 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 5.137 | nll_loss 4.847 | ppl 28.78 | wps 32274.5 | wpb 537.5 | bsz 16.7 | num_updates 132 | best_loss 5.137\n",
            "2022-11-08 08:17:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:17:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint3.pt (epoch 3 @ 132 updates, score 5.137) (writing took 0.5774473819999741 seconds)\n",
            "2022-11-08 08:17:41 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2022-11-08 08:17:41 | INFO | train | epoch 003 | loss 5.495 | nll_loss 5.249 | ppl 38.02 | wps 6858.7 | ups 13.92 | wpb 492.6 | bsz 15.9 | num_updates 132 | lr 3.30967e-05 | gnorm 1.104 | clip 100 | train_wall 2 | wall 12\n",
            "epoch 004:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:17:41 | INFO | fairseq.trainer | begin training epoch 4\n",
            "epoch 004:  98% 43/44 [00:02<00:00, 20.03it/s]2022-11-08 08:17:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 004 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.42it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:17:44 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.92 | nll_loss 4.587 | ppl 24.04 | wps 37809.8 | wpb 537.5 | bsz 16.7 | num_updates 176 | best_loss 4.92\n",
            "2022-11-08 08:17:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:17:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint4.pt (epoch 4 @ 176 updates, score 4.92) (writing took 0.7535141060000115 seconds)\n",
            "2022-11-08 08:17:45 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2022-11-08 08:17:45 | INFO | train | epoch 004 | loss 5.101 | nll_loss 4.8 | ppl 27.85 | wps 6513.8 | ups 13.22 | wpb 492.6 | bsz 15.9 | num_updates 176 | lr 4.40956e-05 | gnorm 0.825 | clip 100 | train_wall 2 | wall 15\n",
            "epoch 005:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:17:45 | INFO | fairseq.trainer | begin training epoch 5\n",
            "epoch 005:  98% 43/44 [00:02<00:00, 20.80it/s, loss=5.151, nll_loss=4.856, ppl=28.95, wps=7062.2, ups=14.02, wpb=503.8, bsz=15.9, num_updates=200, lr=5.0095e-05, gnorm=0.887, clip=100, train_wall=5, wall=17]2022-11-08 08:17:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 005 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.55it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:17:47 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.725 | nll_loss 4.315 | ppl 19.91 | wps 35789.1 | wpb 537.5 | bsz 16.7 | num_updates 220 | best_loss 4.725\n",
            "2022-11-08 08:17:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:17:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint5.pt (epoch 5 @ 220 updates, score 4.725) (writing took 0.5474712030000148 seconds)\n",
            "2022-11-08 08:17:48 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2022-11-08 08:17:48 | INFO | train | epoch 005 | loss 4.879 | nll_loss 4.533 | ppl 23.16 | wps 7025.4 | ups 14.26 | wpb 492.6 | bsz 15.9 | num_updates 220 | lr 5.50945e-05 | gnorm 0.93 | clip 100 | train_wall 2 | wall 18\n",
            "epoch 006:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:17:48 | INFO | fairseq.trainer | begin training epoch 6\n",
            "epoch 006:  98% 43/44 [00:02<00:00, 18.69it/s]2022-11-08 08:17:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 006 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 006 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 22.82it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:17:50 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.419 | nll_loss 3.947 | ppl 15.43 | wps 30351.6 | wpb 537.5 | bsz 16.7 | num_updates 264 | best_loss 4.419\n",
            "2022-11-08 08:17:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:17:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint6.pt (epoch 6 @ 264 updates, score 4.419) (writing took 0.5996673509999937 seconds)\n",
            "2022-11-08 08:17:51 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n",
            "2022-11-08 08:17:51 | INFO | train | epoch 006 | loss 4.635 | nll_loss 4.241 | ppl 18.91 | wps 6547.1 | ups 13.29 | wpb 492.6 | bsz 15.9 | num_updates 264 | lr 6.60934e-05 | gnorm 1.114 | clip 100 | train_wall 2 | wall 22\n",
            "epoch 007:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:17:51 | INFO | fairseq.trainer | begin training epoch 7\n",
            "epoch 007:  95% 42/44 [00:02<00:00, 18.06it/s, loss=4.564, nll_loss=4.155, ppl=17.82, wps=6736.1, ups=13.87, wpb=485.7, bsz=15.9, num_updates=300, lr=7.50925e-05, gnorm=1.024, clip=100, train_wall=6, wall=24]2022-11-08 08:17:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 007 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 007 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.77it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:17:54 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 4.174 | nll_loss 3.634 | ppl 12.42 | wps 38296.4 | wpb 537.5 | bsz 16.7 | num_updates 308 | best_loss 4.174\n",
            "2022-11-08 08:17:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:17:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint7.pt (epoch 7 @ 308 updates, score 4.174) (writing took 0.6821986379999885 seconds)\n",
            "2022-11-08 08:17:54 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)\n",
            "2022-11-08 08:17:54 | INFO | train | epoch 007 | loss 4.333 | nll_loss 3.879 | ppl 14.72 | wps 6239.4 | ups 12.67 | wpb 492.6 | bsz 15.9 | num_updates 308 | lr 7.70923e-05 | gnorm 0.929 | clip 100 | train_wall 3 | wall 25\n",
            "epoch 008:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:17:54 | INFO | fairseq.trainer | begin training epoch 8\n",
            "epoch 008:  98% 43/44 [00:02<00:00, 19.74it/s]2022-11-08 08:17:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 008 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 008 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.52it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:17:57 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 3.972 | nll_loss 3.395 | ppl 10.52 | wps 36342.6 | wpb 537.5 | bsz 16.7 | num_updates 352 | best_loss 3.972\n",
            "2022-11-08 08:17:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:17:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint8.pt (epoch 8 @ 352 updates, score 3.972) (writing took 0.5664740800000061 seconds)\n",
            "2022-11-08 08:17:58 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)\n",
            "2022-11-08 08:17:58 | INFO | train | epoch 008 | loss 4.079 | nll_loss 3.571 | ppl 11.88 | wps 6609.4 | ups 13.42 | wpb 492.6 | bsz 15.9 | num_updates 352 | lr 8.80912e-05 | gnorm 1.069 | clip 100 | train_wall 2 | wall 28\n",
            "epoch 009:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:17:58 | INFO | fairseq.trainer | begin training epoch 9\n",
            "epoch 009:  98% 43/44 [00:02<00:00, 19.92it/s]2022-11-08 08:18:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 009 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 009 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.01it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:00 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 3.83 | nll_loss 3.23 | ppl 9.38 | wps 33882 | wpb 537.5 | bsz 16.7 | num_updates 396 | best_loss 3.83\n",
            "2022-11-08 08:18:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint9.pt (epoch 9 @ 396 updates, score 3.83) (writing took 0.6213947249999876 seconds)\n",
            "2022-11-08 08:18:01 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)\n",
            "2022-11-08 08:18:01 | INFO | train | epoch 009 | loss 3.917 | nll_loss 3.376 | ppl 10.38 | wps 6581.3 | ups 13.36 | wpb 492.6 | bsz 15.9 | num_updates 396 | lr 9.90901e-05 | gnorm 1.071 | clip 100 | train_wall 2 | wall 32\n",
            "epoch 010:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:01 | INFO | fairseq.trainer | begin training epoch 10\n",
            "epoch 010:  98% 43/44 [00:02<00:00, 19.73it/s, loss=4.005, nll_loss=3.483, ppl=11.18, wps=6087.9, ups=12.24, wpb=497.4, bsz=15.9, num_updates=400, lr=0.00010009, gnorm=1.059, clip=100, train_wall=6, wall=32]2022-11-08 08:18:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 010 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 010 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.87it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:04 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 3.763 | nll_loss 3.144 | ppl 8.84 | wps 31688.1 | wpb 537.5 | bsz 16.7 | num_updates 440 | best_loss 3.763\n",
            "2022-11-08 08:18:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint10.pt (epoch 10 @ 440 updates, score 3.763) (writing took 0.612598687000002 seconds)\n",
            "2022-11-08 08:18:04 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)\n",
            "2022-11-08 08:18:04 | INFO | train | epoch 010 | loss 3.797 | nll_loss 3.231 | ppl 9.39 | wps 6595.8 | ups 13.39 | wpb 492.6 | bsz 15.9 | num_updates 440 | lr 0.000110089 | gnorm 1.136 | clip 100 | train_wall 2 | wall 35\n",
            "epoch 011:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:04 | INFO | fairseq.trainer | begin training epoch 11\n",
            "epoch 011:  93% 41/44 [00:02<00:00, 19.67it/s]2022-11-08 08:18:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 011 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 011 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.47it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:07 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 3.709 | nll_loss 3.076 | ppl 8.43 | wps 39756.1 | wpb 537.5 | bsz 16.7 | num_updates 484 | best_loss 3.709\n",
            "2022-11-08 08:18:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint11.pt (epoch 11 @ 484 updates, score 3.709) (writing took 0.6463695509999923 seconds)\n",
            "2022-11-08 08:18:08 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)\n",
            "2022-11-08 08:18:08 | INFO | train | epoch 011 | loss 3.713 | nll_loss 3.133 | ppl 8.77 | wps 6482.7 | ups 13.16 | wpb 492.6 | bsz 15.9 | num_updates 484 | lr 0.000121088 | gnorm 1.227 | clip 100 | train_wall 2 | wall 38\n",
            "epoch 012:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:08 | INFO | fairseq.trainer | begin training epoch 12\n",
            "epoch 012:  93% 41/44 [00:02<00:00, 19.54it/s, loss=3.73, nll_loss=3.153, ppl=8.89, wps=6620.2, ups=13.64, wpb=485.4, bsz=16, num_updates=500, lr=0.000125087, gnorm=1.195, clip=100, train_wall=6, wall=39]2022-11-08 08:18:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 012 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 012 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.15it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:10 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 3.619 | nll_loss 2.981 | ppl 7.9 | wps 32679.8 | wpb 537.5 | bsz 16.7 | num_updates 528 | best_loss 3.619\n",
            "2022-11-08 08:18:10 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint12.pt (epoch 12 @ 528 updates, score 3.619) (writing took 0.5620683200000087 seconds)\n",
            "2022-11-08 08:18:11 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)\n",
            "2022-11-08 08:18:11 | INFO | train | epoch 012 | loss 3.634 | nll_loss 3.038 | ppl 8.21 | wps 6696.7 | ups 13.59 | wpb 492.6 | bsz 15.9 | num_updates 528 | lr 0.000132087 | gnorm 1.229 | clip 100 | train_wall 2 | wall 42\n",
            "epoch 013:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:11 | INFO | fairseq.trainer | begin training epoch 13\n",
            "epoch 013:  95% 42/44 [00:02<00:00, 19.32it/s]2022-11-08 08:18:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 013 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 013 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.21it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:13 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 3.504 | nll_loss 2.852 | ppl 7.22 | wps 32729.9 | wpb 537.5 | bsz 16.7 | num_updates 572 | best_loss 3.504\n",
            "2022-11-08 08:18:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint13.pt (epoch 13 @ 572 updates, score 3.504) (writing took 0.5541337729999896 seconds)\n",
            "2022-11-08 08:18:14 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)\n",
            "2022-11-08 08:18:14 | INFO | train | epoch 013 | loss 3.535 | nll_loss 2.923 | ppl 7.59 | wps 6773.1 | ups 13.75 | wpb 492.6 | bsz 15.9 | num_updates 572 | lr 0.000143086 | gnorm 1.304 | clip 100 | train_wall 2 | wall 45\n",
            "epoch 014:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:14 | INFO | fairseq.trainer | begin training epoch 14\n",
            "epoch 014:  95% 42/44 [00:02<00:00, 19.08it/s, loss=3.543, nll_loss=2.932, ppl=7.63, wps=7058.5, ups=14.1, wpb=500.7, bsz=15.9, num_updates=600, lr=0.000150085, gnorm=1.37, clip=100, train_wall=5, wall=46]2022-11-08 08:18:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 014 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 014 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.22it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:17 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 3.361 | nll_loss 2.677 | ppl 6.4 | wps 28971.6 | wpb 537.5 | bsz 16.7 | num_updates 616 | best_loss 3.361\n",
            "2022-11-08 08:18:17 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint14.pt (epoch 14 @ 616 updates, score 3.361) (writing took 0.5607582879999882 seconds)\n",
            "2022-11-08 08:18:17 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)\n",
            "2022-11-08 08:18:17 | INFO | train | epoch 014 | loss 3.432 | nll_loss 2.803 | ppl 6.98 | wps 6637.1 | ups 13.47 | wpb 492.6 | bsz 15.9 | num_updates 616 | lr 0.000154085 | gnorm 1.568 | clip 100 | train_wall 2 | wall 48\n",
            "epoch 015:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:17 | INFO | fairseq.trainer | begin training epoch 15\n",
            "epoch 015:  93% 41/44 [00:02<00:00, 18.79it/s]2022-11-08 08:18:20 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 015 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 015 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.54it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:20 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 3.247 | nll_loss 2.547 | ppl 5.84 | wps 30084.3 | wpb 537.5 | bsz 16.7 | num_updates 660 | best_loss 3.247\n",
            "2022-11-08 08:18:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint15.pt (epoch 15 @ 660 updates, score 3.247) (writing took 0.6093724969999812 seconds)\n",
            "2022-11-08 08:18:21 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)\n",
            "2022-11-08 08:18:21 | INFO | train | epoch 015 | loss 3.305 | nll_loss 2.657 | ppl 6.31 | wps 6581.3 | ups 13.36 | wpb 492.6 | bsz 15.9 | num_updates 660 | lr 0.000165083 | gnorm 1.607 | clip 100 | train_wall 2 | wall 51\n",
            "epoch 016:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:21 | INFO | fairseq.trainer | begin training epoch 16\n",
            "epoch 016:  93% 41/44 [00:02<00:00, 19.47it/s, loss=3.256, nll_loss=2.599, ppl=6.06, wps=6711.9, ups=13.89, wpb=483.2, bsz=15.9, num_updates=700, lr=0.000175082, gnorm=1.621, clip=100, train_wall=5, wall=54]2022-11-08 08:18:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 016 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.05it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:23 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 3.105 | nll_loss 2.353 | ppl 5.11 | wps 36199.3 | wpb 537.5 | bsz 16.7 | num_updates 704 | best_loss 3.105\n",
            "2022-11-08 08:18:23 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint16.pt (epoch 16 @ 704 updates, score 3.105) (writing took 0.5822211770000081 seconds)\n",
            "2022-11-08 08:18:24 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)\n",
            "2022-11-08 08:18:24 | INFO | train | epoch 016 | loss 3.181 | nll_loss 2.512 | ppl 5.7 | wps 6604.8 | ups 13.41 | wpb 492.6 | bsz 15.9 | num_updates 704 | lr 0.000176082 | gnorm 1.671 | clip 100 | train_wall 2 | wall 55\n",
            "epoch 017:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:24 | INFO | fairseq.trainer | begin training epoch 17\n",
            "epoch 017:  98% 43/44 [00:02<00:00, 19.92it/s]2022-11-08 08:18:26 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 017 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.24it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:27 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 2.95 | nll_loss 2.174 | ppl 4.51 | wps 35970.9 | wpb 537.5 | bsz 16.7 | num_updates 748 | best_loss 2.95\n",
            "2022-11-08 08:18:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint17.pt (epoch 17 @ 748 updates, score 2.95) (writing took 0.5541515019999963 seconds)\n",
            "2022-11-08 08:18:27 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)\n",
            "2022-11-08 08:18:27 | INFO | train | epoch 017 | loss 3.069 | nll_loss 2.38 | ppl 5.2 | wps 6674.6 | ups 13.55 | wpb 492.6 | bsz 15.9 | num_updates 748 | lr 0.000187081 | gnorm 1.786 | clip 100 | train_wall 2 | wall 58\n",
            "epoch 018:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:27 | INFO | fairseq.trainer | begin training epoch 18\n",
            "epoch 018:  98% 43/44 [00:02<00:00, 19.38it/s]2022-11-08 08:18:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 018 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.15it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:30 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 2.921 | nll_loss 2.135 | ppl 4.39 | wps 41587.1 | wpb 537.5 | bsz 16.7 | num_updates 792 | best_loss 2.921\n",
            "2022-11-08 08:18:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint18.pt (epoch 18 @ 792 updates, score 2.921) (writing took 0.6153481879999845 seconds)\n",
            "2022-11-08 08:18:30 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)\n",
            "2022-11-08 08:18:30 | INFO | train | epoch 018 | loss 2.966 | nll_loss 2.259 | ppl 4.79 | wps 6560.1 | ups 13.32 | wpb 492.6 | bsz 15.9 | num_updates 792 | lr 0.00019808 | gnorm 1.94 | clip 100 | train_wall 2 | wall 61\n",
            "epoch 019:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:30 | INFO | fairseq.trainer | begin training epoch 19\n",
            "epoch 019:  98% 43/44 [00:02<00:00, 19.57it/s, loss=3.014, nll_loss=2.314, ppl=4.97, wps=6094.3, ups=12.43, wpb=490.4, bsz=15.9, num_updates=800, lr=0.00020008, gnorm=1.867, clip=100, train_wall=6, wall=62]2022-11-08 08:18:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 019 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.12it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:33 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 2.795 | nll_loss 1.965 | ppl 3.9 | wps 34406.3 | wpb 537.5 | bsz 16.7 | num_updates 836 | best_loss 2.795\n",
            "2022-11-08 08:18:33 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint19.pt (epoch 19 @ 836 updates, score 2.795) (writing took 0.5562909949999835 seconds)\n",
            "2022-11-08 08:18:34 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)\n",
            "2022-11-08 08:18:34 | INFO | train | epoch 019 | loss 2.86 | nll_loss 2.13 | ppl 4.38 | wps 6819.4 | ups 13.84 | wpb 492.6 | bsz 15.9 | num_updates 836 | lr 0.000209079 | gnorm 1.905 | clip 100 | train_wall 2 | wall 64\n",
            "epoch 020:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:34 | INFO | fairseq.trainer | begin training epoch 20\n",
            "epoch 020:  93% 41/44 [00:02<00:00, 19.40it/s]2022-11-08 08:18:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 020 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.86it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:36 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 2.741 | nll_loss 1.9 | ppl 3.73 | wps 34002 | wpb 537.5 | bsz 16.7 | num_updates 880 | best_loss 2.741\n",
            "2022-11-08 08:18:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint20.pt (epoch 20 @ 880 updates, score 2.741) (writing took 0.5637482159999934 seconds)\n",
            "2022-11-08 08:18:37 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)\n",
            "2022-11-08 08:18:37 | INFO | train | epoch 020 | loss 2.739 | nll_loss 1.987 | ppl 3.97 | wps 6707 | ups 13.62 | wpb 492.6 | bsz 15.9 | num_updates 880 | lr 0.000220078 | gnorm 1.91 | clip 100 | train_wall 2 | wall 68\n",
            "epoch 021:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:37 | INFO | fairseq.trainer | begin training epoch 21\n",
            "epoch 021:  93% 41/44 [00:02<00:00, 19.65it/s, loss=2.761, nll_loss=2.014, ppl=4.04, wps=6951.1, ups=14.11, wpb=492.5, bsz=15.9, num_updates=900, lr=0.000225077, gnorm=1.871, clip=100, train_wall=5, wall=69]2022-11-08 08:18:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 021 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 021 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.83it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:39 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 2.7 | nll_loss 1.831 | ppl 3.56 | wps 38613.3 | wpb 537.5 | bsz 16.7 | num_updates 924 | best_loss 2.7\n",
            "2022-11-08 08:18:39 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint21.pt (epoch 21 @ 924 updates, score 2.7) (writing took 0.5511471929999914 seconds)\n",
            "2022-11-08 08:18:40 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)\n",
            "2022-11-08 08:18:40 | INFO | train | epoch 021 | loss 2.62 | nll_loss 1.847 | ppl 3.6 | wps 6797.6 | ups 13.8 | wpb 492.6 | bsz 15.9 | num_updates 924 | lr 0.000231077 | gnorm 1.806 | clip 100 | train_wall 2 | wall 71\n",
            "epoch 022:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:40 | INFO | fairseq.trainer | begin training epoch 22\n",
            "epoch 022:  93% 41/44 [00:02<00:00, 19.44it/s]2022-11-08 08:18:43 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 022 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 022 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.01it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:43 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 2.535 | nll_loss 1.651 | ppl 3.14 | wps 38446.8 | wpb 537.5 | bsz 16.7 | num_updates 968 | best_loss 2.535\n",
            "2022-11-08 08:18:43 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint22.pt (epoch 22 @ 968 updates, score 2.535) (writing took 0.623970522999997 seconds)\n",
            "2022-11-08 08:18:43 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)\n",
            "2022-11-08 08:18:43 | INFO | train | epoch 022 | loss 2.553 | nll_loss 1.765 | ppl 3.4 | wps 6536.9 | ups 13.27 | wpb 492.6 | bsz 15.9 | num_updates 968 | lr 0.000242076 | gnorm 1.854 | clip 100 | train_wall 2 | wall 74\n",
            "epoch 023:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:43 | INFO | fairseq.trainer | begin training epoch 23\n",
            "epoch 023:  98% 43/44 [00:02<00:00, 19.91it/s, loss=2.547, nll_loss=1.759, ppl=3.39, wps=7039.7, ups=13.96, wpb=504.1, bsz=15.9, num_updates=1000, lr=0.000250075, gnorm=1.826, clip=100, train_wall=5, wall=76]2022-11-08 08:18:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 023 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 023 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.14it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:46 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 2.454 | nll_loss 1.541 | ppl 2.91 | wps 36287.2 | wpb 537.5 | bsz 16.7 | num_updates 1012 | best_loss 2.454\n",
            "2022-11-08 08:18:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint23.pt (epoch 23 @ 1012 updates, score 2.454) (writing took 0.5462663879999923 seconds)\n",
            "2022-11-08 08:18:47 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)\n",
            "2022-11-08 08:18:47 | INFO | train | epoch 023 | loss 2.461 | nll_loss 1.659 | ppl 3.16 | wps 6790.8 | ups 13.79 | wpb 492.6 | bsz 15.9 | num_updates 1012 | lr 0.000253075 | gnorm 1.859 | clip 100 | train_wall 2 | wall 77\n",
            "epoch 024:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:47 | INFO | fairseq.trainer | begin training epoch 24\n",
            "epoch 024:  98% 43/44 [00:02<00:00, 19.87it/s]2022-11-08 08:18:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 024 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 024 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.12it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:49 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 2.399 | nll_loss 1.472 | ppl 2.77 | wps 33537.6 | wpb 537.5 | bsz 16.7 | num_updates 1056 | best_loss 2.399\n",
            "2022-11-08 08:18:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint24.pt (epoch 24 @ 1056 updates, score 2.399) (writing took 0.5774980150000033 seconds)\n",
            "2022-11-08 08:18:50 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)\n",
            "2022-11-08 08:18:50 | INFO | train | epoch 024 | loss 2.37 | nll_loss 1.551 | ppl 2.93 | wps 6822.3 | ups 13.85 | wpb 492.6 | bsz 15.9 | num_updates 1056 | lr 0.000264074 | gnorm 1.795 | clip 100 | train_wall 2 | wall 80\n",
            "epoch 025:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:50 | INFO | fairseq.trainer | begin training epoch 25\n",
            "epoch 025:  93% 41/44 [00:02<00:00, 18.52it/s]2022-11-08 08:18:52 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 025 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 025 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.71it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:52 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 2.329 | nll_loss 1.38 | ppl 2.6 | wps 28553.4 | wpb 537.5 | bsz 16.7 | num_updates 1100 | best_loss 2.329\n",
            "2022-11-08 08:18:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint25.pt (epoch 25 @ 1100 updates, score 2.329) (writing took 0.5604845170000203 seconds)\n",
            "2022-11-08 08:18:53 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)\n",
            "2022-11-08 08:18:53 | INFO | train | epoch 025 | loss 2.293 | nll_loss 1.458 | ppl 2.75 | wps 6816.7 | ups 13.84 | wpb 492.6 | bsz 15.9 | num_updates 1100 | lr 0.000275072 | gnorm 1.674 | clip 100 | train_wall 2 | wall 84\n",
            "epoch 026:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:53 | INFO | fairseq.trainer | begin training epoch 26\n",
            "epoch 026:  95% 42/44 [00:02<00:00, 19.87it/s]2022-11-08 08:18:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 026 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 026 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.53it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:55 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 2.318 | nll_loss 1.37 | ppl 2.58 | wps 31496.1 | wpb 537.5 | bsz 16.7 | num_updates 1144 | best_loss 2.318\n",
            "2022-11-08 08:18:55 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint26.pt (epoch 26 @ 1144 updates, score 2.318) (writing took 0.5875039249999929 seconds)\n",
            "2022-11-08 08:18:56 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)\n",
            "2022-11-08 08:18:56 | INFO | train | epoch 026 | loss 2.215 | nll_loss 1.366 | ppl 2.58 | wps 6836.7 | ups 13.88 | wpb 492.6 | bsz 15.9 | num_updates 1144 | lr 0.000286071 | gnorm 1.683 | clip 100 | train_wall 2 | wall 87\n",
            "epoch 027:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:56 | INFO | fairseq.trainer | begin training epoch 27\n",
            "epoch 027:  98% 43/44 [00:02<00:00, 19.77it/s]2022-11-08 08:18:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 027 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 027 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.92it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:18:59 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 2.243 | nll_loss 1.297 | ppl 2.46 | wps 35496.6 | wpb 537.5 | bsz 16.7 | num_updates 1188 | best_loss 2.243\n",
            "2022-11-08 08:18:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:18:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint27.pt (epoch 27 @ 1188 updates, score 2.243) (writing took 0.5491349410000055 seconds)\n",
            "2022-11-08 08:18:59 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)\n",
            "2022-11-08 08:18:59 | INFO | train | epoch 027 | loss 2.179 | nll_loss 1.324 | ppl 2.5 | wps 6792.7 | ups 13.79 | wpb 492.6 | bsz 15.9 | num_updates 1188 | lr 0.00029707 | gnorm 1.716 | clip 100 | train_wall 2 | wall 90\n",
            "epoch 028:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:18:59 | INFO | fairseq.trainer | begin training epoch 28\n",
            "epoch 028:  95% 42/44 [00:02<00:00, 19.19it/s, loss=2.19, nll_loss=1.337, ppl=2.53, wps=6304.1, ups=12.72, wpb=495.7, bsz=15.9, num_updates=1200, lr=0.00030007, gnorm=1.694, clip=100, train_wall=5, wall=91]2022-11-08 08:19:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 028 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 028 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.57it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:02 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 2.139 | nll_loss 1.17 | ppl 2.25 | wps 33439.4 | wpb 537.5 | bsz 16.7 | num_updates 1232 | best_loss 2.139\n",
            "2022-11-08 08:19:02 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint28.pt (epoch 28 @ 1232 updates, score 2.139) (writing took 0.9515841119999777 seconds)\n",
            "2022-11-08 08:19:03 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)\n",
            "2022-11-08 08:19:03 | INFO | train | epoch 028 | loss 2.132 | nll_loss 1.27 | ppl 2.41 | wps 6014.1 | ups 12.21 | wpb 492.6 | bsz 15.9 | num_updates 1232 | lr 0.000308069 | gnorm 1.695 | clip 100 | train_wall 2 | wall 94\n",
            "epoch 029:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:03 | INFO | fairseq.trainer | begin training epoch 29\n",
            "epoch 029:  95% 42/44 [00:02<00:00, 19.14it/s]2022-11-08 08:19:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 029 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 029 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.79it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:06 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 2.217 | nll_loss 1.248 | ppl 2.38 | wps 30279.2 | wpb 537.5 | bsz 16.7 | num_updates 1276 | best_loss 2.139\n",
            "2022-11-08 08:19:06 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint29.pt (epoch 29 @ 1276 updates, score 2.217) (writing took 0.40971977899999956 seconds)\n",
            "2022-11-08 08:19:06 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)\n",
            "2022-11-08 08:19:06 | INFO | train | epoch 029 | loss 2.067 | nll_loss 1.194 | ppl 2.29 | wps 7010 | ups 14.23 | wpb 492.6 | bsz 15.9 | num_updates 1276 | lr 0.000319068 | gnorm 1.565 | clip 100 | train_wall 2 | wall 97\n",
            "epoch 030:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:06 | INFO | fairseq.trainer | begin training epoch 30\n",
            "epoch 030:  95% 42/44 [00:02<00:00, 19.07it/s, loss=2.055, nll_loss=1.181, ppl=2.27, wps=6494.6, ups=13.68, wpb=474.6, bsz=15.9, num_updates=1300, lr=0.000325067, gnorm=1.608, clip=100, train_wall=5, wall=98]2022-11-08 08:19:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 030 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 030 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.34it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:09 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 2.124 | nll_loss 1.156 | ppl 2.23 | wps 36385 | wpb 537.5 | bsz 16.7 | num_updates 1320 | best_loss 2.124\n",
            "2022-11-08 08:19:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint30.pt (epoch 30 @ 1320 updates, score 2.124) (writing took 0.5581030150000288 seconds)\n",
            "2022-11-08 08:19:09 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)\n",
            "2022-11-08 08:19:09 | INFO | train | epoch 030 | loss 2.024 | nll_loss 1.144 | ppl 2.21 | wps 6825.5 | ups 13.86 | wpb 492.6 | bsz 15.9 | num_updates 1320 | lr 0.000330067 | gnorm 1.526 | clip 100 | train_wall 2 | wall 100\n",
            "epoch 031:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:09 | INFO | fairseq.trainer | begin training epoch 31\n",
            "epoch 031:  98% 43/44 [00:02<00:00, 19.61it/s]2022-11-08 08:19:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 031 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 031 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.74it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:12 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 2.12 | nll_loss 1.129 | ppl 2.19 | wps 35608.7 | wpb 537.5 | bsz 16.7 | num_updates 1364 | best_loss 2.12\n",
            "2022-11-08 08:19:12 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint31.pt (epoch 31 @ 1364 updates, score 2.12) (writing took 0.5781106370000089 seconds)\n",
            "2022-11-08 08:19:12 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)\n",
            "2022-11-08 08:19:12 | INFO | train | epoch 031 | loss 1.976 | nll_loss 1.091 | ppl 2.13 | wps 6784.1 | ups 13.77 | wpb 492.6 | bsz 15.9 | num_updates 1364 | lr 0.000341066 | gnorm 1.593 | clip 100 | train_wall 2 | wall 103\n",
            "epoch 032:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:12 | INFO | fairseq.trainer | begin training epoch 32\n",
            "epoch 032:  93% 41/44 [00:02<00:00, 18.03it/s, loss=2.007, nll_loss=1.127, ppl=2.18, wps=7258.3, ups=14.04, wpb=517.1, bsz=15.9, num_updates=1400, lr=0.000350065, gnorm=1.523, clip=100, train_wall=5, wall=105]2022-11-08 08:19:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 032 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 032 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 15.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:15 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 2.105 | nll_loss 1.111 | ppl 2.16 | wps 23471.2 | wpb 537.5 | bsz 16.7 | num_updates 1408 | best_loss 2.105\n",
            "2022-11-08 08:19:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint32.pt (epoch 32 @ 1408 updates, score 2.105) (writing took 0.6486478390000343 seconds)\n",
            "2022-11-08 08:19:16 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)\n",
            "2022-11-08 08:19:16 | INFO | train | epoch 032 | loss 1.933 | nll_loss 1.042 | ppl 2.06 | wps 6379.2 | ups 12.95 | wpb 492.6 | bsz 15.9 | num_updates 1408 | lr 0.000352065 | gnorm 1.463 | clip 100 | train_wall 2 | wall 106\n",
            "epoch 033:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:16 | INFO | fairseq.trainer | begin training epoch 33\n",
            "epoch 033:  93% 41/44 [00:02<00:00, 19.27it/s]2022-11-08 08:19:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 033 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 033 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.76it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:18 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 2.022 | nll_loss 1.028 | ppl 2.04 | wps 30819.5 | wpb 537.5 | bsz 16.7 | num_updates 1452 | best_loss 2.022\n",
            "2022-11-08 08:19:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint33.pt (epoch 33 @ 1452 updates, score 2.022) (writing took 0.6019890420000138 seconds)\n",
            "2022-11-08 08:19:19 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)\n",
            "2022-11-08 08:19:19 | INFO | train | epoch 033 | loss 1.917 | nll_loss 1.022 | ppl 2.03 | wps 6695.6 | ups 13.59 | wpb 492.6 | bsz 15.9 | num_updates 1452 | lr 0.000363064 | gnorm 1.47 | clip 100 | train_wall 2 | wall 110\n",
            "epoch 034:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:19 | INFO | fairseq.trainer | begin training epoch 34\n",
            "epoch 034:  95% 42/44 [00:02<00:00, 19.71it/s]2022-11-08 08:19:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 034 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 034 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.50it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:22 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 1.98 | nll_loss 0.99 | ppl 1.99 | wps 33764.6 | wpb 537.5 | bsz 16.7 | num_updates 1496 | best_loss 1.98\n",
            "2022-11-08 08:19:22 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint34.pt (epoch 34 @ 1496 updates, score 1.98) (writing took 0.550633892999997 seconds)\n",
            "2022-11-08 08:19:22 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)\n",
            "2022-11-08 08:19:22 | INFO | train | epoch 034 | loss 1.874 | nll_loss 0.974 | ppl 1.96 | wps 6826.2 | ups 13.86 | wpb 492.6 | bsz 15.9 | num_updates 1496 | lr 0.000374063 | gnorm 1.428 | clip 100 | train_wall 2 | wall 113\n",
            "epoch 035:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:22 | INFO | fairseq.trainer | begin training epoch 35\n",
            "epoch 035:  95% 42/44 [00:02<00:00, 19.30it/s, loss=1.877, nll_loss=0.976, ppl=1.97, wps=6058.4, ups=12.48, wpb=485.6, bsz=15.9, num_updates=1500, lr=0.000375062, gnorm=1.451, clip=100, train_wall=5, wall=113]2022-11-08 08:19:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 035 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 035 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.11it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:25 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 2.045 | nll_loss 1.069 | ppl 2.1 | wps 29984.2 | wpb 537.5 | bsz 16.7 | num_updates 1540 | best_loss 1.98\n",
            "2022-11-08 08:19:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint35.pt (epoch 35 @ 1540 updates, score 2.045) (writing took 0.4164753349999728 seconds)\n",
            "2022-11-08 08:19:25 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)\n",
            "2022-11-08 08:19:25 | INFO | train | epoch 035 | loss 1.877 | nll_loss 0.98 | ppl 1.97 | wps 6994.4 | ups 14.2 | wpb 492.6 | bsz 15.9 | num_updates 1540 | lr 0.000385061 | gnorm 1.47 | clip 100 | train_wall 2 | wall 116\n",
            "epoch 036:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:25 | INFO | fairseq.trainer | begin training epoch 36\n",
            "epoch 036:  93% 41/44 [00:02<00:00, 19.70it/s]2022-11-08 08:19:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 036 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 036 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.57it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:28 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 1.986 | nll_loss 0.983 | ppl 1.98 | wps 33313.2 | wpb 537.5 | bsz 16.7 | num_updates 1584 | best_loss 1.98\n",
            "2022-11-08 08:19:28 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint36.pt (epoch 36 @ 1584 updates, score 1.986) (writing took 0.41063165399998525 seconds)\n",
            "2022-11-08 08:19:28 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)\n",
            "2022-11-08 08:19:28 | INFO | train | epoch 036 | loss 1.81 | nll_loss 0.902 | ppl 1.87 | wps 7196.6 | ups 14.61 | wpb 492.6 | bsz 15.9 | num_updates 1584 | lr 0.00039606 | gnorm 1.334 | clip 100 | train_wall 2 | wall 119\n",
            "epoch 037:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:28 | INFO | fairseq.trainer | begin training epoch 37\n",
            "epoch 037:  95% 42/44 [00:02<00:00, 19.42it/s, loss=1.84, nll_loss=0.938, ppl=1.92, wps=7316.4, ups=14.83, wpb=493.4, bsz=15.9, num_updates=1600, lr=0.00040006, gnorm=1.387, clip=100, train_wall=5, wall=120]2022-11-08 08:19:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 037 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 037 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.91it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:31 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 1.931 | nll_loss 0.931 | ppl 1.91 | wps 37567.8 | wpb 537.5 | bsz 16.7 | num_updates 1628 | best_loss 1.931\n",
            "2022-11-08 08:19:31 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint37.pt (epoch 37 @ 1628 updates, score 1.931) (writing took 0.602904169999988 seconds)\n",
            "2022-11-08 08:19:31 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)\n",
            "2022-11-08 08:19:31 | INFO | train | epoch 037 | loss 1.802 | nll_loss 0.893 | ppl 1.86 | wps 6715.3 | ups 13.63 | wpb 492.6 | bsz 15.9 | num_updates 1628 | lr 0.000407059 | gnorm 1.398 | clip 100 | train_wall 2 | wall 122\n",
            "epoch 038:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:31 | INFO | fairseq.trainer | begin training epoch 38\n",
            "epoch 038:  95% 42/44 [00:02<00:00, 19.89it/s]2022-11-08 08:19:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 038 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 038 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.68it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:34 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 1.919 | nll_loss 0.911 | ppl 1.88 | wps 31961.6 | wpb 537.5 | bsz 16.7 | num_updates 1672 | best_loss 1.919\n",
            "2022-11-08 08:19:34 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint38.pt (epoch 38 @ 1672 updates, score 1.919) (writing took 0.5957214759999943 seconds)\n",
            "2022-11-08 08:19:35 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)\n",
            "2022-11-08 08:19:35 | INFO | train | epoch 038 | loss 1.775 | nll_loss 0.866 | ppl 1.82 | wps 6682.7 | ups 13.57 | wpb 492.6 | bsz 15.9 | num_updates 1672 | lr 0.000418058 | gnorm 1.281 | clip 100 | train_wall 2 | wall 125\n",
            "epoch 039:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:35 | INFO | fairseq.trainer | begin training epoch 39\n",
            "epoch 039:  93% 41/44 [00:02<00:00, 20.19it/s, loss=1.779, nll_loss=0.867, ppl=1.82, wps=6881.8, ups=14, wpb=491.6, bsz=15.9, num_updates=1700, lr=0.000425057, gnorm=1.363, clip=100, train_wall=5, wall=127]2022-11-08 08:19:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 039 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 039 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.91it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:37 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 1.938 | nll_loss 0.95 | ppl 1.93 | wps 36441.5 | wpb 537.5 | bsz 16.7 | num_updates 1716 | best_loss 1.919\n",
            "2022-11-08 08:19:37 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint39.pt (epoch 39 @ 1716 updates, score 1.938) (writing took 0.417247911000004 seconds)\n",
            "2022-11-08 08:19:38 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)\n",
            "2022-11-08 08:19:38 | INFO | train | epoch 039 | loss 1.785 | nll_loss 0.875 | ppl 1.83 | wps 7162.1 | ups 14.54 | wpb 492.6 | bsz 15.9 | num_updates 1716 | lr 0.000429057 | gnorm 1.414 | clip 100 | train_wall 2 | wall 128\n",
            "epoch 040:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:38 | INFO | fairseq.trainer | begin training epoch 40\n",
            "epoch 040:  93% 41/44 [00:02<00:00, 19.33it/s]2022-11-08 08:19:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 040 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 040 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.82it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:40 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 1.915 | nll_loss 0.919 | ppl 1.89 | wps 30434.6 | wpb 537.5 | bsz 16.7 | num_updates 1760 | best_loss 1.915\n",
            "2022-11-08 08:19:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint40.pt (epoch 40 @ 1760 updates, score 1.915) (writing took 0.5759759589999476 seconds)\n",
            "2022-11-08 08:19:41 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)\n",
            "2022-11-08 08:19:41 | INFO | train | epoch 040 | loss 1.717 | nll_loss 0.803 | ppl 1.74 | wps 6531.7 | ups 13.26 | wpb 492.6 | bsz 15.9 | num_updates 1760 | lr 0.000440056 | gnorm 1.194 | clip 100 | train_wall 2 | wall 132\n",
            "epoch 041:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:41 | INFO | fairseq.trainer | begin training epoch 41\n",
            "epoch 041:  93% 41/44 [00:02<00:00, 19.13it/s, loss=1.744, nll_loss=0.831, ppl=1.78, wps=7048.2, ups=14.38, wpb=490.3, bsz=15.9, num_updates=1800, lr=0.000450055, gnorm=1.269, clip=100, train_wall=5, wall=134]2022-11-08 08:19:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 041 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 041 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.79it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:44 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 1.847 | nll_loss 0.845 | ppl 1.8 | wps 31600.7 | wpb 537.5 | bsz 16.7 | num_updates 1804 | best_loss 1.847\n",
            "2022-11-08 08:19:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint41.pt (epoch 41 @ 1804 updates, score 1.847) (writing took 0.5824328790000095 seconds)\n",
            "2022-11-08 08:19:44 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)\n",
            "2022-11-08 08:19:44 | INFO | train | epoch 041 | loss 1.739 | nll_loss 0.823 | ppl 1.77 | wps 6733.6 | ups 13.67 | wpb 492.6 | bsz 15.9 | num_updates 1804 | lr 0.000451055 | gnorm 1.29 | clip 100 | train_wall 2 | wall 135\n",
            "epoch 042:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:44 | INFO | fairseq.trainer | begin training epoch 42\n",
            "epoch 042:  95% 42/44 [00:02<00:00, 19.61it/s]2022-11-08 08:19:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 042 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 042 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.19it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:47 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 1.88 | nll_loss 0.891 | ppl 1.85 | wps 37502.2 | wpb 537.5 | bsz 16.7 | num_updates 1848 | best_loss 1.847\n",
            "2022-11-08 08:19:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint42.pt (epoch 42 @ 1848 updates, score 1.88) (writing took 0.4101539640000169 seconds)\n",
            "2022-11-08 08:19:47 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)\n",
            "2022-11-08 08:19:47 | INFO | train | epoch 042 | loss 1.672 | nll_loss 0.752 | ppl 1.68 | wps 7115.5 | ups 14.45 | wpb 492.6 | bsz 15.9 | num_updates 1848 | lr 0.000462054 | gnorm 1.178 | clip 100 | train_wall 2 | wall 138\n",
            "epoch 043:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:47 | INFO | fairseq.trainer | begin training epoch 43\n",
            "epoch 043:  95% 42/44 [00:02<00:00, 18.95it/s]2022-11-08 08:19:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 043 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 043 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.20it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:50 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 1.857 | nll_loss 0.862 | ppl 1.82 | wps 35911 | wpb 537.5 | bsz 16.7 | num_updates 1892 | best_loss 1.847\n",
            "2022-11-08 08:19:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint43.pt (epoch 43 @ 1892 updates, score 1.857) (writing took 0.3742895909999788 seconds)\n",
            "2022-11-08 08:19:50 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)\n",
            "2022-11-08 08:19:50 | INFO | train | epoch 043 | loss 1.692 | nll_loss 0.774 | ppl 1.71 | wps 7202 | ups 14.62 | wpb 492.6 | bsz 15.9 | num_updates 1892 | lr 0.000473053 | gnorm 1.229 | clip 100 | train_wall 2 | wall 141\n",
            "epoch 044:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:50 | INFO | fairseq.trainer | begin training epoch 44\n",
            "epoch 044:  98% 43/44 [00:02<00:00, 19.58it/s, loss=1.679, nll_loss=0.759, ppl=1.69, wps=6474.1, ups=13.19, wpb=490.8, bsz=15.9, num_updates=1900, lr=0.000475052, gnorm=1.202, clip=100, train_wall=5, wall=142]2022-11-08 08:19:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 044 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 044 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.07it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:53 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 1.878 | nll_loss 0.879 | ppl 1.84 | wps 32335.1 | wpb 537.5 | bsz 16.7 | num_updates 1936 | best_loss 1.847\n",
            "2022-11-08 08:19:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint44.pt (epoch 44 @ 1936 updates, score 1.878) (writing took 0.43248922100002574 seconds)\n",
            "2022-11-08 08:19:53 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)\n",
            "2022-11-08 08:19:53 | INFO | train | epoch 044 | loss 1.652 | nll_loss 0.728 | ppl 1.66 | wps 7007.3 | ups 14.23 | wpb 492.6 | bsz 15.9 | num_updates 1936 | lr 0.000484052 | gnorm 1.147 | clip 100 | train_wall 2 | wall 144\n",
            "epoch 045:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:53 | INFO | fairseq.trainer | begin training epoch 45\n",
            "epoch 045:  98% 43/44 [00:02<00:00, 19.69it/s]2022-11-08 08:19:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 045 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 045 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.94it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:56 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 1.868 | nll_loss 0.865 | ppl 1.82 | wps 31673.3 | wpb 537.5 | bsz 16.7 | num_updates 1980 | best_loss 1.847\n",
            "2022-11-08 08:19:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:19:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint45.pt (epoch 45 @ 1980 updates, score 1.868) (writing took 0.387529561000008 seconds)\n",
            "2022-11-08 08:19:56 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)\n",
            "2022-11-08 08:19:56 | INFO | train | epoch 045 | loss 1.644 | nll_loss 0.721 | ppl 1.65 | wps 7173.2 | ups 14.56 | wpb 492.6 | bsz 15.9 | num_updates 1980 | lr 0.00049505 | gnorm 1.124 | clip 100 | train_wall 2 | wall 147\n",
            "epoch 046:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:19:56 | INFO | fairseq.trainer | begin training epoch 46\n",
            "epoch 046:  95% 42/44 [00:02<00:00, 19.14it/s, loss=1.626, nll_loss=0.699, ppl=1.62, wps=7222.7, ups=14.87, wpb=485.6, bsz=15.9, num_updates=2000, lr=0.00050005, gnorm=1.137, clip=100, train_wall=5, wall=148]2022-11-08 08:19:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 046 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 046 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.88it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:19:59 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 1.835 | nll_loss 0.848 | ppl 1.8 | wps 33966.6 | wpb 537.5 | bsz 16.7 | num_updates 2024 | best_loss 1.835\n",
            "2022-11-08 08:19:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint46.pt (epoch 46 @ 2024 updates, score 1.835) (writing took 0.8839290809999625 seconds)\n",
            "2022-11-08 08:20:00 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)\n",
            "2022-11-08 08:20:00 | INFO | train | epoch 046 | loss 1.616 | nll_loss 0.689 | ppl 1.61 | wps 6186.7 | ups 12.56 | wpb 492.6 | bsz 15.9 | num_updates 2024 | lr 0.000506049 | gnorm 1.163 | clip 100 | train_wall 2 | wall 151\n",
            "epoch 047:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:00 | INFO | fairseq.trainer | begin training epoch 47\n",
            "epoch 047:  98% 43/44 [00:02<00:00, 18.99it/s]2022-11-08 08:20:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 047 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 047 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.46it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:03 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 1.817 | nll_loss 0.819 | ppl 1.76 | wps 35638.5 | wpb 537.5 | bsz 16.7 | num_updates 2068 | best_loss 1.817\n",
            "2022-11-08 08:20:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint47.pt (epoch 47 @ 2068 updates, score 1.817) (writing took 0.540061100999992 seconds)\n",
            "2022-11-08 08:20:03 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)\n",
            "2022-11-08 08:20:03 | INFO | train | epoch 047 | loss 1.607 | nll_loss 0.68 | ppl 1.6 | wps 6665.9 | ups 13.53 | wpb 492.6 | bsz 15.9 | num_updates 2068 | lr 0.000517048 | gnorm 1.116 | clip 100 | train_wall 2 | wall 154\n",
            "epoch 048:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:03 | INFO | fairseq.trainer | begin training epoch 48\n",
            "epoch 048:  98% 43/44 [00:02<00:00, 19.28it/s, loss=1.576, nll_loss=0.643, ppl=1.56, wps=6524.2, ups=13.4, wpb=486.8, bsz=15.9, num_updates=2100, lr=0.000525047, gnorm=1.09, clip=100, train_wall=5, wall=156]2022-11-08 08:20:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 048 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 048 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:06 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 1.818 | nll_loss 0.82 | ppl 1.77 | wps 35838.5 | wpb 537.5 | bsz 16.7 | num_updates 2112 | best_loss 1.817\n",
            "2022-11-08 08:20:06 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint48.pt (epoch 48 @ 2112 updates, score 1.818) (writing took 0.38198442800000976 seconds)\n",
            "2022-11-08 08:20:06 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)\n",
            "2022-11-08 08:20:06 | INFO | train | epoch 048 | loss 1.563 | nll_loss 0.628 | ppl 1.55 | wps 7126.9 | ups 14.47 | wpb 492.6 | bsz 15.9 | num_updates 2112 | lr 0.000528047 | gnorm 1.024 | clip 100 | train_wall 2 | wall 157\n",
            "epoch 049:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:06 | INFO | fairseq.trainer | begin training epoch 49\n",
            "epoch 049:  98% 43/44 [00:02<00:00, 19.46it/s]2022-11-08 08:20:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 049 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 049 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.51it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:09 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 1.819 | nll_loss 0.835 | ppl 1.78 | wps 33803.6 | wpb 537.5 | bsz 16.7 | num_updates 2156 | best_loss 1.817\n",
            "2022-11-08 08:20:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint49.pt (epoch 49 @ 2156 updates, score 1.819) (writing took 0.450110608999978 seconds)\n",
            "2022-11-08 08:20:09 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)\n",
            "2022-11-08 08:20:09 | INFO | train | epoch 049 | loss 1.568 | nll_loss 0.637 | ppl 1.55 | wps 7028.4 | ups 14.27 | wpb 492.6 | bsz 15.9 | num_updates 2156 | lr 0.000539046 | gnorm 1.107 | clip 100 | train_wall 2 | wall 160\n",
            "epoch 050:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:09 | INFO | fairseq.trainer | begin training epoch 50\n",
            "epoch 050:  98% 43/44 [00:02<00:00, 19.64it/s]2022-11-08 08:20:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 050 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 050 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.42it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:12 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 1.833 | nll_loss 0.859 | ppl 1.81 | wps 34746.8 | wpb 537.5 | bsz 16.7 | num_updates 2200 | best_loss 1.817\n",
            "2022-11-08 08:20:12 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint50.pt (epoch 50 @ 2200 updates, score 1.833) (writing took 0.3962937240000315 seconds)\n",
            "2022-11-08 08:20:12 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)\n",
            "2022-11-08 08:20:12 | INFO | train | epoch 050 | loss 1.559 | nll_loss 0.624 | ppl 1.54 | wps 7151.6 | ups 14.52 | wpb 492.6 | bsz 15.9 | num_updates 2200 | lr 0.000550045 | gnorm 1.065 | clip 100 | train_wall 2 | wall 163\n",
            "epoch 051:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:12 | INFO | fairseq.trainer | begin training epoch 51\n",
            "epoch 051:  95% 42/44 [00:02<00:00, 19.52it/s]2022-11-08 08:20:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 051 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 051 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.19it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:15 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 1.815 | nll_loss 0.83 | ppl 1.78 | wps 29116.8 | wpb 537.5 | bsz 16.7 | num_updates 2244 | best_loss 1.815\n",
            "2022-11-08 08:20:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint51.pt (epoch 51 @ 2244 updates, score 1.815) (writing took 0.6189760010000214 seconds)\n",
            "2022-11-08 08:20:16 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)\n",
            "2022-11-08 08:20:16 | INFO | train | epoch 051 | loss 1.53 | nll_loss 0.594 | ppl 1.51 | wps 6652.3 | ups 13.5 | wpb 492.6 | bsz 15.9 | num_updates 2244 | lr 0.000561044 | gnorm 1.033 | clip 100 | train_wall 2 | wall 166\n",
            "epoch 052:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:16 | INFO | fairseq.trainer | begin training epoch 52\n",
            "epoch 052:  93% 41/44 [00:02<00:00, 19.66it/s]2022-11-08 08:20:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 052 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 052 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.69it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:18 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 1.797 | nll_loss 0.801 | ppl 1.74 | wps 32989.5 | wpb 537.5 | bsz 16.7 | num_updates 2288 | best_loss 1.797\n",
            "2022-11-08 08:20:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint52.pt (epoch 52 @ 2288 updates, score 1.797) (writing took 0.5849069759999566 seconds)\n",
            "2022-11-08 08:20:19 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)\n",
            "2022-11-08 08:20:19 | INFO | train | epoch 052 | loss 1.557 | nll_loss 0.625 | ppl 1.54 | wps 6685 | ups 13.57 | wpb 492.6 | bsz 15.9 | num_updates 2288 | lr 0.000572043 | gnorm 1.119 | clip 100 | train_wall 2 | wall 170\n",
            "epoch 053:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:19 | INFO | fairseq.trainer | begin training epoch 53\n",
            "epoch 053:  98% 43/44 [00:02<00:00, 19.30it/s, loss=1.55, nll_loss=0.616, ppl=1.53, wps=6409.6, ups=12.76, wpb=502.2, bsz=15.9, num_updates=2300, lr=0.000575042, gnorm=1.063, clip=100, train_wall=5, wall=170]2022-11-08 08:20:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 053 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 053 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.39it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:21 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 1.803 | nll_loss 0.818 | ppl 1.76 | wps 35529.3 | wpb 537.5 | bsz 16.7 | num_updates 2332 | best_loss 1.797\n",
            "2022-11-08 08:20:21 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint53.pt (epoch 53 @ 2332 updates, score 1.803) (writing took 0.40832602500000803 seconds)\n",
            "2022-11-08 08:20:22 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)\n",
            "2022-11-08 08:20:22 | INFO | train | epoch 053 | loss 1.511 | nll_loss 0.574 | ppl 1.49 | wps 7061.3 | ups 14.33 | wpb 492.6 | bsz 15.9 | num_updates 2332 | lr 0.000583042 | gnorm 1.064 | clip 100 | train_wall 2 | wall 173\n",
            "epoch 054:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:22 | INFO | fairseq.trainer | begin training epoch 54\n",
            "epoch 054:  98% 43/44 [00:02<00:00, 20.10it/s]2022-11-08 08:20:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 054 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 054 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.07it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:25 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 1.77 | nll_loss 0.777 | ppl 1.71 | wps 35546.3 | wpb 537.5 | bsz 16.7 | num_updates 2376 | best_loss 1.77\n",
            "2022-11-08 08:20:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint54.pt (epoch 54 @ 2376 updates, score 1.77) (writing took 0.5364449150000041 seconds)\n",
            "2022-11-08 08:20:25 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)\n",
            "2022-11-08 08:20:25 | INFO | train | epoch 054 | loss 1.507 | nll_loss 0.568 | ppl 1.48 | wps 6843.1 | ups 13.89 | wpb 492.6 | bsz 15.9 | num_updates 2376 | lr 0.000594041 | gnorm 1.016 | clip 100 | train_wall 2 | wall 176\n",
            "epoch 055:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:25 | INFO | fairseq.trainer | begin training epoch 55\n",
            "epoch 055:  95% 42/44 [00:02<00:00, 19.83it/s, loss=1.494, nll_loss=0.555, ppl=1.47, wps=7007.9, ups=14.36, wpb=488.1, bsz=16, num_updates=2400, lr=0.00060004, gnorm=1.037, clip=100, train_wall=5, wall=177]2022-11-08 08:20:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 055 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 055 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.28it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:28 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 1.803 | nll_loss 0.811 | ppl 1.75 | wps 33123.5 | wpb 537.5 | bsz 16.7 | num_updates 2420 | best_loss 1.77\n",
            "2022-11-08 08:20:28 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint55.pt (epoch 55 @ 2420 updates, score 1.803) (writing took 0.42420730800000683 seconds)\n",
            "2022-11-08 08:20:28 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)\n",
            "2022-11-08 08:20:28 | INFO | train | epoch 055 | loss 1.492 | nll_loss 0.553 | ppl 1.47 | wps 6954 | ups 14.12 | wpb 492.6 | bsz 15.9 | num_updates 2420 | lr 0.000605039 | gnorm 1.015 | clip 100 | train_wall 2 | wall 179\n",
            "epoch 056:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:28 | INFO | fairseq.trainer | begin training epoch 56\n",
            "epoch 056:  95% 42/44 [00:02<00:00, 19.53it/s]2022-11-08 08:20:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 056 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 056 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.17it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:31 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 1.781 | nll_loss 0.781 | ppl 1.72 | wps 31739.8 | wpb 537.5 | bsz 16.7 | num_updates 2464 | best_loss 1.77\n",
            "2022-11-08 08:20:31 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint56.pt (epoch 56 @ 2464 updates, score 1.781) (writing took 0.40769534100002147 seconds)\n",
            "2022-11-08 08:20:31 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)\n",
            "2022-11-08 08:20:31 | INFO | train | epoch 056 | loss 1.495 | nll_loss 0.558 | ppl 1.47 | wps 7081.3 | ups 14.38 | wpb 492.6 | bsz 15.9 | num_updates 2464 | lr 0.000616038 | gnorm 1.063 | clip 100 | train_wall 2 | wall 182\n",
            "epoch 057:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:31 | INFO | fairseq.trainer | begin training epoch 57\n",
            "epoch 057:  98% 43/44 [00:02<00:00, 19.77it/s, loss=1.474, nll_loss=0.534, ppl=1.45, wps=7096.2, ups=14.81, wpb=479.2, bsz=15.9, num_updates=2500, lr=0.000625037, gnorm=1.033, clip=100, train_wall=5, wall=184]2022-11-08 08:20:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 057 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 057 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.28it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:34 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 1.886 | nll_loss 0.908 | ppl 1.88 | wps 30776.7 | wpb 537.5 | bsz 16.7 | num_updates 2508 | best_loss 1.77\n",
            "2022-11-08 08:20:34 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint57.pt (epoch 57 @ 2508 updates, score 1.886) (writing took 0.40774649600001567 seconds)\n",
            "2022-11-08 08:20:34 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)\n",
            "2022-11-08 08:20:34 | INFO | train | epoch 057 | loss 1.49 | nll_loss 0.55 | ppl 1.46 | wps 7101.5 | ups 14.42 | wpb 492.6 | bsz 15.9 | num_updates 2508 | lr 0.000627037 | gnorm 1.015 | clip 100 | train_wall 2 | wall 185\n",
            "epoch 058:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:34 | INFO | fairseq.trainer | begin training epoch 58\n",
            "epoch 058:  98% 43/44 [00:02<00:00, 20.02it/s]2022-11-08 08:20:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 058 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 058 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.61it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:37 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 1.76 | nll_loss 0.771 | ppl 1.71 | wps 34737.1 | wpb 537.5 | bsz 16.7 | num_updates 2552 | best_loss 1.76\n",
            "2022-11-08 08:20:37 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint58.pt (epoch 58 @ 2552 updates, score 1.76) (writing took 1.1241010269999947 seconds)\n",
            "2022-11-08 08:20:38 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)\n",
            "2022-11-08 08:20:38 | INFO | train | epoch 058 | loss 1.469 | nll_loss 0.528 | ppl 1.44 | wps 5814.8 | ups 11.8 | wpb 492.6 | bsz 15.9 | num_updates 2552 | lr 0.000638036 | gnorm 1.018 | clip 100 | train_wall 2 | wall 189\n",
            "epoch 059:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:38 | INFO | fairseq.trainer | begin training epoch 59\n",
            "epoch 059:  98% 43/44 [00:02<00:00, 19.58it/s]2022-11-08 08:20:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 059 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 059 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.30it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:41 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 1.777 | nll_loss 0.792 | ppl 1.73 | wps 28917.7 | wpb 537.5 | bsz 16.7 | num_updates 2596 | best_loss 1.76\n",
            "2022-11-08 08:20:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint59.pt (epoch 59 @ 2596 updates, score 1.777) (writing took 0.43410130799998115 seconds)\n",
            "2022-11-08 08:20:41 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)\n",
            "2022-11-08 08:20:41 | INFO | train | epoch 059 | loss 1.463 | nll_loss 0.525 | ppl 1.44 | wps 7065 | ups 14.34 | wpb 492.6 | bsz 15.9 | num_updates 2596 | lr 0.000649035 | gnorm 0.973 | clip 100 | train_wall 2 | wall 192\n",
            "epoch 060:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:41 | INFO | fairseq.trainer | begin training epoch 60\n",
            "epoch 060:  95% 42/44 [00:02<00:00, 19.21it/s, loss=1.494, nll_loss=0.558, ppl=1.47, wps=6250.2, ups=12.33, wpb=506.8, bsz=15.9, num_updates=2600, lr=0.000650035, gnorm=1.008, clip=100, train_wall=5, wall=192]2022-11-08 08:20:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 060 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 060 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.92it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:44 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 1.735 | nll_loss 0.751 | ppl 1.68 | wps 37587.1 | wpb 537.5 | bsz 16.7 | num_updates 2640 | best_loss 1.735\n",
            "2022-11-08 08:20:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint60.pt (epoch 60 @ 2640 updates, score 1.735) (writing took 0.5845489170000064 seconds)\n",
            "2022-11-08 08:20:44 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)\n",
            "2022-11-08 08:20:44 | INFO | train | epoch 060 | loss 1.481 | nll_loss 0.543 | ppl 1.46 | wps 6675.6 | ups 13.55 | wpb 492.6 | bsz 15.9 | num_updates 2640 | lr 0.000660034 | gnorm 0.982 | clip 100 | train_wall 2 | wall 195\n",
            "epoch 061:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:44 | INFO | fairseq.trainer | begin training epoch 61\n",
            "epoch 061:  95% 42/44 [00:02<00:00, 19.38it/s]2022-11-08 08:20:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 061 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 061 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.92it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:47 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 1.776 | nll_loss 0.79 | ppl 1.73 | wps 34133.8 | wpb 537.5 | bsz 16.7 | num_updates 2684 | best_loss 1.735\n",
            "2022-11-08 08:20:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint61.pt (epoch 61 @ 2684 updates, score 1.776) (writing took 0.39867382800002815 seconds)\n",
            "2022-11-08 08:20:47 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)\n",
            "2022-11-08 08:20:47 | INFO | train | epoch 061 | loss 1.428 | nll_loss 0.485 | ppl 1.4 | wps 7191.5 | ups 14.6 | wpb 492.6 | bsz 15.9 | num_updates 2684 | lr 0.000671033 | gnorm 0.949 | clip 100 | train_wall 2 | wall 198\n",
            "epoch 062:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:47 | INFO | fairseq.trainer | begin training epoch 62\n",
            "epoch 062:  95% 42/44 [00:02<00:00, 20.35it/s, loss=1.448, nll_loss=0.505, ppl=1.42, wps=7042.1, ups=14.51, wpb=485.3, bsz=15.9, num_updates=2700, lr=0.000675032, gnorm=0.961, clip=100, train_wall=5, wall=199]2022-11-08 08:20:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 062 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 062 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.86it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:50 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 1.802 | nll_loss 0.827 | ppl 1.77 | wps 28784.1 | wpb 537.5 | bsz 16.7 | num_updates 2728 | best_loss 1.735\n",
            "2022-11-08 08:20:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint62.pt (epoch 62 @ 2728 updates, score 1.802) (writing took 0.40744435800002066 seconds)\n",
            "2022-11-08 08:20:50 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)\n",
            "2022-11-08 08:20:50 | INFO | train | epoch 062 | loss 1.421 | nll_loss 0.474 | ppl 1.39 | wps 7268.8 | ups 14.76 | wpb 492.6 | bsz 15.9 | num_updates 2728 | lr 0.000682032 | gnorm 0.978 | clip 100 | train_wall 2 | wall 201\n",
            "epoch 063:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:50 | INFO | fairseq.trainer | begin training epoch 63\n",
            "epoch 063:  98% 43/44 [00:02<00:00, 20.04it/s]2022-11-08 08:20:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 063 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 063 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:53 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 1.739 | nll_loss 0.738 | ppl 1.67 | wps 34127.7 | wpb 537.5 | bsz 16.7 | num_updates 2772 | best_loss 1.735\n",
            "2022-11-08 08:20:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint63.pt (epoch 63 @ 2772 updates, score 1.739) (writing took 0.39002331599999707 seconds)\n",
            "2022-11-08 08:20:53 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)\n",
            "2022-11-08 08:20:53 | INFO | train | epoch 063 | loss 1.429 | nll_loss 0.484 | ppl 1.4 | wps 7257 | ups 14.73 | wpb 492.6 | bsz 15.9 | num_updates 2772 | lr 0.000693031 | gnorm 0.96 | clip 100 | train_wall 2 | wall 204\n",
            "epoch 064:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:53 | INFO | fairseq.trainer | begin training epoch 64\n",
            "epoch 064:  98% 43/44 [00:02<00:00, 20.96it/s, loss=1.407, nll_loss=0.46, ppl=1.38, wps=7413.2, ups=15.15, wpb=489.4, bsz=16, num_updates=2800, lr=0.00070003, gnorm=0.985, clip=100, train_wall=5, wall=206]2022-11-08 08:20:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 064 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 064 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.42it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:56 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 1.663 | nll_loss 0.671 | ppl 1.59 | wps 32331.1 | wpb 537.5 | bsz 16.7 | num_updates 2816 | best_loss 1.663\n",
            "2022-11-08 08:20:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint64.pt (epoch 64 @ 2816 updates, score 1.663) (writing took 0.5557949230000077 seconds)\n",
            "2022-11-08 08:20:56 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)\n",
            "2022-11-08 08:20:56 | INFO | train | epoch 064 | loss 1.436 | nll_loss 0.495 | ppl 1.41 | wps 6990 | ups 14.19 | wpb 492.6 | bsz 15.9 | num_updates 2816 | lr 0.00070403 | gnorm 1.04 | clip 100 | train_wall 2 | wall 207\n",
            "epoch 065:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:56 | INFO | fairseq.trainer | begin training epoch 65\n",
            "epoch 065:  93% 41/44 [00:02<00:00, 19.64it/s]2022-11-08 08:20:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 065 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 065 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.08it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:20:59 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 1.696 | nll_loss 0.702 | ppl 1.63 | wps 34606.5 | wpb 537.5 | bsz 16.7 | num_updates 2860 | best_loss 1.663\n",
            "2022-11-08 08:20:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:20:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint65.pt (epoch 65 @ 2860 updates, score 1.696) (writing took 0.42639939899999035 seconds)\n",
            "2022-11-08 08:20:59 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)\n",
            "2022-11-08 08:20:59 | INFO | train | epoch 065 | loss 1.398 | nll_loss 0.451 | ppl 1.37 | wps 7193.9 | ups 14.6 | wpb 492.6 | bsz 15.9 | num_updates 2860 | lr 0.000715028 | gnorm 0.951 | clip 100 | train_wall 2 | wall 210\n",
            "epoch 066:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:20:59 | INFO | fairseq.trainer | begin training epoch 66\n",
            "epoch 066:  95% 42/44 [00:02<00:00, 19.93it/s, loss=1.427, nll_loss=0.486, ppl=1.4, wps=7514.1, ups=14.88, wpb=505.1, bsz=15.9, num_updates=2900, lr=0.000725027, gnorm=0.978, clip=100, train_wall=5, wall=212]2022-11-08 08:21:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 066 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 066 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.61it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:02 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 1.763 | nll_loss 0.775 | ppl 1.71 | wps 37364 | wpb 537.5 | bsz 16.7 | num_updates 2904 | best_loss 1.663\n",
            "2022-11-08 08:21:02 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint66.pt (epoch 66 @ 2904 updates, score 1.763) (writing took 0.43371056799998087 seconds)\n",
            "2022-11-08 08:21:02 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)\n",
            "2022-11-08 08:21:02 | INFO | train | epoch 066 | loss 1.416 | nll_loss 0.473 | ppl 1.39 | wps 7227.1 | ups 14.67 | wpb 492.6 | bsz 15.9 | num_updates 2904 | lr 0.000726027 | gnorm 0.981 | clip 100 | train_wall 2 | wall 213\n",
            "epoch 067:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:02 | INFO | fairseq.trainer | begin training epoch 67\n",
            "epoch 067:  93% 41/44 [00:02<00:00, 18.91it/s]2022-11-08 08:21:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 067 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 067 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.83it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:05 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 1.672 | nll_loss 0.678 | ppl 1.6 | wps 34984.6 | wpb 537.5 | bsz 16.7 | num_updates 2948 | best_loss 1.663\n",
            "2022-11-08 08:21:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint67.pt (epoch 67 @ 2948 updates, score 1.672) (writing took 0.4466242990000069 seconds)\n",
            "2022-11-08 08:21:06 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)\n",
            "2022-11-08 08:21:06 | INFO | train | epoch 067 | loss 1.402 | nll_loss 0.459 | ppl 1.37 | wps 7025 | ups 14.26 | wpb 492.6 | bsz 15.9 | num_updates 2948 | lr 0.000737026 | gnorm 0.966 | clip 100 | train_wall 2 | wall 216\n",
            "epoch 068:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:06 | INFO | fairseq.trainer | begin training epoch 68\n",
            "epoch 068:  93% 41/44 [00:02<00:00, 19.25it/s]2022-11-08 08:21:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 068 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 068 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.09it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:08 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 1.741 | nll_loss 0.745 | ppl 1.68 | wps 40804.2 | wpb 537.5 | bsz 16.7 | num_updates 2992 | best_loss 1.663\n",
            "2022-11-08 08:21:08 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint68.pt (epoch 68 @ 2992 updates, score 1.741) (writing took 0.39109131800000796 seconds)\n",
            "2022-11-08 08:21:09 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)\n",
            "2022-11-08 08:21:09 | INFO | train | epoch 068 | loss 1.388 | nll_loss 0.44 | ppl 1.36 | wps 7264.9 | ups 14.75 | wpb 492.6 | bsz 15.9 | num_updates 2992 | lr 0.000748025 | gnorm 0.895 | clip 100 | train_wall 2 | wall 219\n",
            "epoch 069:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:09 | INFO | fairseq.trainer | begin training epoch 69\n",
            "epoch 069:  98% 43/44 [00:02<00:00, 19.88it/s, loss=1.385, nll_loss=0.438, ppl=1.35, wps=6487, ups=13.5, wpb=480.6, bsz=15.9, num_updates=3000, lr=0.000750025, gnorm=0.932, clip=100, train_wall=5, wall=220]2022-11-08 08:21:11 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 069 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 069 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.55it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:11 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 1.71 | nll_loss 0.722 | ppl 1.65 | wps 35344.3 | wpb 537.5 | bsz 16.7 | num_updates 3036 | best_loss 1.663\n",
            "2022-11-08 08:21:11 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint69.pt (epoch 69 @ 3036 updates, score 1.71) (writing took 0.4292061419999982 seconds)\n",
            "2022-11-08 08:21:12 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)\n",
            "2022-11-08 08:21:12 | INFO | train | epoch 069 | loss 1.404 | nll_loss 0.46 | ppl 1.38 | wps 7039.8 | ups 14.29 | wpb 492.6 | bsz 15.9 | num_updates 3036 | lr 0.000759024 | gnorm 0.962 | clip 100 | train_wall 2 | wall 222\n",
            "epoch 070:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:12 | INFO | fairseq.trainer | begin training epoch 70\n",
            "epoch 070:  95% 42/44 [00:02<00:00, 19.59it/s]2022-11-08 08:21:14 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 070 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 070 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.65it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:14 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 1.659 | nll_loss 0.66 | ppl 1.58 | wps 36362.9 | wpb 537.5 | bsz 16.7 | num_updates 3080 | best_loss 1.659\n",
            "2022-11-08 08:21:14 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint70.pt (epoch 70 @ 3080 updates, score 1.659) (writing took 0.5907211179999763 seconds)\n",
            "2022-11-08 08:21:15 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)\n",
            "2022-11-08 08:21:15 | INFO | train | epoch 070 | loss 1.401 | nll_loss 0.457 | ppl 1.37 | wps 6807.3 | ups 13.82 | wpb 492.6 | bsz 15.9 | num_updates 3080 | lr 0.000770023 | gnorm 0.919 | clip 100 | train_wall 2 | wall 226\n",
            "epoch 071:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:15 | INFO | fairseq.trainer | begin training epoch 71\n",
            "epoch 071:  93% 41/44 [00:02<00:00, 20.06it/s, loss=1.419, nll_loss=0.478, ppl=1.39, wps=7270.3, ups=14.4, wpb=504.8, bsz=15.9, num_updates=3100, lr=0.000775022, gnorm=0.939, clip=100, train_wall=5, wall=227]2022-11-08 08:21:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 071 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 071 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.57it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:17 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 1.682 | nll_loss 0.687 | ppl 1.61 | wps 31869 | wpb 537.5 | bsz 16.7 | num_updates 3124 | best_loss 1.659\n",
            "2022-11-08 08:21:17 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint71.pt (epoch 71 @ 3124 updates, score 1.682) (writing took 0.41847385300002315 seconds)\n",
            "2022-11-08 08:21:18 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)\n",
            "2022-11-08 08:21:18 | INFO | train | epoch 071 | loss 1.361 | nll_loss 0.413 | ppl 1.33 | wps 7099.6 | ups 14.41 | wpb 492.6 | bsz 15.9 | num_updates 3124 | lr 0.000781022 | gnorm 0.874 | clip 100 | train_wall 2 | wall 229\n",
            "epoch 072:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:18 | INFO | fairseq.trainer | begin training epoch 72\n",
            "epoch 072:  93% 41/44 [00:02<00:00, 19.37it/s]2022-11-08 08:21:20 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 072 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 072 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.39it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:20 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 1.713 | nll_loss 0.723 | ppl 1.65 | wps 30171.9 | wpb 537.5 | bsz 16.7 | num_updates 3168 | best_loss 1.659\n",
            "2022-11-08 08:21:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint72.pt (epoch 72 @ 3168 updates, score 1.713) (writing took 0.4206669159999592 seconds)\n",
            "2022-11-08 08:21:21 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)\n",
            "2022-11-08 08:21:21 | INFO | train | epoch 072 | loss 1.374 | nll_loss 0.428 | ppl 1.35 | wps 7125.7 | ups 14.47 | wpb 492.6 | bsz 15.9 | num_updates 3168 | lr 0.000792021 | gnorm 0.934 | clip 100 | train_wall 2 | wall 232\n",
            "epoch 073:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:21 | INFO | fairseq.trainer | begin training epoch 73\n",
            "epoch 073:  95% 42/44 [00:02<00:00, 19.81it/s, loss=1.333, nll_loss=0.38, ppl=1.3, wps=7083.1, ups=14.9, wpb=475.4, bsz=16, num_updates=3200, lr=0.00080002, gnorm=0.903, clip=100, train_wall=5, wall=233]2022-11-08 08:21:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 073 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 073 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.70it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:23 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 1.647 | nll_loss 0.659 | ppl 1.58 | wps 32774.5 | wpb 537.5 | bsz 16.7 | num_updates 3212 | best_loss 1.647\n",
            "2022-11-08 08:21:23 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint73.pt (epoch 73 @ 3212 updates, score 1.647) (writing took 0.557646482999985 seconds)\n",
            "2022-11-08 08:21:24 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)\n",
            "2022-11-08 08:21:24 | INFO | train | epoch 073 | loss 1.359 | nll_loss 0.411 | ppl 1.33 | wps 6871.2 | ups 13.95 | wpb 492.6 | bsz 15.9 | num_updates 3212 | lr 0.00080302 | gnorm 0.91 | clip 100 | train_wall 2 | wall 235\n",
            "epoch 074:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:24 | INFO | fairseq.trainer | begin training epoch 74\n",
            "epoch 074:  98% 43/44 [00:02<00:00, 19.51it/s]2022-11-08 08:21:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 074 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 074 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.36it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:27 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 1.702 | nll_loss 0.701 | ppl 1.63 | wps 39125.1 | wpb 537.5 | bsz 16.7 | num_updates 3256 | best_loss 1.647\n",
            "2022-11-08 08:21:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint74.pt (epoch 74 @ 3256 updates, score 1.702) (writing took 0.4105735710000431 seconds)\n",
            "2022-11-08 08:21:27 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)\n",
            "2022-11-08 08:21:27 | INFO | train | epoch 074 | loss 1.353 | nll_loss 0.403 | ppl 1.32 | wps 7125 | ups 14.46 | wpb 492.6 | bsz 15.9 | num_updates 3256 | lr 0.000814019 | gnorm 0.926 | clip 100 | train_wall 2 | wall 238\n",
            "epoch 075:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:27 | INFO | fairseq.trainer | begin training epoch 75\n",
            "epoch 075:  93% 41/44 [00:02<00:00, 20.15it/s]2022-11-08 08:21:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 075 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 075 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.87it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:30 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 1.677 | nll_loss 0.681 | ppl 1.6 | wps 34525.8 | wpb 537.5 | bsz 16.7 | num_updates 3300 | best_loss 1.647\n",
            "2022-11-08 08:21:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint75.pt (epoch 75 @ 3300 updates, score 1.677) (writing took 0.4299013709999713 seconds)\n",
            "2022-11-08 08:21:30 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)\n",
            "2022-11-08 08:21:30 | INFO | train | epoch 075 | loss 1.369 | nll_loss 0.424 | ppl 1.34 | wps 7167 | ups 14.55 | wpb 492.6 | bsz 15.9 | num_updates 3300 | lr 0.000825017 | gnorm 0.987 | clip 100 | train_wall 2 | wall 241\n",
            "epoch 076:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:30 | INFO | fairseq.trainer | begin training epoch 76\n",
            "epoch 076:  95% 42/44 [00:02<00:00, 19.18it/s]2022-11-08 08:21:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 076 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 076 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.41it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:33 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 1.629 | nll_loss 0.631 | ppl 1.55 | wps 36158.3 | wpb 537.5 | bsz 16.7 | num_updates 3344 | best_loss 1.629\n",
            "2022-11-08 08:21:33 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint76.pt (epoch 76 @ 3344 updates, score 1.629) (writing took 0.5616180220000047 seconds)\n",
            "2022-11-08 08:21:33 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)\n",
            "2022-11-08 08:21:33 | INFO | train | epoch 076 | loss 1.347 | nll_loss 0.4 | ppl 1.32 | wps 6843 | ups 13.89 | wpb 492.6 | bsz 15.9 | num_updates 3344 | lr 0.000836016 | gnorm 0.943 | clip 100 | train_wall 2 | wall 244\n",
            "epoch 077:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:33 | INFO | fairseq.trainer | begin training epoch 77\n",
            "epoch 077:  98% 43/44 [00:02<00:00, 19.88it/s]2022-11-08 08:21:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 077 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 077 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.03it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:36 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 1.635 | nll_loss 0.63 | ppl 1.55 | wps 32892.3 | wpb 537.5 | bsz 16.7 | num_updates 3388 | best_loss 1.629\n",
            "2022-11-08 08:21:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint77.pt (epoch 77 @ 3388 updates, score 1.635) (writing took 0.4208691079999767 seconds)\n",
            "2022-11-08 08:21:36 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)\n",
            "2022-11-08 08:21:36 | INFO | train | epoch 077 | loss 1.351 | nll_loss 0.403 | ppl 1.32 | wps 7084 | ups 14.38 | wpb 492.6 | bsz 15.9 | num_updates 3388 | lr 0.000847015 | gnorm 1.012 | clip 100 | train_wall 2 | wall 247\n",
            "epoch 078:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:36 | INFO | fairseq.trainer | begin training epoch 78\n",
            "epoch 078:  98% 43/44 [00:02<00:00, 19.66it/s, loss=1.343, nll_loss=0.395, ppl=1.31, wps=6553.1, ups=13.26, wpb=494.3, bsz=15.9, num_updates=3400, lr=0.000850015, gnorm=0.963, clip=100, train_wall=5, wall=248]2022-11-08 08:21:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 078 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 078 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.54it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:39 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 1.694 | nll_loss 0.695 | ppl 1.62 | wps 32554.3 | wpb 537.5 | bsz 16.7 | num_updates 3432 | best_loss 1.629\n",
            "2022-11-08 08:21:39 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint78.pt (epoch 78 @ 3432 updates, score 1.694) (writing took 0.3908744240000033 seconds)\n",
            "2022-11-08 08:21:39 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)\n",
            "2022-11-08 08:21:39 | INFO | train | epoch 078 | loss 1.339 | nll_loss 0.39 | ppl 1.31 | wps 7208.5 | ups 14.63 | wpb 492.6 | bsz 15.9 | num_updates 3432 | lr 0.000858014 | gnorm 0.995 | clip 100 | train_wall 2 | wall 250\n",
            "epoch 079:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:39 | INFO | fairseq.trainer | begin training epoch 79\n",
            "epoch 079:  93% 41/44 [00:02<00:00, 20.00it/s]2022-11-08 08:21:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 079 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 079 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.19it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:42 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 1.751 | nll_loss 0.755 | ppl 1.69 | wps 27933 | wpb 537.5 | bsz 16.7 | num_updates 3476 | best_loss 1.629\n",
            "2022-11-08 08:21:42 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint79.pt (epoch 79 @ 3476 updates, score 1.751) (writing took 0.41828807899997855 seconds)\n",
            "2022-11-08 08:21:42 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)\n",
            "2022-11-08 08:21:42 | INFO | train | epoch 079 | loss 1.349 | nll_loss 0.401 | ppl 1.32 | wps 7071.4 | ups 14.36 | wpb 492.6 | bsz 15.9 | num_updates 3476 | lr 0.000869013 | gnorm 0.919 | clip 100 | train_wall 2 | wall 253\n",
            "epoch 080:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:42 | INFO | fairseq.trainer | begin training epoch 80\n",
            "epoch 080:  95% 42/44 [00:02<00:00, 19.39it/s, loss=1.333, nll_loss=0.382, ppl=1.3, wps=7166.8, ups=14.79, wpb=484.6, bsz=15.9, num_updates=3500, lr=0.000875012, gnorm=0.977, clip=100, train_wall=5, wall=255]2022-11-08 08:21:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 080 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 080 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.84it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:45 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 1.682 | nll_loss 0.682 | ppl 1.6 | wps 37414 | wpb 537.5 | bsz 16.7 | num_updates 3520 | best_loss 1.629\n",
            "2022-11-08 08:21:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint80.pt (epoch 80 @ 3520 updates, score 1.682) (writing took 0.3965782149999768 seconds)\n",
            "2022-11-08 08:21:45 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)\n",
            "2022-11-08 08:21:45 | INFO | train | epoch 080 | loss 1.341 | nll_loss 0.392 | ppl 1.31 | wps 7185.7 | ups 14.59 | wpb 492.6 | bsz 15.9 | num_updates 3520 | lr 0.000880012 | gnorm 1.033 | clip 100 | train_wall 2 | wall 256\n",
            "epoch 081:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:45 | INFO | fairseq.trainer | begin training epoch 81\n",
            "epoch 081:  98% 43/44 [00:02<00:00, 19.86it/s]2022-11-08 08:21:48 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 081 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 081 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.08it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:48 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 1.634 | nll_loss 0.634 | ppl 1.55 | wps 37910.5 | wpb 537.5 | bsz 16.7 | num_updates 3564 | best_loss 1.629\n",
            "2022-11-08 08:21:48 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint81.pt (epoch 81 @ 3564 updates, score 1.634) (writing took 0.418562871000006 seconds)\n",
            "2022-11-08 08:21:49 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)\n",
            "2022-11-08 08:21:49 | INFO | train | epoch 081 | loss 1.329 | nll_loss 0.378 | ppl 1.3 | wps 6967.2 | ups 14.14 | wpb 492.6 | bsz 15.9 | num_updates 3564 | lr 0.000891011 | gnorm 0.921 | clip 100 | train_wall 2 | wall 259\n",
            "epoch 082:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:49 | INFO | fairseq.trainer | begin training epoch 82\n",
            "epoch 082:  95% 42/44 [00:02<00:00, 20.20it/s, loss=1.345, nll_loss=0.398, ppl=1.32, wps=7367.8, ups=14.92, wpb=493.8, bsz=15.9, num_updates=3600, lr=0.00090001, gnorm=0.949, clip=100, train_wall=5, wall=261]2022-11-08 08:21:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 082 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 082 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.68it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:51 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 1.678 | nll_loss 0.675 | ppl 1.6 | wps 30259.4 | wpb 537.5 | bsz 16.7 | num_updates 3608 | best_loss 1.629\n",
            "2022-11-08 08:21:51 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint82.pt (epoch 82 @ 3608 updates, score 1.678) (writing took 0.39420610499996656 seconds)\n",
            "2022-11-08 08:21:52 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)\n",
            "2022-11-08 08:21:52 | INFO | train | epoch 082 | loss 1.344 | nll_loss 0.397 | ppl 1.32 | wps 7290.4 | ups 14.8 | wpb 492.6 | bsz 15.9 | num_updates 3608 | lr 0.00090201 | gnorm 0.914 | clip 100 | train_wall 2 | wall 262\n",
            "epoch 083:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:52 | INFO | fairseq.trainer | begin training epoch 83\n",
            "epoch 083:  98% 43/44 [00:02<00:00, 19.87it/s]2022-11-08 08:21:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 083 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 083 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.35it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:54 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 1.638 | nll_loss 0.624 | ppl 1.54 | wps 35968.9 | wpb 537.5 | bsz 16.7 | num_updates 3652 | best_loss 1.629\n",
            "2022-11-08 08:21:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint83.pt (epoch 83 @ 3652 updates, score 1.638) (writing took 0.4164105309999968 seconds)\n",
            "2022-11-08 08:21:55 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)\n",
            "2022-11-08 08:21:55 | INFO | train | epoch 083 | loss 1.358 | nll_loss 0.413 | ppl 1.33 | wps 7183.5 | ups 14.58 | wpb 492.6 | bsz 15.9 | num_updates 3652 | lr 0.000913009 | gnorm 1.073 | clip 100 | train_wall 2 | wall 265\n",
            "epoch 084:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:55 | INFO | fairseq.trainer | begin training epoch 84\n",
            "epoch 084:  95% 42/44 [00:02<00:00, 18.90it/s]2022-11-08 08:21:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 084 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 084 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.42it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:21:57 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 1.627 | nll_loss 0.625 | ppl 1.54 | wps 34989.5 | wpb 537.5 | bsz 16.7 | num_updates 3696 | best_loss 1.627\n",
            "2022-11-08 08:21:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:21:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint84.pt (epoch 84 @ 3696 updates, score 1.627) (writing took 0.5604082169999742 seconds)\n",
            "2022-11-08 08:21:58 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)\n",
            "2022-11-08 08:21:58 | INFO | train | epoch 084 | loss 1.329 | nll_loss 0.381 | ppl 1.3 | wps 6721.8 | ups 13.65 | wpb 492.6 | bsz 15.9 | num_updates 3696 | lr 0.000924008 | gnorm 0.907 | clip 100 | train_wall 2 | wall 269\n",
            "epoch 085:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:21:58 | INFO | fairseq.trainer | begin training epoch 85\n",
            "epoch 085:  98% 43/44 [00:02<00:00, 19.29it/s, loss=1.347, nll_loss=0.4, ppl=1.32, wps=6528.6, ups=13.16, wpb=496, bsz=15.9, num_updates=3700, lr=0.000925007, gnorm=0.982, clip=100, train_wall=5, wall=269]2022-11-08 08:22:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 085 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 085 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.24it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:00 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 1.663 | nll_loss 0.654 | ppl 1.57 | wps 32836.4 | wpb 537.5 | bsz 16.7 | num_updates 3740 | best_loss 1.627\n",
            "2022-11-08 08:22:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint85.pt (epoch 85 @ 3740 updates, score 1.663) (writing took 0.40475717900000063 seconds)\n",
            "2022-11-08 08:22:01 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)\n",
            "2022-11-08 08:22:01 | INFO | train | epoch 085 | loss 1.314 | nll_loss 0.362 | ppl 1.29 | wps 6975.8 | ups 14.16 | wpb 492.6 | bsz 15.9 | num_updates 3740 | lr 0.000935006 | gnorm 0.975 | clip 100 | train_wall 2 | wall 272\n",
            "epoch 086:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:01 | INFO | fairseq.trainer | begin training epoch 86\n",
            "epoch 086:  95% 42/44 [00:02<00:00, 19.06it/s]2022-11-08 08:22:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 086 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 086 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.69it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:03 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 1.622 | nll_loss 0.623 | ppl 1.54 | wps 32799 | wpb 537.5 | bsz 16.7 | num_updates 3784 | best_loss 1.622\n",
            "2022-11-08 08:22:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint86.pt (epoch 86 @ 3784 updates, score 1.622) (writing took 0.5574680199999875 seconds)\n",
            "2022-11-08 08:22:04 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)\n",
            "2022-11-08 08:22:04 | INFO | train | epoch 086 | loss 1.321 | nll_loss 0.37 | ppl 1.29 | wps 6817.1 | ups 13.84 | wpb 492.6 | bsz 15.9 | num_updates 3784 | lr 0.000946005 | gnorm 0.934 | clip 100 | train_wall 2 | wall 275\n",
            "epoch 087:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:04 | INFO | fairseq.trainer | begin training epoch 87\n",
            "epoch 087:  95% 42/44 [00:02<00:00, 19.35it/s, loss=1.316, nll_loss=0.366, ppl=1.29, wps=7246.7, ups=14.46, wpb=501.3, bsz=15.9, num_updates=3800, lr=0.000950005, gnorm=0.935, clip=100, train_wall=5, wall=276]2022-11-08 08:22:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 087 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 087 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.11it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:07 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 1.612 | nll_loss 0.597 | ppl 1.51 | wps 35577 | wpb 537.5 | bsz 16.7 | num_updates 3828 | best_loss 1.612\n",
            "2022-11-08 08:22:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint87.pt (epoch 87 @ 3828 updates, score 1.612) (writing took 0.5697381619999646 seconds)\n",
            "2022-11-08 08:22:07 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)\n",
            "2022-11-08 08:22:07 | INFO | train | epoch 087 | loss 1.329 | nll_loss 0.383 | ppl 1.3 | wps 6708.7 | ups 13.62 | wpb 492.6 | bsz 15.9 | num_updates 3828 | lr 0.000957004 | gnorm 0.927 | clip 100 | train_wall 2 | wall 278\n",
            "epoch 088:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:07 | INFO | fairseq.trainer | begin training epoch 88\n",
            "epoch 088:  98% 43/44 [00:02<00:00, 20.21it/s]2022-11-08 08:22:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 088 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 088 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.82it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:10 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 1.618 | nll_loss 0.62 | ppl 1.54 | wps 32750.3 | wpb 537.5 | bsz 16.7 | num_updates 3872 | best_loss 1.612\n",
            "2022-11-08 08:22:10 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint88.pt (epoch 88 @ 3872 updates, score 1.618) (writing took 0.4388377359999822 seconds)\n",
            "2022-11-08 08:22:10 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)\n",
            "2022-11-08 08:22:10 | INFO | train | epoch 088 | loss 1.336 | nll_loss 0.388 | ppl 1.31 | wps 6937.2 | ups 14.08 | wpb 492.6 | bsz 15.9 | num_updates 3872 | lr 0.000968003 | gnorm 0.944 | clip 100 | train_wall 2 | wall 281\n",
            "epoch 089:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:10 | INFO | fairseq.trainer | begin training epoch 89\n",
            "epoch 089:  93% 41/44 [00:02<00:00, 19.66it/s, loss=1.341, nll_loss=0.394, ppl=1.31, wps=6927.7, ups=14.38, wpb=481.8, bsz=15.9, num_updates=3900, lr=0.000975002, gnorm=1.005, clip=100, train_wall=5, wall=283]2022-11-08 08:22:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 089 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 089 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.77it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:13 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 1.616 | nll_loss 0.614 | ppl 1.53 | wps 35782.6 | wpb 537.5 | bsz 16.7 | num_updates 3916 | best_loss 1.612\n",
            "2022-11-08 08:22:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint89.pt (epoch 89 @ 3916 updates, score 1.616) (writing took 0.4247847680000518 seconds)\n",
            "2022-11-08 08:22:13 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)\n",
            "2022-11-08 08:22:13 | INFO | train | epoch 089 | loss 1.325 | nll_loss 0.38 | ppl 1.3 | wps 7209.4 | ups 14.64 | wpb 492.6 | bsz 15.9 | num_updates 3916 | lr 0.000979002 | gnorm 1.047 | clip 100 | train_wall 2 | wall 284\n",
            "epoch 090:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:13 | INFO | fairseq.trainer | begin training epoch 90\n",
            "epoch 090:  98% 43/44 [00:02<00:00, 19.91it/s]2022-11-08 08:22:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 090 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 090 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.94it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:16 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 1.612 | nll_loss 0.6 | ppl 1.52 | wps 31380.9 | wpb 537.5 | bsz 16.7 | num_updates 3960 | best_loss 1.612\n",
            "2022-11-08 08:22:16 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint90.pt (epoch 90 @ 3960 updates, score 1.612) (writing took 0.574512545999994 seconds)\n",
            "2022-11-08 08:22:17 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)\n",
            "2022-11-08 08:22:17 | INFO | train | epoch 090 | loss 1.325 | nll_loss 0.376 | ppl 1.3 | wps 6877.6 | ups 13.96 | wpb 492.6 | bsz 15.9 | num_updates 3960 | lr 0.000990001 | gnorm 0.859 | clip 100 | train_wall 2 | wall 287\n",
            "epoch 091:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:17 | INFO | fairseq.trainer | begin training epoch 91\n",
            "epoch 091:  95% 42/44 [00:02<00:00, 19.38it/s, loss=1.312, nll_loss=0.364, ppl=1.29, wps=7308.6, ups=14.73, wpb=496.3, bsz=15.9, num_updates=4000, lr=0.001, gnorm=0.883, clip=100, train_wall=5, wall=290]2022-11-08 08:22:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 091 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 091 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.35it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:19 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 1.604 | nll_loss 0.6 | ppl 1.52 | wps 30851.3 | wpb 537.5 | bsz 16.7 | num_updates 4004 | best_loss 1.604\n",
            "2022-11-08 08:22:19 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint91.pt (epoch 91 @ 4004 updates, score 1.604) (writing took 0.6108515999999895 seconds)\n",
            "2022-11-08 08:22:20 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)\n",
            "2022-11-08 08:22:20 | INFO | train | epoch 091 | loss 1.31 | nll_loss 0.362 | ppl 1.29 | wps 6733.3 | ups 13.67 | wpb 492.6 | bsz 15.9 | num_updates 4004 | lr 0.0009995 | gnorm 0.923 | clip 100 | train_wall 2 | wall 291\n",
            "epoch 092:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:20 | INFO | fairseq.trainer | begin training epoch 92\n",
            "epoch 092:  98% 43/44 [00:02<00:00, 20.18it/s]2022-11-08 08:22:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 092 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 092 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.85it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:22 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 1.648 | nll_loss 0.642 | ppl 1.56 | wps 30888.3 | wpb 537.5 | bsz 16.7 | num_updates 4048 | best_loss 1.604\n",
            "2022-11-08 08:22:22 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint92.pt (epoch 92 @ 4048 updates, score 1.648) (writing took 0.4442130010000369 seconds)\n",
            "2022-11-08 08:22:23 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)\n",
            "2022-11-08 08:22:23 | INFO | train | epoch 092 | loss 1.304 | nll_loss 0.352 | ppl 1.28 | wps 7042.2 | ups 14.3 | wpb 492.6 | bsz 15.9 | num_updates 4048 | lr 0.000994053 | gnorm 0.988 | clip 100 | train_wall 2 | wall 294\n",
            "epoch 093:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:23 | INFO | fairseq.trainer | begin training epoch 93\n",
            "epoch 093:  95% 42/44 [00:02<00:00, 19.89it/s]2022-11-08 08:22:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 093 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 093 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.56it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:25 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 1.677 | nll_loss 0.676 | ppl 1.6 | wps 36432.2 | wpb 537.5 | bsz 16.7 | num_updates 4092 | best_loss 1.604\n",
            "2022-11-08 08:22:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint93.pt (epoch 93 @ 4092 updates, score 1.677) (writing took 0.426562663000027 seconds)\n",
            "2022-11-08 08:22:26 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)\n",
            "2022-11-08 08:22:26 | INFO | train | epoch 093 | loss 1.308 | nll_loss 0.36 | ppl 1.28 | wps 7226.3 | ups 14.67 | wpb 492.6 | bsz 15.9 | num_updates 4092 | lr 0.000988695 | gnorm 0.889 | clip 100 | train_wall 2 | wall 297\n",
            "epoch 094:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:26 | INFO | fairseq.trainer | begin training epoch 94\n",
            "epoch 094:  98% 43/44 [00:02<00:00, 19.63it/s, loss=1.307, nll_loss=0.357, ppl=1.28, wps=6370.8, ups=13.14, wpb=484.9, bsz=15.9, num_updates=4100, lr=0.00098773, gnorm=0.972, clip=100, train_wall=5, wall=297]2022-11-08 08:22:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 094 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 094 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.82it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:28 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 1.601 | nll_loss 0.596 | ppl 1.51 | wps 34461.7 | wpb 537.5 | bsz 16.7 | num_updates 4136 | best_loss 1.601\n",
            "2022-11-08 08:22:28 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint94.pt (epoch 94 @ 4136 updates, score 1.601) (writing took 0.5784729399999833 seconds)\n",
            "2022-11-08 08:22:29 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)\n",
            "2022-11-08 08:22:29 | INFO | train | epoch 094 | loss 1.315 | nll_loss 0.366 | ppl 1.29 | wps 6783.2 | ups 13.77 | wpb 492.6 | bsz 15.9 | num_updates 4136 | lr 0.000983422 | gnorm 0.928 | clip 100 | train_wall 2 | wall 300\n",
            "epoch 095:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:29 | INFO | fairseq.trainer | begin training epoch 95\n",
            "epoch 095:  93% 41/44 [00:02<00:00, 19.03it/s]2022-11-08 08:22:32 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 095 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 095 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.82it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:32 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 1.596 | nll_loss 0.589 | ppl 1.5 | wps 31571 | wpb 537.5 | bsz 16.7 | num_updates 4180 | best_loss 1.596\n",
            "2022-11-08 08:22:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint95.pt (epoch 95 @ 4180 updates, score 1.596) (writing took 0.5468090679999591 seconds)\n",
            "2022-11-08 08:22:32 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)\n",
            "2022-11-08 08:22:32 | INFO | train | epoch 095 | loss 1.3 | nll_loss 0.352 | ppl 1.28 | wps 6691.6 | ups 13.58 | wpb 492.6 | bsz 15.9 | num_updates 4180 | lr 0.000978232 | gnorm 0.926 | clip 100 | train_wall 2 | wall 303\n",
            "epoch 096:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:32 | INFO | fairseq.trainer | begin training epoch 96\n",
            "epoch 096:  93% 41/44 [00:02<00:00, 19.40it/s, loss=1.301, nll_loss=0.352, ppl=1.28, wps=7002.1, ups=14.05, wpb=498.5, bsz=15.9, num_updates=4200, lr=0.0009759, gnorm=0.894, clip=100, train_wall=5, wall=304]2022-11-08 08:22:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 096 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 096 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.89it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:35 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 1.584 | nll_loss 0.571 | ppl 1.49 | wps 30292.7 | wpb 537.5 | bsz 16.7 | num_updates 4224 | best_loss 1.584\n",
            "2022-11-08 08:22:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint96.pt (epoch 96 @ 4224 updates, score 1.584) (writing took 0.5681678870000155 seconds)\n",
            "2022-11-08 08:22:35 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)\n",
            "2022-11-08 08:22:35 | INFO | train | epoch 096 | loss 1.294 | nll_loss 0.346 | ppl 1.27 | wps 6759.9 | ups 13.72 | wpb 492.6 | bsz 15.9 | num_updates 4224 | lr 0.000973124 | gnorm 0.95 | clip 100 | train_wall 2 | wall 306\n",
            "epoch 097:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:35 | INFO | fairseq.trainer | begin training epoch 97\n",
            "epoch 097:  98% 43/44 [00:02<00:00, 18.99it/s]2022-11-08 08:22:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 097 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 097 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 17.61it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:38 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 1.603 | nll_loss 0.606 | ppl 1.52 | wps 28014 | wpb 537.5 | bsz 16.7 | num_updates 4268 | best_loss 1.584\n",
            "2022-11-08 08:22:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint97.pt (epoch 97 @ 4268 updates, score 1.603) (writing took 0.41413090999998303 seconds)\n",
            "2022-11-08 08:22:39 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)\n",
            "2022-11-08 08:22:39 | INFO | train | epoch 097 | loss 1.295 | nll_loss 0.346 | ppl 1.27 | wps 6975.7 | ups 14.16 | wpb 492.6 | bsz 15.9 | num_updates 4268 | lr 0.000968095 | gnorm 0.857 | clip 100 | train_wall 2 | wall 309\n",
            "epoch 098:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:39 | INFO | fairseq.trainer | begin training epoch 98\n",
            "epoch 098:  98% 43/44 [00:02<00:00, 18.82it/s, loss=1.287, nll_loss=0.337, ppl=1.26, wps=7049.7, ups=14.42, wpb=489, bsz=15.9, num_updates=4300, lr=0.000964486, gnorm=0.895, clip=100, train_wall=5, wall=311]2022-11-08 08:22:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 098 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 098 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.98it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:41 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 1.588 | nll_loss 0.576 | ppl 1.49 | wps 29047 | wpb 537.5 | bsz 16.7 | num_updates 4312 | best_loss 1.584\n",
            "2022-11-08 08:22:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint98.pt (epoch 98 @ 4312 updates, score 1.588) (writing took 0.4127122290000216 seconds)\n",
            "2022-11-08 08:22:42 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)\n",
            "2022-11-08 08:22:42 | INFO | train | epoch 098 | loss 1.293 | nll_loss 0.343 | ppl 1.27 | wps 7061.2 | ups 14.33 | wpb 492.6 | bsz 15.9 | num_updates 4312 | lr 0.000963143 | gnorm 0.901 | clip 100 | train_wall 2 | wall 312\n",
            "epoch 099:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:42 | INFO | fairseq.trainer | begin training epoch 99\n",
            "epoch 099:  95% 42/44 [00:02<00:00, 19.93it/s]2022-11-08 08:22:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 099 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 099 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.59it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:44 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 1.605 | nll_loss 0.601 | ppl 1.52 | wps 37616.5 | wpb 537.5 | bsz 16.7 | num_updates 4356 | best_loss 1.584\n",
            "2022-11-08 08:22:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint99.pt (epoch 99 @ 4356 updates, score 1.605) (writing took 0.40326541399997495 seconds)\n",
            "2022-11-08 08:22:45 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)\n",
            "2022-11-08 08:22:45 | INFO | train | epoch 099 | loss 1.28 | nll_loss 0.328 | ppl 1.26 | wps 7172.2 | ups 14.56 | wpb 492.6 | bsz 15.9 | num_updates 4356 | lr 0.000958266 | gnorm 0.798 | clip 100 | train_wall 2 | wall 315\n",
            "epoch 100:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:45 | INFO | fairseq.trainer | begin training epoch 100\n",
            "epoch 100:  95% 42/44 [00:02<00:00, 20.42it/s]2022-11-08 08:22:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 100 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 100 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.40it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:47 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 1.589 | nll_loss 0.582 | ppl 1.5 | wps 34174 | wpb 537.5 | bsz 16.7 | num_updates 4400 | best_loss 1.584\n",
            "2022-11-08 08:22:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint100.pt (epoch 100 @ 4400 updates, score 1.589) (writing took 0.4169739239999899 seconds)\n",
            "2022-11-08 08:22:48 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)\n",
            "2022-11-08 08:22:48 | INFO | train | epoch 100 | loss 1.276 | nll_loss 0.324 | ppl 1.25 | wps 7225.6 | ups 14.67 | wpb 492.6 | bsz 15.9 | num_updates 4400 | lr 0.000953463 | gnorm 0.835 | clip 100 | train_wall 2 | wall 318\n",
            "epoch 101:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:48 | INFO | fairseq.trainer | begin training epoch 101\n",
            "epoch 101:  93% 41/44 [00:02<00:00, 19.72it/s]2022-11-08 08:22:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 101 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 101 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.93it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:50 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 1.599 | nll_loss 0.597 | ppl 1.51 | wps 34150.1 | wpb 537.5 | bsz 16.7 | num_updates 4444 | best_loss 1.584\n",
            "2022-11-08 08:22:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint101.pt (epoch 101 @ 4444 updates, score 1.599) (writing took 0.404788190999966 seconds)\n",
            "2022-11-08 08:22:51 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)\n",
            "2022-11-08 08:22:51 | INFO | train | epoch 101 | loss 1.279 | nll_loss 0.329 | ppl 1.26 | wps 7183 | ups 14.58 | wpb 492.6 | bsz 15.9 | num_updates 4444 | lr 0.000948731 | gnorm 0.853 | clip 100 | train_wall 2 | wall 321\n",
            "epoch 102:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:51 | INFO | fairseq.trainer | begin training epoch 102\n",
            "epoch 102:  93% 41/44 [00:02<00:00, 20.14it/s]2022-11-08 08:22:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 102 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 102 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.54it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:53 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 1.591 | nll_loss 0.588 | ppl 1.5 | wps 35657.4 | wpb 537.5 | bsz 16.7 | num_updates 4488 | best_loss 1.584\n",
            "2022-11-08 08:22:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint102.pt (epoch 102 @ 4488 updates, score 1.591) (writing took 0.4368211620000011 seconds)\n",
            "2022-11-08 08:22:54 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)\n",
            "2022-11-08 08:22:54 | INFO | train | epoch 102 | loss 1.278 | nll_loss 0.327 | ppl 1.25 | wps 7140.1 | ups 14.5 | wpb 492.6 | bsz 15.9 | num_updates 4488 | lr 0.000944069 | gnorm 0.92 | clip 100 | train_wall 2 | wall 325\n",
            "epoch 103:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:54 | INFO | fairseq.trainer | begin training epoch 103\n",
            "epoch 103:  98% 43/44 [00:02<00:00, 19.80it/s, loss=1.272, nll_loss=0.321, ppl=1.25, wps=6581.2, ups=13.54, wpb=486.1, bsz=15.9, num_updates=4500, lr=0.000942809, gnorm=0.869, clip=100, train_wall=5, wall=325]2022-11-08 08:22:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 103 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 103 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.65it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:56 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 1.591 | nll_loss 0.584 | ppl 1.5 | wps 35474.8 | wpb 537.5 | bsz 16.7 | num_updates 4532 | best_loss 1.584\n",
            "2022-11-08 08:22:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:22:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint103.pt (epoch 103 @ 4532 updates, score 1.591) (writing took 0.41678264700004775 seconds)\n",
            "2022-11-08 08:22:57 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)\n",
            "2022-11-08 08:22:57 | INFO | train | epoch 103 | loss 1.271 | nll_loss 0.321 | ppl 1.25 | wps 7233.3 | ups 14.68 | wpb 492.6 | bsz 15.9 | num_updates 4532 | lr 0.000939475 | gnorm 0.798 | clip 100 | train_wall 2 | wall 328\n",
            "epoch 104:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:22:57 | INFO | fairseq.trainer | begin training epoch 104\n",
            "epoch 104:  95% 42/44 [00:02<00:00, 20.15it/s]2022-11-08 08:22:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 104 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 104 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.61it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:22:59 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 1.564 | nll_loss 0.558 | ppl 1.47 | wps 31154.4 | wpb 537.5 | bsz 16.7 | num_updates 4576 | best_loss 1.564\n",
            "2022-11-08 08:22:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint104.pt (epoch 104 @ 4576 updates, score 1.564) (writing took 0.5713106620000303 seconds)\n",
            "2022-11-08 08:23:00 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)\n",
            "2022-11-08 08:23:00 | INFO | train | epoch 104 | loss 1.277 | nll_loss 0.328 | ppl 1.26 | wps 6862.7 | ups 13.93 | wpb 492.6 | bsz 15.9 | num_updates 4576 | lr 0.000934947 | gnorm 0.814 | clip 100 | train_wall 2 | wall 331\n",
            "epoch 105:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:00 | INFO | fairseq.trainer | begin training epoch 105\n",
            "epoch 105:  98% 43/44 [00:02<00:00, 19.91it/s, loss=1.283, nll_loss=0.335, ppl=1.26, wps=7329.5, ups=14.64, wpb=500.8, bsz=15.9, num_updates=4600, lr=0.000932505, gnorm=0.819, clip=100, train_wall=5, wall=332]2022-11-08 08:23:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 105 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 105 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.93it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:03 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 1.596 | nll_loss 0.583 | ppl 1.5 | wps 29828 | wpb 537.5 | bsz 16.7 | num_updates 4620 | best_loss 1.564\n",
            "2022-11-08 08:23:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint105.pt (epoch 105 @ 4620 updates, score 1.596) (writing took 0.41546150299996043 seconds)\n",
            "2022-11-08 08:23:03 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)\n",
            "2022-11-08 08:23:03 | INFO | train | epoch 105 | loss 1.266 | nll_loss 0.314 | ppl 1.24 | wps 7065.8 | ups 14.34 | wpb 492.6 | bsz 15.9 | num_updates 4620 | lr 0.000930484 | gnorm 0.841 | clip 100 | train_wall 2 | wall 334\n",
            "epoch 106:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:03 | INFO | fairseq.trainer | begin training epoch 106\n",
            "epoch 106:  98% 43/44 [00:02<00:00, 19.37it/s]2022-11-08 08:23:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 106 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 106 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.80it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:06 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 1.592 | nll_loss 0.578 | ppl 1.49 | wps 36388.7 | wpb 537.5 | bsz 16.7 | num_updates 4664 | best_loss 1.564\n",
            "2022-11-08 08:23:06 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint106.pt (epoch 106 @ 4664 updates, score 1.592) (writing took 0.4232588739999983 seconds)\n",
            "2022-11-08 08:23:06 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)\n",
            "2022-11-08 08:23:06 | INFO | train | epoch 106 | loss 1.252 | nll_loss 0.299 | ppl 1.23 | wps 6989.2 | ups 14.19 | wpb 492.6 | bsz 15.9 | num_updates 4664 | lr 0.000926085 | gnorm 0.721 | clip 100 | train_wall 2 | wall 337\n",
            "epoch 107:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:06 | INFO | fairseq.trainer | begin training epoch 107\n",
            "epoch 107:  98% 43/44 [00:02<00:00, 19.32it/s, loss=1.255, nll_loss=0.302, ppl=1.23, wps=7207.4, ups=14.6, wpb=493.6, bsz=15.9, num_updates=4700, lr=0.000922531, gnorm=0.766, clip=100, train_wall=5, wall=339]2022-11-08 08:23:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 107 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 107 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.91it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:09 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 1.577 | nll_loss 0.573 | ppl 1.49 | wps 36571.8 | wpb 537.5 | bsz 16.7 | num_updates 4708 | best_loss 1.564\n",
            "2022-11-08 08:23:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint107.pt (epoch 107 @ 4708 updates, score 1.577) (writing took 0.40202362800005176 seconds)\n",
            "2022-11-08 08:23:09 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)\n",
            "2022-11-08 08:23:09 | INFO | train | epoch 107 | loss 1.261 | nll_loss 0.31 | ppl 1.24 | wps 7040.3 | ups 14.29 | wpb 492.6 | bsz 15.9 | num_updates 4708 | lr 0.000921747 | gnorm 0.805 | clip 100 | train_wall 2 | wall 340\n",
            "epoch 108:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:09 | INFO | fairseq.trainer | begin training epoch 108\n",
            "epoch 108:  98% 43/44 [00:02<00:00, 19.45it/s]2022-11-08 08:23:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 108 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 108 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.66it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:12 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 1.592 | nll_loss 0.598 | ppl 1.51 | wps 31465.6 | wpb 537.5 | bsz 16.7 | num_updates 4752 | best_loss 1.564\n",
            "2022-11-08 08:23:12 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint108.pt (epoch 108 @ 4752 updates, score 1.592) (writing took 0.4211596569999756 seconds)\n",
            "2022-11-08 08:23:12 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)\n",
            "2022-11-08 08:23:12 | INFO | train | epoch 108 | loss 1.256 | nll_loss 0.304 | ppl 1.23 | wps 7186.7 | ups 14.59 | wpb 492.6 | bsz 15.9 | num_updates 4752 | lr 0.00091747 | gnorm 0.882 | clip 100 | train_wall 2 | wall 343\n",
            "epoch 109:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:12 | INFO | fairseq.trainer | begin training epoch 109\n",
            "epoch 109:  93% 41/44 [00:02<00:00, 19.47it/s]2022-11-08 08:23:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 109 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 109 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.39it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:15 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 1.579 | nll_loss 0.568 | ppl 1.48 | wps 33409.8 | wpb 537.5 | bsz 16.7 | num_updates 4796 | best_loss 1.564\n",
            "2022-11-08 08:23:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint109.pt (epoch 109 @ 4796 updates, score 1.579) (writing took 0.37747066200000745 seconds)\n",
            "2022-11-08 08:23:15 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)\n",
            "2022-11-08 08:23:15 | INFO | train | epoch 109 | loss 1.251 | nll_loss 0.3 | ppl 1.23 | wps 7244.5 | ups 14.71 | wpb 492.6 | bsz 15.9 | num_updates 4796 | lr 0.000913252 | gnorm 0.851 | clip 100 | train_wall 2 | wall 346\n",
            "epoch 110:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:15 | INFO | fairseq.trainer | begin training epoch 110\n",
            "epoch 110:  95% 42/44 [00:02<00:00, 18.98it/s, loss=1.25, nll_loss=0.298, ppl=1.23, wps=6683.6, ups=13.68, wpb=488.5, bsz=15.9, num_updates=4800, lr=0.000912871, gnorm=0.881, clip=100, train_wall=5, wall=346]2022-11-08 08:23:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 110 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 110 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.18it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:18 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 1.59 | nll_loss 0.583 | ppl 1.5 | wps 33349.9 | wpb 537.5 | bsz 16.7 | num_updates 4840 | best_loss 1.564\n",
            "2022-11-08 08:23:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint110.pt (epoch 110 @ 4840 updates, score 1.59) (writing took 0.4546619839999835 seconds)\n",
            "2022-11-08 08:23:18 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)\n",
            "2022-11-08 08:23:18 | INFO | train | epoch 110 | loss 1.241 | nll_loss 0.286 | ppl 1.22 | wps 6977.2 | ups 14.16 | wpb 492.6 | bsz 15.9 | num_updates 4840 | lr 0.000909091 | gnorm 0.794 | clip 100 | train_wall 2 | wall 349\n",
            "epoch 111:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:18 | INFO | fairseq.trainer | begin training epoch 111\n",
            "epoch 111:  93% 41/44 [00:02<00:00, 19.45it/s]2022-11-08 08:23:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 111 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 111 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.51it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:21 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 1.61 | nll_loss 0.606 | ppl 1.52 | wps 32000.1 | wpb 537.5 | bsz 16.7 | num_updates 4884 | best_loss 1.564\n",
            "2022-11-08 08:23:21 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint111.pt (epoch 111 @ 4884 updates, score 1.61) (writing took 0.41554031999999097 seconds)\n",
            "2022-11-08 08:23:21 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)\n",
            "2022-11-08 08:23:21 | INFO | train | epoch 111 | loss 1.254 | nll_loss 0.304 | ppl 1.23 | wps 7111.1 | ups 14.44 | wpb 492.6 | bsz 15.9 | num_updates 4884 | lr 0.000904987 | gnorm 0.943 | clip 100 | train_wall 2 | wall 352\n",
            "epoch 112:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:21 | INFO | fairseq.trainer | begin training epoch 112\n",
            "epoch 112:  98% 43/44 [00:02<00:00, 19.66it/s, loss=1.254, nll_loss=0.303, ppl=1.23, wps=7282.5, ups=14.69, wpb=495.8, bsz=15.9, num_updates=4900, lr=0.000903508, gnorm=0.842, clip=100, train_wall=5, wall=353]2022-11-08 08:23:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 112 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 112 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.50it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:24 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 1.565 | nll_loss 0.566 | ppl 1.48 | wps 37651.3 | wpb 537.5 | bsz 16.7 | num_updates 4928 | best_loss 1.564\n",
            "2022-11-08 08:23:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint112.pt (epoch 112 @ 4928 updates, score 1.565) (writing took 0.4440213859999176 seconds)\n",
            "2022-11-08 08:23:24 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)\n",
            "2022-11-08 08:23:24 | INFO | train | epoch 112 | loss 1.248 | nll_loss 0.297 | ppl 1.23 | wps 6994.1 | ups 14.2 | wpb 492.6 | bsz 15.9 | num_updates 4928 | lr 0.000900937 | gnorm 0.827 | clip 100 | train_wall 2 | wall 355\n",
            "epoch 113:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:24 | INFO | fairseq.trainer | begin training epoch 113\n",
            "epoch 113:  95% 42/44 [00:02<00:00, 19.23it/s]2022-11-08 08:23:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 113 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 113 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.58it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:27 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 1.558 | nll_loss 0.551 | ppl 1.46 | wps 32281.9 | wpb 537.5 | bsz 16.7 | num_updates 4972 | best_loss 1.558\n",
            "2022-11-08 08:23:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint113.pt (epoch 113 @ 4972 updates, score 1.558) (writing took 0.5774484410000014 seconds)\n",
            "2022-11-08 08:23:28 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)\n",
            "2022-11-08 08:23:28 | INFO | train | epoch 113 | loss 1.23 | nll_loss 0.275 | ppl 1.21 | wps 6768.1 | ups 13.74 | wpb 492.6 | bsz 15.9 | num_updates 4972 | lr 0.000896942 | gnorm 0.777 | clip 100 | train_wall 2 | wall 358\n",
            "epoch 114:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:28 | INFO | fairseq.trainer | begin training epoch 114\n",
            "epoch 114:  95% 42/44 [00:02<00:00, 20.29it/s, loss=1.235, nll_loss=0.281, ppl=1.22, wps=7143.5, ups=14.37, wpb=496.9, bsz=15.9, num_updates=5000, lr=0.000894427, gnorm=0.804, clip=100, train_wall=5, wall=360]2022-11-08 08:23:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 114 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 114 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.38it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:30 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 1.559 | nll_loss 0.547 | ppl 1.46 | wps 34068.9 | wpb 537.5 | bsz 16.7 | num_updates 5016 | best_loss 1.558\n",
            "2022-11-08 08:23:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint114.pt (epoch 114 @ 5016 updates, score 1.559) (writing took 0.43780510700003106 seconds)\n",
            "2022-11-08 08:23:31 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)\n",
            "2022-11-08 08:23:31 | INFO | train | epoch 114 | loss 1.234 | nll_loss 0.28 | ppl 1.21 | wps 7089.3 | ups 14.39 | wpb 492.6 | bsz 15.9 | num_updates 5016 | lr 0.000893 | gnorm 0.848 | clip 100 | train_wall 2 | wall 361\n",
            "epoch 115:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:31 | INFO | fairseq.trainer | begin training epoch 115\n",
            "epoch 115:  98% 43/44 [00:02<00:00, 19.36it/s]2022-11-08 08:23:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 115 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 115 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.13it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:33 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 1.581 | nll_loss 0.58 | ppl 1.49 | wps 31934.5 | wpb 537.5 | bsz 16.7 | num_updates 5060 | best_loss 1.558\n",
            "2022-11-08 08:23:33 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint115.pt (epoch 115 @ 5060 updates, score 1.581) (writing took 0.41881629700003487 seconds)\n",
            "2022-11-08 08:23:34 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)\n",
            "2022-11-08 08:23:34 | INFO | train | epoch 115 | loss 1.231 | nll_loss 0.277 | ppl 1.21 | wps 7060.7 | ups 14.33 | wpb 492.6 | bsz 15.9 | num_updates 5060 | lr 0.000889108 | gnorm 0.759 | clip 100 | train_wall 2 | wall 365\n",
            "epoch 116:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:34 | INFO | fairseq.trainer | begin training epoch 116\n",
            "epoch 116:  95% 42/44 [00:02<00:00, 19.28it/s, loss=1.233, nll_loss=0.279, ppl=1.21, wps=7204.9, ups=14.75, wpb=488.4, bsz=15.9, num_updates=5100, lr=0.000885615, gnorm=0.852, clip=100, train_wall=5, wall=367]2022-11-08 08:23:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 116 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 116 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.76it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:36 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 1.565 | nll_loss 0.558 | ppl 1.47 | wps 37067.8 | wpb 537.5 | bsz 16.7 | num_updates 5104 | best_loss 1.558\n",
            "2022-11-08 08:23:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint116.pt (epoch 116 @ 5104 updates, score 1.565) (writing took 0.40962358000001586 seconds)\n",
            "2022-11-08 08:23:37 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)\n",
            "2022-11-08 08:23:37 | INFO | train | epoch 116 | loss 1.239 | nll_loss 0.288 | ppl 1.22 | wps 7097.5 | ups 14.41 | wpb 492.6 | bsz 15.9 | num_updates 5104 | lr 0.000885268 | gnorm 0.895 | clip 100 | train_wall 2 | wall 368\n",
            "epoch 117:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:37 | INFO | fairseq.trainer | begin training epoch 117\n",
            "epoch 117:  98% 43/44 [00:02<00:00, 20.24it/s]2022-11-08 08:23:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 117 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 117 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.64it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:39 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 1.574 | nll_loss 0.56 | ppl 1.47 | wps 40194.1 | wpb 537.5 | bsz 16.7 | num_updates 5148 | best_loss 1.558\n",
            "2022-11-08 08:23:39 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint117.pt (epoch 117 @ 5148 updates, score 1.574) (writing took 0.3748380490000045 seconds)\n",
            "2022-11-08 08:23:40 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)\n",
            "2022-11-08 08:23:40 | INFO | train | epoch 117 | loss 1.229 | nll_loss 0.277 | ppl 1.21 | wps 7235.7 | ups 14.69 | wpb 492.6 | bsz 15.9 | num_updates 5148 | lr 0.000881476 | gnorm 0.861 | clip 100 | train_wall 2 | wall 371\n",
            "epoch 118:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:40 | INFO | fairseq.trainer | begin training epoch 118\n",
            "epoch 118:  98% 43/44 [00:02<00:00, 18.99it/s]2022-11-08 08:23:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 118 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 118 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.94it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:42 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 1.566 | nll_loss 0.556 | ppl 1.47 | wps 30586.6 | wpb 537.5 | bsz 16.7 | num_updates 5192 | best_loss 1.558\n",
            "2022-11-08 08:23:42 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint118.pt (epoch 118 @ 5192 updates, score 1.566) (writing took 0.36405931899992083 seconds)\n",
            "2022-11-08 08:23:43 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)\n",
            "2022-11-08 08:23:43 | INFO | train | epoch 118 | loss 1.227 | nll_loss 0.275 | ppl 1.21 | wps 7185.5 | ups 14.59 | wpb 492.6 | bsz 15.9 | num_updates 5192 | lr 0.000877733 | gnorm 0.74 | clip 100 | train_wall 2 | wall 374\n",
            "epoch 119:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:43 | INFO | fairseq.trainer | begin training epoch 119\n",
            "epoch 119:  93% 41/44 [00:02<00:00, 19.33it/s, loss=1.223, nll_loss=0.27, ppl=1.21, wps=6640.2, ups=13.64, wpb=486.8, bsz=15.9, num_updates=5200, lr=0.000877058, gnorm=0.791, clip=100, train_wall=5, wall=374]2022-11-08 08:23:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 119 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 119 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.30it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:45 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 1.577 | nll_loss 0.564 | ppl 1.48 | wps 30856.1 | wpb 537.5 | bsz 16.7 | num_updates 5236 | best_loss 1.558\n",
            "2022-11-08 08:23:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint119.pt (epoch 119 @ 5236 updates, score 1.577) (writing took 0.3691654550000294 seconds)\n",
            "2022-11-08 08:23:46 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)\n",
            "2022-11-08 08:23:46 | INFO | train | epoch 119 | loss 1.227 | nll_loss 0.274 | ppl 1.21 | wps 7155.9 | ups 14.53 | wpb 492.6 | bsz 15.9 | num_updates 5236 | lr 0.000874038 | gnorm 0.792 | clip 100 | train_wall 2 | wall 377\n",
            "epoch 120:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:46 | INFO | fairseq.trainer | begin training epoch 120\n",
            "epoch 120:  98% 43/44 [00:02<00:00, 19.80it/s]2022-11-08 08:23:48 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 120 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 120 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.47it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:48 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 1.576 | nll_loss 0.565 | ppl 1.48 | wps 29799.9 | wpb 537.5 | bsz 16.7 | num_updates 5280 | best_loss 1.558\n",
            "2022-11-08 08:23:48 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint120.pt (epoch 120 @ 5280 updates, score 1.576) (writing took 0.3755951370000048 seconds)\n",
            "2022-11-08 08:23:49 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)\n",
            "2022-11-08 08:23:49 | INFO | train | epoch 120 | loss 1.223 | nll_loss 0.27 | ppl 1.21 | wps 7216.7 | ups 14.65 | wpb 492.6 | bsz 15.9 | num_updates 5280 | lr 0.000870388 | gnorm 0.641 | clip 100 | train_wall 2 | wall 380\n",
            "epoch 121:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:49 | INFO | fairseq.trainer | begin training epoch 121\n",
            "epoch 121:  93% 41/44 [00:02<00:00, 18.93it/s, loss=1.236, nll_loss=0.285, ppl=1.22, wps=7411.7, ups=15.01, wpb=493.8, bsz=15.9, num_updates=5300, lr=0.000868744, gnorm=0.718, clip=100, train_wall=5, wall=381]2022-11-08 08:23:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 121 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 121 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.46it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:51 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 1.592 | nll_loss 0.591 | ppl 1.51 | wps 36801.9 | wpb 537.5 | bsz 16.7 | num_updates 5324 | best_loss 1.558\n",
            "2022-11-08 08:23:51 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint121.pt (epoch 121 @ 5324 updates, score 1.592) (writing took 0.37368124500005706 seconds)\n",
            "2022-11-08 08:23:52 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)\n",
            "2022-11-08 08:23:52 | INFO | train | epoch 121 | loss 1.242 | nll_loss 0.291 | ppl 1.22 | wps 7272.6 | ups 14.76 | wpb 492.6 | bsz 15.9 | num_updates 5324 | lr 0.000866784 | gnorm 0.718 | clip 100 | train_wall 2 | wall 383\n",
            "epoch 122:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:52 | INFO | fairseq.trainer | begin training epoch 122\n",
            "epoch 122:  98% 43/44 [00:02<00:00, 18.99it/s]2022-11-08 08:23:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 122 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 122 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.68it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:54 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 1.559 | nll_loss 0.546 | ppl 1.46 | wps 31538.1 | wpb 537.5 | bsz 16.7 | num_updates 5368 | best_loss 1.558\n",
            "2022-11-08 08:23:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint122.pt (epoch 122 @ 5368 updates, score 1.559) (writing took 0.3688993399999845 seconds)\n",
            "2022-11-08 08:23:55 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)\n",
            "2022-11-08 08:23:55 | INFO | train | epoch 122 | loss 1.225 | nll_loss 0.274 | ppl 1.21 | wps 7157.5 | ups 14.53 | wpb 492.6 | bsz 15.9 | num_updates 5368 | lr 0.000863224 | gnorm 0.812 | clip 100 | train_wall 2 | wall 386\n",
            "epoch 123:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:55 | INFO | fairseq.trainer | begin training epoch 123\n",
            "epoch 123:  95% 42/44 [00:02<00:00, 19.60it/s, loss=1.214, nll_loss=0.26, ppl=1.2, wps=7409.9, ups=14.98, wpb=494.7, bsz=16, num_updates=5400, lr=0.000860663, gnorm=0.738, clip=100, train_wall=5, wall=387]2022-11-08 08:23:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 123 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 123 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.48it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:23:57 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 1.536 | nll_loss 0.517 | ppl 1.43 | wps 33990.1 | wpb 537.5 | bsz 16.7 | num_updates 5412 | best_loss 1.536\n",
            "2022-11-08 08:23:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:23:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint123.pt (epoch 123 @ 5412 updates, score 1.536) (writing took 0.507226750999962 seconds)\n",
            "2022-11-08 08:23:58 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)\n",
            "2022-11-08 08:23:58 | INFO | train | epoch 123 | loss 1.212 | nll_loss 0.258 | ppl 1.2 | wps 6883.4 | ups 13.97 | wpb 492.6 | bsz 15.9 | num_updates 5412 | lr 0.000859708 | gnorm 0.693 | clip 100 | train_wall 2 | wall 389\n",
            "epoch 124:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:23:58 | INFO | fairseq.trainer | begin training epoch 124\n",
            "epoch 124:  98% 43/44 [00:02<00:00, 19.99it/s]2022-11-08 08:24:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 124 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 124 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.47it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:01 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 1.572 | nll_loss 0.563 | ppl 1.48 | wps 30540.1 | wpb 537.5 | bsz 16.7 | num_updates 5456 | best_loss 1.536\n",
            "2022-11-08 08:24:01 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint124.pt (epoch 124 @ 5456 updates, score 1.572) (writing took 0.37629058400000304 seconds)\n",
            "2022-11-08 08:24:01 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)\n",
            "2022-11-08 08:24:01 | INFO | train | epoch 124 | loss 1.219 | nll_loss 0.266 | ppl 1.2 | wps 7230.8 | ups 14.68 | wpb 492.6 | bsz 15.9 | num_updates 5456 | lr 0.000856235 | gnorm 0.692 | clip 100 | train_wall 2 | wall 392\n",
            "epoch 125:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:01 | INFO | fairseq.trainer | begin training epoch 125\n",
            "epoch 125:  98% 43/44 [00:02<00:00, 19.74it/s]2022-11-08 08:24:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 125 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 125 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.64it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:04 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 1.577 | nll_loss 0.565 | ppl 1.48 | wps 35628.2 | wpb 537.5 | bsz 16.7 | num_updates 5500 | best_loss 1.536\n",
            "2022-11-08 08:24:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint125.pt (epoch 125 @ 5500 updates, score 1.577) (writing took 0.3728984470000114 seconds)\n",
            "2022-11-08 08:24:04 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)\n",
            "2022-11-08 08:24:04 | INFO | train | epoch 125 | loss 1.213 | nll_loss 0.26 | ppl 1.2 | wps 7307.1 | ups 14.83 | wpb 492.6 | bsz 15.9 | num_updates 5500 | lr 0.000852803 | gnorm 0.737 | clip 100 | train_wall 2 | wall 395\n",
            "epoch 126:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:04 | INFO | fairseq.trainer | begin training epoch 126\n",
            "epoch 126:  98% 43/44 [00:02<00:00, 20.35it/s]2022-11-08 08:24:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 126 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 126 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.98it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:07 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 1.552 | nll_loss 0.538 | ppl 1.45 | wps 31860.9 | wpb 537.5 | bsz 16.7 | num_updates 5544 | best_loss 1.536\n",
            "2022-11-08 08:24:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint126.pt (epoch 126 @ 5544 updates, score 1.552) (writing took 0.38593611600003896 seconds)\n",
            "2022-11-08 08:24:07 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)\n",
            "2022-11-08 08:24:07 | INFO | train | epoch 126 | loss 1.21 | nll_loss 0.256 | ppl 1.19 | wps 7169.1 | ups 14.55 | wpb 492.6 | bsz 15.9 | num_updates 5544 | lr 0.000849412 | gnorm 0.704 | clip 100 | train_wall 2 | wall 398\n",
            "epoch 127:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:07 | INFO | fairseq.trainer | begin training epoch 127\n",
            "epoch 127:  98% 43/44 [00:02<00:00, 19.74it/s]2022-11-08 08:24:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 127 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 127 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.79it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:10 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 1.544 | nll_loss 0.529 | ppl 1.44 | wps 31966.2 | wpb 537.5 | bsz 16.7 | num_updates 5588 | best_loss 1.536\n",
            "2022-11-08 08:24:10 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint127.pt (epoch 127 @ 5588 updates, score 1.544) (writing took 0.4057420770000135 seconds)\n",
            "2022-11-08 08:24:10 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)\n",
            "2022-11-08 08:24:10 | INFO | train | epoch 127 | loss 1.213 | nll_loss 0.261 | ppl 1.2 | wps 7065.6 | ups 14.34 | wpb 492.6 | bsz 15.9 | num_updates 5588 | lr 0.000846061 | gnorm 0.877 | clip 100 | train_wall 2 | wall 401\n",
            "epoch 128:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:10 | INFO | fairseq.trainer | begin training epoch 128\n",
            "epoch 128:  98% 43/44 [00:02<00:00, 19.88it/s, loss=1.215, nll_loss=0.263, ppl=1.2, wps=6634.6, ups=13.52, wpb=490.9, bsz=15.9, num_updates=5600, lr=0.000845154, gnorm=0.828, clip=100, train_wall=5, wall=402]2022-11-08 08:24:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 128 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 128 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 18.07it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:13 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 1.566 | nll_loss 0.555 | ppl 1.47 | wps 32210.2 | wpb 537.5 | bsz 16.7 | num_updates 5632 | best_loss 1.536\n",
            "2022-11-08 08:24:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint128.pt (epoch 128 @ 5632 updates, score 1.566) (writing took 0.4082701080000106 seconds)\n",
            "2022-11-08 08:24:13 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)\n",
            "2022-11-08 08:24:13 | INFO | train | epoch 128 | loss 1.21 | nll_loss 0.259 | ppl 1.2 | wps 7094.8 | ups 14.4 | wpb 492.6 | bsz 15.9 | num_updates 5632 | lr 0.00084275 | gnorm 0.873 | clip 100 | train_wall 2 | wall 404\n",
            "epoch 129:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:13 | INFO | fairseq.trainer | begin training epoch 129\n",
            "epoch 129:  95% 42/44 [00:02<00:00, 19.24it/s]2022-11-08 08:24:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 129 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 129 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.74it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:16 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 1.601 | nll_loss 0.597 | ppl 1.51 | wps 33522.2 | wpb 537.5 | bsz 16.7 | num_updates 5676 | best_loss 1.536\n",
            "2022-11-08 08:24:16 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint129.pt (epoch 129 @ 5676 updates, score 1.601) (writing took 0.42745914699992227 seconds)\n",
            "2022-11-08 08:24:16 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)\n",
            "2022-11-08 08:24:16 | INFO | train | epoch 129 | loss 1.215 | nll_loss 0.263 | ppl 1.2 | wps 7114.7 | ups 14.44 | wpb 492.6 | bsz 15.9 | num_updates 5676 | lr 0.000839477 | gnorm 0.7 | clip 100 | train_wall 2 | wall 407\n",
            "epoch 130:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:16 | INFO | fairseq.trainer | begin training epoch 130\n",
            "epoch 130:  95% 42/44 [00:02<00:00, 20.29it/s, loss=1.204, nll_loss=0.25, ppl=1.19, wps=7192.3, ups=14.82, wpb=485.4, bsz=16, num_updates=5700, lr=0.000837708, gnorm=0.717, clip=100, train_wall=5, wall=408]2022-11-08 08:24:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 130 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 130 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.42it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:19 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 1.57 | nll_loss 0.564 | ppl 1.48 | wps 29499.2 | wpb 537.5 | bsz 16.7 | num_updates 5720 | best_loss 1.536\n",
            "2022-11-08 08:24:19 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint130.pt (epoch 130 @ 5720 updates, score 1.57) (writing took 0.42539993900004447 seconds)\n",
            "2022-11-08 08:24:19 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)\n",
            "2022-11-08 08:24:19 | INFO | train | epoch 130 | loss 1.22 | nll_loss 0.267 | ppl 1.2 | wps 7123.5 | ups 14.46 | wpb 492.6 | bsz 15.9 | num_updates 5720 | lr 0.000836242 | gnorm 0.7 | clip 100 | train_wall 2 | wall 410\n",
            "epoch 131:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:19 | INFO | fairseq.trainer | begin training epoch 131\n",
            "epoch 131:  95% 42/44 [00:02<00:00, 20.04it/s]2022-11-08 08:24:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 131 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 131 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.84it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:22 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 1.557 | nll_loss 0.542 | ppl 1.46 | wps 30279.7 | wpb 537.5 | bsz 16.7 | num_updates 5764 | best_loss 1.536\n",
            "2022-11-08 08:24:22 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint131.pt (epoch 131 @ 5764 updates, score 1.557) (writing took 0.41177212299999155 seconds)\n",
            "2022-11-08 08:24:22 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)\n",
            "2022-11-08 08:24:22 | INFO | train | epoch 131 | loss 1.206 | nll_loss 0.254 | ppl 1.19 | wps 7245.1 | ups 14.71 | wpb 492.6 | bsz 15.9 | num_updates 5764 | lr 0.000833044 | gnorm 0.729 | clip 100 | train_wall 2 | wall 413\n",
            "epoch 132:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:22 | INFO | fairseq.trainer | begin training epoch 132\n",
            "epoch 132:  93% 41/44 [00:02<00:00, 20.01it/s, loss=1.215, nll_loss=0.264, ppl=1.2, wps=7633, ups=15.06, wpb=506.8, bsz=15.9, num_updates=5800, lr=0.000830455, gnorm=0.691, clip=100, train_wall=5, wall=415]2022-11-08 08:24:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 132 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 132 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.58it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:25 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 1.557 | nll_loss 0.545 | ppl 1.46 | wps 36278.7 | wpb 537.5 | bsz 16.7 | num_updates 5808 | best_loss 1.536\n",
            "2022-11-08 08:24:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint132.pt (epoch 132 @ 5808 updates, score 1.557) (writing took 0.42003431299997374 seconds)\n",
            "2022-11-08 08:24:25 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)\n",
            "2022-11-08 08:24:25 | INFO | train | epoch 132 | loss 1.2 | nll_loss 0.246 | ppl 1.19 | wps 7272.2 | ups 14.76 | wpb 492.6 | bsz 15.9 | num_updates 5808 | lr 0.000829883 | gnorm 0.601 | clip 100 | train_wall 2 | wall 416\n",
            "epoch 133:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:25 | INFO | fairseq.trainer | begin training epoch 133\n",
            "epoch 133:  93% 41/44 [00:02<00:00, 19.77it/s]2022-11-08 08:24:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 133 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 133 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.89it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:28 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 1.568 | nll_loss 0.55 | ppl 1.46 | wps 38030 | wpb 537.5 | bsz 16.7 | num_updates 5852 | best_loss 1.536\n",
            "2022-11-08 08:24:28 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint133.pt (epoch 133 @ 5852 updates, score 1.568) (writing took 0.4214752300000555 seconds)\n",
            "2022-11-08 08:24:28 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)\n",
            "2022-11-08 08:24:28 | INFO | train | epoch 133 | loss 1.202 | nll_loss 0.249 | ppl 1.19 | wps 7174.4 | ups 14.56 | wpb 492.6 | bsz 15.9 | num_updates 5852 | lr 0.000826757 | gnorm 0.789 | clip 100 | train_wall 2 | wall 419\n",
            "epoch 134:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:28 | INFO | fairseq.trainer | begin training epoch 134\n",
            "epoch 134:  98% 43/44 [00:02<00:00, 19.62it/s]2022-11-08 08:24:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 134 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 134 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.19it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:31 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 1.598 | nll_loss 0.594 | ppl 1.51 | wps 35331.6 | wpb 537.5 | bsz 16.7 | num_updates 5896 | best_loss 1.536\n",
            "2022-11-08 08:24:31 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint134.pt (epoch 134 @ 5896 updates, score 1.598) (writing took 0.41273914900000364 seconds)\n",
            "2022-11-08 08:24:31 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)\n",
            "2022-11-08 08:24:31 | INFO | train | epoch 134 | loss 1.199 | nll_loss 0.245 | ppl 1.19 | wps 7153.6 | ups 14.52 | wpb 492.6 | bsz 15.9 | num_updates 5896 | lr 0.000823666 | gnorm 0.716 | clip 100 | train_wall 2 | wall 422\n",
            "epoch 135:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:31 | INFO | fairseq.trainer | begin training epoch 135\n",
            "epoch 135:  98% 43/44 [00:02<00:00, 19.67it/s, loss=1.198, nll_loss=0.244, ppl=1.18, wps=6651, ups=13.65, wpb=487.3, bsz=15.9, num_updates=5900, lr=0.000823387, gnorm=0.731, clip=100, train_wall=5, wall=422]2022-11-08 08:24:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 135 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 135 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.79it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:34 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 1.566 | nll_loss 0.555 | ppl 1.47 | wps 37538.6 | wpb 537.5 | bsz 16.7 | num_updates 5940 | best_loss 1.536\n",
            "2022-11-08 08:24:34 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint135.pt (epoch 135 @ 5940 updates, score 1.566) (writing took 0.3922894390000238 seconds)\n",
            "2022-11-08 08:24:34 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)\n",
            "2022-11-08 08:24:34 | INFO | train | epoch 135 | loss 1.201 | nll_loss 0.248 | ppl 1.19 | wps 7202.4 | ups 14.62 | wpb 492.6 | bsz 15.9 | num_updates 5940 | lr 0.00082061 | gnorm 0.744 | clip 100 | train_wall 2 | wall 425\n",
            "epoch 136:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:34 | INFO | fairseq.trainer | begin training epoch 136\n",
            "epoch 136:  95% 42/44 [00:02<00:00, 19.54it/s]2022-11-08 08:24:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 136 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 136 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.74it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:37 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 1.59 | nll_loss 0.585 | ppl 1.5 | wps 28291.6 | wpb 537.5 | bsz 16.7 | num_updates 5984 | best_loss 1.536\n",
            "2022-11-08 08:24:37 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint136.pt (epoch 136 @ 5984 updates, score 1.59) (writing took 0.5395572820000325 seconds)\n",
            "2022-11-08 08:24:37 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)\n",
            "2022-11-08 08:24:37 | INFO | train | epoch 136 | loss 1.193 | nll_loss 0.238 | ppl 1.18 | wps 6781.5 | ups 13.77 | wpb 492.6 | bsz 15.9 | num_updates 5984 | lr 0.000817587 | gnorm 0.679 | clip 100 | train_wall 2 | wall 428\n",
            "epoch 137:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:37 | INFO | fairseq.trainer | begin training epoch 137\n",
            "epoch 137:  98% 43/44 [00:02<00:00, 19.28it/s, loss=1.201, nll_loss=0.248, ppl=1.19, wps=7157.8, ups=14.46, wpb=495.1, bsz=15.9, num_updates=6000, lr=0.000816497, gnorm=0.784, clip=100, train_wall=5, wall=429]2022-11-08 08:24:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 137 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 137 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.84it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:40 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 1.554 | nll_loss 0.543 | ppl 1.46 | wps 26504.7 | wpb 537.5 | bsz 16.7 | num_updates 6028 | best_loss 1.536\n",
            "2022-11-08 08:24:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint137.pt (epoch 137 @ 6028 updates, score 1.554) (writing took 0.4199035569999978 seconds)\n",
            "2022-11-08 08:24:41 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)\n",
            "2022-11-08 08:24:41 | INFO | train | epoch 137 | loss 1.194 | nll_loss 0.24 | ppl 1.18 | wps 6796.3 | ups 13.8 | wpb 492.6 | bsz 15.9 | num_updates 6028 | lr 0.000814598 | gnorm 0.788 | clip 97.7 | train_wall 2 | wall 431\n",
            "epoch 138:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:41 | INFO | fairseq.trainer | begin training epoch 138\n",
            "epoch 138:  98% 43/44 [00:02<00:00, 19.10it/s]2022-11-08 08:24:43 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 138 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 138 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.41it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:43 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 1.56 | nll_loss 0.545 | ppl 1.46 | wps 32881.9 | wpb 537.5 | bsz 16.7 | num_updates 6072 | best_loss 1.536\n",
            "2022-11-08 08:24:43 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint138.pt (epoch 138 @ 6072 updates, score 1.56) (writing took 0.4382392059999347 seconds)\n",
            "2022-11-08 08:24:44 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)\n",
            "2022-11-08 08:24:44 | INFO | train | epoch 138 | loss 1.19 | nll_loss 0.236 | ppl 1.18 | wps 6993.5 | ups 14.2 | wpb 492.6 | bsz 15.9 | num_updates 6072 | lr 0.000811641 | gnorm 0.67 | clip 97.7 | train_wall 2 | wall 434\n",
            "epoch 139:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:44 | INFO | fairseq.trainer | begin training epoch 139\n",
            "epoch 139:  93% 41/44 [00:02<00:00, 19.54it/s, loss=1.188, nll_loss=0.233, ppl=1.18, wps=6960.2, ups=14.42, wpb=482.5, bsz=15.9, num_updates=6100, lr=0.000809776, gnorm=0.634, clip=98, train_wall=5, wall=436]2022-11-08 08:24:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 139 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 139 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.17it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:46 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 1.571 | nll_loss 0.564 | ppl 1.48 | wps 34941 | wpb 537.5 | bsz 16.7 | num_updates 6116 | best_loss 1.536\n",
            "2022-11-08 08:24:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint139.pt (epoch 139 @ 6116 updates, score 1.571) (writing took 0.4058891610000046 seconds)\n",
            "2022-11-08 08:24:47 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)\n",
            "2022-11-08 08:24:47 | INFO | train | epoch 139 | loss 1.192 | nll_loss 0.237 | ppl 1.18 | wps 7082.5 | ups 14.38 | wpb 492.6 | bsz 15.9 | num_updates 6116 | lr 0.000808716 | gnorm 0.706 | clip 100 | train_wall 2 | wall 438\n",
            "epoch 140:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:47 | INFO | fairseq.trainer | begin training epoch 140\n",
            "epoch 140:  93% 41/44 [00:02<00:00, 19.68it/s]2022-11-08 08:24:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 140 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 140 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.72it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:49 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 1.569 | nll_loss 0.559 | ppl 1.47 | wps 32303.8 | wpb 537.5 | bsz 16.7 | num_updates 6160 | best_loss 1.536\n",
            "2022-11-08 08:24:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint140.pt (epoch 140 @ 6160 updates, score 1.569) (writing took 0.45459842499997194 seconds)\n",
            "2022-11-08 08:24:50 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)\n",
            "2022-11-08 08:24:50 | INFO | train | epoch 140 | loss 1.188 | nll_loss 0.234 | ppl 1.18 | wps 6957.9 | ups 14.13 | wpb 492.6 | bsz 15.9 | num_updates 6160 | lr 0.000805823 | gnorm 0.728 | clip 100 | train_wall 2 | wall 441\n",
            "epoch 141:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:50 | INFO | fairseq.trainer | begin training epoch 141\n",
            "epoch 141:  98% 43/44 [00:02<00:00, 18.86it/s, loss=1.189, nll_loss=0.235, ppl=1.18, wps=7423.2, ups=14.75, wpb=503.4, bsz=15.9, num_updates=6200, lr=0.000803219, gnorm=0.695, clip=99, train_wall=5, wall=443]2022-11-08 08:24:52 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 141 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 141 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.83it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:53 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 1.573 | nll_loss 0.561 | ppl 1.48 | wps 33854.1 | wpb 537.5 | bsz 16.7 | num_updates 6204 | best_loss 1.536\n",
            "2022-11-08 08:24:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint141.pt (epoch 141 @ 6204 updates, score 1.573) (writing took 0.44502402300008725 seconds)\n",
            "2022-11-08 08:24:53 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)\n",
            "2022-11-08 08:24:53 | INFO | train | epoch 141 | loss 1.186 | nll_loss 0.233 | ppl 1.17 | wps 6966.5 | ups 14.14 | wpb 492.6 | bsz 15.9 | num_updates 6204 | lr 0.00080296 | gnorm 0.592 | clip 97.7 | train_wall 2 | wall 444\n",
            "epoch 142:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:53 | INFO | fairseq.trainer | begin training epoch 142\n",
            "epoch 142:  95% 42/44 [00:02<00:00, 19.85it/s]2022-11-08 08:24:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 142 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 142 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.47it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:56 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 1.567 | nll_loss 0.559 | ppl 1.47 | wps 26382.4 | wpb 537.5 | bsz 16.7 | num_updates 6248 | best_loss 1.536\n",
            "2022-11-08 08:24:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint142.pt (epoch 142 @ 6248 updates, score 1.567) (writing took 0.41119189799997 seconds)\n",
            "2022-11-08 08:24:56 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)\n",
            "2022-11-08 08:24:56 | INFO | train | epoch 142 | loss 1.189 | nll_loss 0.236 | ppl 1.18 | wps 7110.9 | ups 14.44 | wpb 492.6 | bsz 15.9 | num_updates 6248 | lr 0.000800128 | gnorm 0.657 | clip 97.7 | train_wall 2 | wall 447\n",
            "epoch 143:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:56 | INFO | fairseq.trainer | begin training epoch 143\n",
            "epoch 143:  95% 42/44 [00:02<00:00, 19.58it/s]2022-11-08 08:24:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 143 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 143 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.04it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:24:59 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 1.536 | nll_loss 0.517 | ppl 1.43 | wps 33782.3 | wpb 537.5 | bsz 16.7 | num_updates 6292 | best_loss 1.536\n",
            "2022-11-08 08:24:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:24:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint143.pt (epoch 143 @ 6292 updates, score 1.536) (writing took 0.5521947919999093 seconds)\n",
            "2022-11-08 08:24:59 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)\n",
            "2022-11-08 08:24:59 | INFO | train | epoch 143 | loss 1.198 | nll_loss 0.247 | ppl 1.19 | wps 6755.7 | ups 13.71 | wpb 492.6 | bsz 15.9 | num_updates 6292 | lr 0.000797325 | gnorm 0.702 | clip 100 | train_wall 2 | wall 450\n",
            "epoch 144:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:24:59 | INFO | fairseq.trainer | begin training epoch 144\n",
            "epoch 144:  95% 42/44 [00:02<00:00, 19.64it/s, loss=1.189, nll_loss=0.236, ppl=1.18, wps=6305.5, ups=13.05, wpb=483.2, bsz=15.9, num_updates=6300, lr=0.000796819, gnorm=0.684, clip=99, train_wall=5, wall=451]2022-11-08 08:25:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 144 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 144 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.71it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:02 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 1.524 | nll_loss 0.517 | ppl 1.43 | wps 37450.8 | wpb 537.5 | bsz 16.7 | num_updates 6336 | best_loss 1.524\n",
            "2022-11-08 08:25:02 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint144.pt (epoch 144 @ 6336 updates, score 1.524) (writing took 0.7723614479999696 seconds)\n",
            "2022-11-08 08:25:03 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)\n",
            "2022-11-08 08:25:03 | INFO | train | epoch 144 | loss 1.192 | nll_loss 0.24 | ppl 1.18 | wps 6275.9 | ups 12.74 | wpb 492.6 | bsz 15.9 | num_updates 6336 | lr 0.000794552 | gnorm 0.738 | clip 100 | train_wall 2 | wall 453\n",
            "epoch 145:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:03 | INFO | fairseq.trainer | begin training epoch 145\n",
            "epoch 145:  93% 41/44 [00:02<00:00, 18.42it/s]2022-11-08 08:25:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 145 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 145 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 17.85it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:05 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 1.558 | nll_loss 0.544 | ppl 1.46 | wps 29421 | wpb 537.5 | bsz 16.7 | num_updates 6380 | best_loss 1.524\n",
            "2022-11-08 08:25:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint145.pt (epoch 145 @ 6380 updates, score 1.558) (writing took 0.41195001800008413 seconds)\n",
            "2022-11-08 08:25:06 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)\n",
            "2022-11-08 08:25:06 | INFO | train | epoch 145 | loss 1.188 | nll_loss 0.236 | ppl 1.18 | wps 7108.2 | ups 14.43 | wpb 492.6 | bsz 15.9 | num_updates 6380 | lr 0.000791808 | gnorm 0.694 | clip 100 | train_wall 2 | wall 457\n",
            "epoch 146:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:06 | INFO | fairseq.trainer | begin training epoch 146\n",
            "epoch 146:  93% 41/44 [00:02<00:00, 18.95it/s, loss=1.195, nll_loss=0.244, ppl=1.18, wps=6968.2, ups=14.06, wpb=495.8, bsz=15.9, num_updates=6400, lr=0.000790569, gnorm=0.747, clip=100, train_wall=5, wall=458]2022-11-08 08:25:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 146 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 146 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.19it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:08 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 1.559 | nll_loss 0.55 | ppl 1.46 | wps 39182.6 | wpb 537.5 | bsz 16.7 | num_updates 6424 | best_loss 1.524\n",
            "2022-11-08 08:25:08 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint146.pt (epoch 146 @ 6424 updates, score 1.559) (writing took 0.4024597369999583 seconds)\n",
            "2022-11-08 08:25:09 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)\n",
            "2022-11-08 08:25:09 | INFO | train | epoch 146 | loss 1.193 | nll_loss 0.242 | ppl 1.18 | wps 7240.8 | ups 14.7 | wpb 492.6 | bsz 15.9 | num_updates 6424 | lr 0.000789091 | gnorm 0.8 | clip 100 | train_wall 2 | wall 460\n",
            "epoch 147:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:09 | INFO | fairseq.trainer | begin training epoch 147\n",
            "epoch 147:  95% 42/44 [00:02<00:00, 19.00it/s]2022-11-08 08:25:11 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 147 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 147 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.76it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:11 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 1.576 | nll_loss 0.566 | ppl 1.48 | wps 29540 | wpb 537.5 | bsz 16.7 | num_updates 6468 | best_loss 1.524\n",
            "2022-11-08 08:25:11 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint147.pt (epoch 147 @ 6468 updates, score 1.576) (writing took 0.40950852100002066 seconds)\n",
            "2022-11-08 08:25:12 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)\n",
            "2022-11-08 08:25:12 | INFO | train | epoch 147 | loss 1.183 | nll_loss 0.23 | ppl 1.17 | wps 7060.7 | ups 14.33 | wpb 492.6 | bsz 15.9 | num_updates 6468 | lr 0.000786403 | gnorm 0.698 | clip 97.7 | train_wall 2 | wall 463\n",
            "epoch 148:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:12 | INFO | fairseq.trainer | begin training epoch 148\n",
            "epoch 148:  93% 41/44 [00:02<00:00, 18.67it/s, loss=1.184, nll_loss=0.231, ppl=1.17, wps=7264.4, ups=14.71, wpb=493.7, bsz=15.9, num_updates=6500, lr=0.000784465, gnorm=0.692, clip=99, train_wall=5, wall=465]2022-11-08 08:25:14 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 148 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 148 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.62it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:15 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 1.544 | nll_loss 0.533 | ppl 1.45 | wps 26957.4 | wpb 537.5 | bsz 16.7 | num_updates 6512 | best_loss 1.524\n",
            "2022-11-08 08:25:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint148.pt (epoch 148 @ 6512 updates, score 1.544) (writing took 0.4111673419999988 seconds)\n",
            "2022-11-08 08:25:15 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)\n",
            "2022-11-08 08:25:15 | INFO | train | epoch 148 | loss 1.181 | nll_loss 0.227 | ppl 1.17 | wps 6932.7 | ups 14.07 | wpb 492.6 | bsz 15.9 | num_updates 6512 | lr 0.000783741 | gnorm 0.627 | clip 100 | train_wall 2 | wall 466\n",
            "epoch 149:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:15 | INFO | fairseq.trainer | begin training epoch 149\n",
            "epoch 149:  98% 43/44 [00:02<00:00, 18.99it/s]2022-11-08 08:25:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 149 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 149 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.74it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:18 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 1.556 | nll_loss 0.543 | ppl 1.46 | wps 31856.9 | wpb 537.5 | bsz 16.7 | num_updates 6556 | best_loss 1.524\n",
            "2022-11-08 08:25:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint149.pt (epoch 149 @ 6556 updates, score 1.556) (writing took 0.42313513900001 seconds)\n",
            "2022-11-08 08:25:18 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)\n",
            "2022-11-08 08:25:18 | INFO | train | epoch 149 | loss 1.18 | nll_loss 0.227 | ppl 1.17 | wps 7026.9 | ups 14.27 | wpb 492.6 | bsz 15.9 | num_updates 6556 | lr 0.000781107 | gnorm 0.591 | clip 100 | train_wall 2 | wall 469\n",
            "epoch 150:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:18 | INFO | fairseq.trainer | begin training epoch 150\n",
            "epoch 150:  98% 43/44 [00:02<00:00, 19.73it/s]2022-11-08 08:25:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 150 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 150 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.08it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:21 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 1.571 | nll_loss 0.556 | ppl 1.47 | wps 35294.2 | wpb 537.5 | bsz 16.7 | num_updates 6600 | best_loss 1.524\n",
            "2022-11-08 08:25:21 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint150.pt (epoch 150 @ 6600 updates, score 1.571) (writing took 0.3957104060000347 seconds)\n",
            "2022-11-08 08:25:21 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)\n",
            "2022-11-08 08:25:21 | INFO | train | epoch 150 | loss 1.175 | nll_loss 0.22 | ppl 1.16 | wps 7098.5 | ups 14.41 | wpb 492.6 | bsz 15.9 | num_updates 6600 | lr 0.000778499 | gnorm 0.566 | clip 93.2 | train_wall 2 | wall 472\n",
            "epoch 151:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:21 | INFO | fairseq.trainer | begin training epoch 151\n",
            "epoch 151:  95% 42/44 [00:02<00:00, 18.49it/s]2022-11-08 08:25:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 151 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 151 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.15it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:24 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 1.552 | nll_loss 0.537 | ppl 1.45 | wps 34468.9 | wpb 537.5 | bsz 16.7 | num_updates 6644 | best_loss 1.524\n",
            "2022-11-08 08:25:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint151.pt (epoch 151 @ 6644 updates, score 1.552) (writing took 0.4125026250000019 seconds)\n",
            "2022-11-08 08:25:24 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)\n",
            "2022-11-08 08:25:24 | INFO | train | epoch 151 | loss 1.185 | nll_loss 0.233 | ppl 1.18 | wps 7042.3 | ups 14.3 | wpb 492.6 | bsz 15.9 | num_updates 6644 | lr 0.000775917 | gnorm 0.721 | clip 100 | train_wall 2 | wall 475\n",
            "epoch 152:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:24 | INFO | fairseq.trainer | begin training epoch 152\n",
            "epoch 152:  95% 42/44 [00:02<00:00, 19.72it/s]2022-11-08 08:25:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 152 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 152 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.21it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:27 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 1.578 | nll_loss 0.564 | ppl 1.48 | wps 32618.4 | wpb 537.5 | bsz 16.7 | num_updates 6688 | best_loss 1.524\n",
            "2022-11-08 08:25:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint152.pt (epoch 152 @ 6688 updates, score 1.578) (writing took 0.4226761450000822 seconds)\n",
            "2022-11-08 08:25:27 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)\n",
            "2022-11-08 08:25:27 | INFO | train | epoch 152 | loss 1.173 | nll_loss 0.219 | ppl 1.16 | wps 7138.3 | ups 14.49 | wpb 492.6 | bsz 15.9 | num_updates 6688 | lr 0.00077336 | gnorm 0.641 | clip 100 | train_wall 2 | wall 478\n",
            "epoch 153:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:27 | INFO | fairseq.trainer | begin training epoch 153\n",
            "epoch 153:  98% 43/44 [00:02<00:00, 19.80it/s, loss=1.178, nll_loss=0.224, ppl=1.17, wps=6529.1, ups=13.47, wpb=484.9, bsz=15.9, num_updates=6700, lr=0.000772667, gnorm=0.68, clip=100, train_wall=5, wall=479]2022-11-08 08:25:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 153 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 153 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.99it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:30 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 1.542 | nll_loss 0.533 | ppl 1.45 | wps 37105.9 | wpb 537.5 | bsz 16.7 | num_updates 6732 | best_loss 1.524\n",
            "2022-11-08 08:25:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint153.pt (epoch 153 @ 6732 updates, score 1.542) (writing took 0.4282019089999949 seconds)\n",
            "2022-11-08 08:25:30 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)\n",
            "2022-11-08 08:25:30 | INFO | train | epoch 153 | loss 1.181 | nll_loss 0.229 | ppl 1.17 | wps 7061.3 | ups 14.33 | wpb 492.6 | bsz 15.9 | num_updates 6732 | lr 0.000770829 | gnorm 0.644 | clip 100 | train_wall 2 | wall 481\n",
            "epoch 154:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:30 | INFO | fairseq.trainer | begin training epoch 154\n",
            "epoch 154:  93% 41/44 [00:02<00:00, 17.88it/s]2022-11-08 08:25:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 154 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 154 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.74it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:33 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 1.57 | nll_loss 0.557 | ppl 1.47 | wps 31377.2 | wpb 537.5 | bsz 16.7 | num_updates 6776 | best_loss 1.524\n",
            "2022-11-08 08:25:33 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint154.pt (epoch 154 @ 6776 updates, score 1.57) (writing took 0.40667729699998745 seconds)\n",
            "2022-11-08 08:25:33 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)\n",
            "2022-11-08 08:25:33 | INFO | train | epoch 154 | loss 1.173 | nll_loss 0.221 | ppl 1.17 | wps 6968.6 | ups 14.15 | wpb 492.6 | bsz 15.9 | num_updates 6776 | lr 0.000768322 | gnorm 0.646 | clip 100 | train_wall 2 | wall 484\n",
            "epoch 155:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:33 | INFO | fairseq.trainer | begin training epoch 155\n",
            "epoch 155:  95% 42/44 [00:02<00:00, 19.54it/s, loss=1.177, nll_loss=0.224, ppl=1.17, wps=7405.7, ups=14.56, wpb=508.5, bsz=15.9, num_updates=6800, lr=0.000766965, gnorm=0.638, clip=100, train_wall=5, wall=486]2022-11-08 08:25:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 155 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 155 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:36 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 1.575 | nll_loss 0.567 | ppl 1.48 | wps 36941.9 | wpb 537.5 | bsz 16.7 | num_updates 6820 | best_loss 1.524\n",
            "2022-11-08 08:25:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint155.pt (epoch 155 @ 6820 updates, score 1.575) (writing took 0.4094061490000058 seconds)\n",
            "2022-11-08 08:25:36 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)\n",
            "2022-11-08 08:25:36 | INFO | train | epoch 155 | loss 1.174 | nll_loss 0.22 | ppl 1.16 | wps 7065.5 | ups 14.34 | wpb 492.6 | bsz 15.9 | num_updates 6820 | lr 0.00076584 | gnorm 0.662 | clip 95.5 | train_wall 2 | wall 487\n",
            "epoch 156:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:36 | INFO | fairseq.trainer | begin training epoch 156\n",
            "epoch 156:  95% 42/44 [00:02<00:00, 18.45it/s]2022-11-08 08:25:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 156 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 156 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.33it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:39 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 1.573 | nll_loss 0.568 | ppl 1.48 | wps 28447.8 | wpb 537.5 | bsz 16.7 | num_updates 6864 | best_loss 1.524\n",
            "2022-11-08 08:25:39 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint156.pt (epoch 156 @ 6864 updates, score 1.573) (writing took 0.4257054800000333 seconds)\n",
            "2022-11-08 08:25:40 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)\n",
            "2022-11-08 08:25:40 | INFO | train | epoch 156 | loss 1.183 | nll_loss 0.231 | ppl 1.17 | wps 6924.9 | ups 14.06 | wpb 492.6 | bsz 15.9 | num_updates 6864 | lr 0.000763381 | gnorm 0.722 | clip 100 | train_wall 2 | wall 490\n",
            "epoch 157:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:40 | INFO | fairseq.trainer | begin training epoch 157\n",
            "epoch 157:  98% 43/44 [00:02<00:00, 19.97it/s, loss=1.175, nll_loss=0.222, ppl=1.17, wps=7042.2, ups=14.64, wpb=481.1, bsz=15.9, num_updates=6900, lr=0.000761387, gnorm=0.685, clip=98, train_wall=5, wall=492]2022-11-08 08:25:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 157 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 157 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.16it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:42 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 1.556 | nll_loss 0.549 | ppl 1.46 | wps 36105.1 | wpb 537.5 | bsz 16.7 | num_updates 6908 | best_loss 1.524\n",
            "2022-11-08 08:25:42 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint157.pt (epoch 157 @ 6908 updates, score 1.556) (writing took 0.4317210880000175 seconds)\n",
            "2022-11-08 08:25:43 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)\n",
            "2022-11-08 08:25:43 | INFO | train | epoch 157 | loss 1.177 | nll_loss 0.226 | ppl 1.17 | wps 7084.6 | ups 14.38 | wpb 492.6 | bsz 15.9 | num_updates 6908 | lr 0.000760946 | gnorm 0.634 | clip 100 | train_wall 2 | wall 493\n",
            "epoch 158:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:43 | INFO | fairseq.trainer | begin training epoch 158\n",
            "epoch 158:  98% 43/44 [00:02<00:00, 19.72it/s]2022-11-08 08:25:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 158 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 158 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.67it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:45 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 1.572 | nll_loss 0.565 | ppl 1.48 | wps 26731.8 | wpb 537.5 | bsz 16.7 | num_updates 6952 | best_loss 1.524\n",
            "2022-11-08 08:25:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint158.pt (epoch 158 @ 6952 updates, score 1.572) (writing took 0.4249232849999771 seconds)\n",
            "2022-11-08 08:25:46 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)\n",
            "2022-11-08 08:25:46 | INFO | train | epoch 158 | loss 1.176 | nll_loss 0.222 | ppl 1.17 | wps 6898.1 | ups 14 | wpb 492.6 | bsz 15.9 | num_updates 6952 | lr 0.000758534 | gnorm 0.617 | clip 100 | train_wall 2 | wall 497\n",
            "epoch 159:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:46 | INFO | fairseq.trainer | begin training epoch 159\n",
            "epoch 159:  98% 43/44 [00:02<00:00, 19.94it/s]2022-11-08 08:25:48 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 159 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 159 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.55it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:48 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 1.518 | nll_loss 0.505 | ppl 1.42 | wps 29280.4 | wpb 537.5 | bsz 16.7 | num_updates 6996 | best_loss 1.518\n",
            "2022-11-08 08:25:48 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint159.pt (epoch 159 @ 6996 updates, score 1.518) (writing took 0.5767592359999298 seconds)\n",
            "2022-11-08 08:25:49 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)\n",
            "2022-11-08 08:25:49 | INFO | train | epoch 159 | loss 1.164 | nll_loss 0.21 | ppl 1.16 | wps 6705.2 | ups 13.61 | wpb 492.6 | bsz 15.9 | num_updates 6996 | lr 0.000756145 | gnorm 0.592 | clip 100 | train_wall 2 | wall 500\n",
            "epoch 160:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:49 | INFO | fairseq.trainer | begin training epoch 160\n",
            "epoch 160:  95% 42/44 [00:02<00:00, 19.19it/s, loss=1.175, nll_loss=0.223, ppl=1.17, wps=6468.9, ups=12.99, wpb=497.9, bsz=15.9, num_updates=7000, lr=0.000755929, gnorm=0.603, clip=100, train_wall=5, wall=500]2022-11-08 08:25:52 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 160 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 160 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.83it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:52 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 1.533 | nll_loss 0.523 | ppl 1.44 | wps 34191.8 | wpb 537.5 | bsz 16.7 | num_updates 7040 | best_loss 1.518\n",
            "2022-11-08 08:25:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint160.pt (epoch 160 @ 7040 updates, score 1.533) (writing took 0.39456775700000435 seconds)\n",
            "2022-11-08 08:25:52 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)\n",
            "2022-11-08 08:25:52 | INFO | train | epoch 160 | loss 1.168 | nll_loss 0.215 | ppl 1.16 | wps 7041.6 | ups 14.3 | wpb 492.6 | bsz 15.9 | num_updates 7040 | lr 0.000753778 | gnorm 0.532 | clip 97.7 | train_wall 2 | wall 503\n",
            "epoch 161:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:52 | INFO | fairseq.trainer | begin training epoch 161\n",
            "epoch 161:  95% 42/44 [00:02<00:00, 19.34it/s]2022-11-08 08:25:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 161 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 161 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:55 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 1.538 | nll_loss 0.525 | ppl 1.44 | wps 25354.6 | wpb 537.5 | bsz 16.7 | num_updates 7084 | best_loss 1.518\n",
            "2022-11-08 08:25:55 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint161.pt (epoch 161 @ 7084 updates, score 1.538) (writing took 0.3947253390000469 seconds)\n",
            "2022-11-08 08:25:55 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)\n",
            "2022-11-08 08:25:55 | INFO | train | epoch 161 | loss 1.175 | nll_loss 0.224 | ppl 1.17 | wps 7040 | ups 14.29 | wpb 492.6 | bsz 15.9 | num_updates 7084 | lr 0.000751434 | gnorm 0.684 | clip 100 | train_wall 2 | wall 506\n",
            "epoch 162:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:55 | INFO | fairseq.trainer | begin training epoch 162\n",
            "epoch 162:  95% 42/44 [00:02<00:00, 19.56it/s, loss=1.171, nll_loss=0.218, ppl=1.16, wps=7239.9, ups=14.73, wpb=491.4, bsz=15.9, num_updates=7100, lr=0.000750587, gnorm=0.626, clip=98, train_wall=5, wall=507]2022-11-08 08:25:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 162 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 162 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.89it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:25:58 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 1.546 | nll_loss 0.535 | ppl 1.45 | wps 29387.5 | wpb 537.5 | bsz 16.7 | num_updates 7128 | best_loss 1.518\n",
            "2022-11-08 08:25:58 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:25:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint162.pt (epoch 162 @ 7128 updates, score 1.546) (writing took 0.40961889099992277 seconds)\n",
            "2022-11-08 08:25:58 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)\n",
            "2022-11-08 08:25:58 | INFO | train | epoch 162 | loss 1.173 | nll_loss 0.22 | ppl 1.16 | wps 7102.6 | ups 14.42 | wpb 492.6 | bsz 15.9 | num_updates 7128 | lr 0.000749111 | gnorm 0.591 | clip 97.7 | train_wall 2 | wall 509\n",
            "epoch 163:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:25:58 | INFO | fairseq.trainer | begin training epoch 163\n",
            "epoch 163:  98% 43/44 [00:02<00:00, 18.80it/s]2022-11-08 08:26:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 163 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 163 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.24it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:01 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 1.542 | nll_loss 0.531 | ppl 1.44 | wps 37566 | wpb 537.5 | bsz 16.7 | num_updates 7172 | best_loss 1.518\n",
            "2022-11-08 08:26:01 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint163.pt (epoch 163 @ 7172 updates, score 1.542) (writing took 0.36157678199992915 seconds)\n",
            "2022-11-08 08:26:01 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)\n",
            "2022-11-08 08:26:01 | INFO | train | epoch 163 | loss 1.171 | nll_loss 0.217 | ppl 1.16 | wps 7216.1 | ups 14.65 | wpb 492.6 | bsz 15.9 | num_updates 7172 | lr 0.00074681 | gnorm 0.72 | clip 100 | train_wall 2 | wall 512\n",
            "epoch 164:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:01 | INFO | fairseq.trainer | begin training epoch 164\n",
            "epoch 164:  95% 42/44 [00:02<00:00, 18.39it/s, loss=1.17, nll_loss=0.217, ppl=1.16, wps=7237, ups=14.83, wpb=488, bsz=15.9, num_updates=7200, lr=0.000745356, gnorm=0.654, clip=100, train_wall=5, wall=514]2022-11-08 08:26:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 164 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 164 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:04 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 1.538 | nll_loss 0.52 | ppl 1.43 | wps 33125.9 | wpb 537.5 | bsz 16.7 | num_updates 7216 | best_loss 1.518\n",
            "2022-11-08 08:26:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint164.pt (epoch 164 @ 7216 updates, score 1.538) (writing took 0.3656429579999667 seconds)\n",
            "2022-11-08 08:26:04 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)\n",
            "2022-11-08 08:26:04 | INFO | train | epoch 164 | loss 1.165 | nll_loss 0.211 | ppl 1.16 | wps 7041.5 | ups 14.29 | wpb 492.6 | bsz 15.9 | num_updates 7216 | lr 0.000744529 | gnorm 0.582 | clip 100 | train_wall 2 | wall 515\n",
            "epoch 165:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:04 | INFO | fairseq.trainer | begin training epoch 165\n",
            "epoch 165:  95% 42/44 [00:02<00:00, 18.65it/s]2022-11-08 08:26:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 165 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 165 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.14it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:07 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 1.547 | nll_loss 0.538 | ppl 1.45 | wps 29025.7 | wpb 537.5 | bsz 16.7 | num_updates 7260 | best_loss 1.518\n",
            "2022-11-08 08:26:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint165.pt (epoch 165 @ 7260 updates, score 1.547) (writing took 0.5148030110000263 seconds)\n",
            "2022-11-08 08:26:08 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)\n",
            "2022-11-08 08:26:08 | INFO | train | epoch 165 | loss 1.17 | nll_loss 0.218 | ppl 1.16 | wps 6679 | ups 13.56 | wpb 492.6 | bsz 15.9 | num_updates 7260 | lr 0.00074227 | gnorm 0.645 | clip 95.5 | train_wall 2 | wall 518\n",
            "epoch 166:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:08 | INFO | fairseq.trainer | begin training epoch 166\n",
            "epoch 166:  98% 43/44 [00:02<00:00, 19.23it/s, loss=1.173, nll_loss=0.22, ppl=1.16, wps=7193.4, ups=14.25, wpb=504.9, bsz=15.9, num_updates=7300, lr=0.000740233, gnorm=0.589, clip=97, train_wall=6, wall=521]2022-11-08 08:26:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 166 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 166 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.35it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:10 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 1.551 | nll_loss 0.536 | ppl 1.45 | wps 37164 | wpb 537.5 | bsz 16.7 | num_updates 7304 | best_loss 1.518\n",
            "2022-11-08 08:26:10 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint166.pt (epoch 166 @ 7304 updates, score 1.551) (writing took 0.41235406199996305 seconds)\n",
            "2022-11-08 08:26:11 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)\n",
            "2022-11-08 08:26:11 | INFO | train | epoch 166 | loss 1.174 | nll_loss 0.221 | ppl 1.17 | wps 6932.1 | ups 14.07 | wpb 492.6 | bsz 15.9 | num_updates 7304 | lr 0.00074003 | gnorm 0.609 | clip 97.7 | train_wall 2 | wall 521\n",
            "epoch 167:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:11 | INFO | fairseq.trainer | begin training epoch 167\n",
            "epoch 167:  98% 43/44 [00:02<00:00, 19.46it/s]2022-11-08 08:26:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 167 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 167 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.27it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:13 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 1.557 | nll_loss 0.544 | ppl 1.46 | wps 33752.9 | wpb 537.5 | bsz 16.7 | num_updates 7348 | best_loss 1.518\n",
            "2022-11-08 08:26:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint167.pt (epoch 167 @ 7348 updates, score 1.557) (writing took 0.3947397599999931 seconds)\n",
            "2022-11-08 08:26:14 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)\n",
            "2022-11-08 08:26:14 | INFO | train | epoch 167 | loss 1.167 | nll_loss 0.215 | ppl 1.16 | wps 7156.1 | ups 14.53 | wpb 492.6 | bsz 15.9 | num_updates 7348 | lr 0.000737812 | gnorm 0.646 | clip 95.5 | train_wall 2 | wall 524\n",
            "epoch 168:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:14 | INFO | fairseq.trainer | begin training epoch 168\n",
            "epoch 168:  93% 41/44 [00:02<00:00, 18.65it/s]2022-11-08 08:26:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 168 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 168 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.90it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:16 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 1.535 | nll_loss 0.525 | ppl 1.44 | wps 29285.8 | wpb 537.5 | bsz 16.7 | num_updates 7392 | best_loss 1.518\n",
            "2022-11-08 08:26:16 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint168.pt (epoch 168 @ 7392 updates, score 1.535) (writing took 0.3838799749998998 seconds)\n",
            "2022-11-08 08:26:17 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)\n",
            "2022-11-08 08:26:17 | INFO | train | epoch 168 | loss 1.167 | nll_loss 0.214 | ppl 1.16 | wps 6890.2 | ups 13.99 | wpb 492.6 | bsz 15.9 | num_updates 7392 | lr 0.000735612 | gnorm 0.608 | clip 100 | train_wall 2 | wall 528\n",
            "epoch 169:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:17 | INFO | fairseq.trainer | begin training epoch 169\n",
            "epoch 169:  98% 43/44 [00:02<00:00, 19.63it/s, loss=1.168, nll_loss=0.215, ppl=1.16, wps=6546.4, ups=13.35, wpb=490.5, bsz=15.9, num_updates=7400, lr=0.000735215, gnorm=0.642, clip=98, train_wall=5, wall=528]2022-11-08 08:26:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 169 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 169 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.87it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:19 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 1.55 | nll_loss 0.533 | ppl 1.45 | wps 28080.3 | wpb 537.5 | bsz 16.7 | num_updates 7436 | best_loss 1.518\n",
            "2022-11-08 08:26:19 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint169.pt (epoch 169 @ 7436 updates, score 1.55) (writing took 0.3768658230000028 seconds)\n",
            "2022-11-08 08:26:20 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)\n",
            "2022-11-08 08:26:20 | INFO | train | epoch 169 | loss 1.166 | nll_loss 0.213 | ppl 1.16 | wps 7192.4 | ups 14.6 | wpb 492.6 | bsz 15.9 | num_updates 7436 | lr 0.000733433 | gnorm 0.509 | clip 100 | train_wall 2 | wall 531\n",
            "epoch 170:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:20 | INFO | fairseq.trainer | begin training epoch 170\n",
            "epoch 170:  95% 42/44 [00:02<00:00, 19.91it/s]2022-11-08 08:26:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 170 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 170 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.24it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:22 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 1.557 | nll_loss 0.54 | ppl 1.45 | wps 37287.1 | wpb 537.5 | bsz 16.7 | num_updates 7480 | best_loss 1.518\n",
            "2022-11-08 08:26:22 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint170.pt (epoch 170 @ 7480 updates, score 1.557) (writing took 0.3822552330000235 seconds)\n",
            "2022-11-08 08:26:23 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)\n",
            "2022-11-08 08:26:23 | INFO | train | epoch 170 | loss 1.165 | nll_loss 0.212 | ppl 1.16 | wps 7216.8 | ups 14.65 | wpb 492.6 | bsz 15.9 | num_updates 7480 | lr 0.000731272 | gnorm 0.53 | clip 97.7 | train_wall 2 | wall 534\n",
            "epoch 171:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:23 | INFO | fairseq.trainer | begin training epoch 171\n",
            "epoch 171:  95% 42/44 [00:02<00:00, 19.92it/s, loss=1.164, nll_loss=0.211, ppl=1.16, wps=7081.7, ups=14.96, wpb=473.5, bsz=15.9, num_updates=7500, lr=0.000730297, gnorm=0.502, clip=99, train_wall=5, wall=535]2022-11-08 08:26:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 171 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 171 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.00it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:26 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 1.564 | nll_loss 0.549 | ppl 1.46 | wps 33803.7 | wpb 537.5 | bsz 16.7 | num_updates 7524 | best_loss 1.518\n",
            "2022-11-08 08:26:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint171.pt (epoch 171 @ 7524 updates, score 1.564) (writing took 0.3902309679999689 seconds)\n",
            "2022-11-08 08:26:26 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)\n",
            "2022-11-08 08:26:26 | INFO | train | epoch 171 | loss 1.163 | nll_loss 0.21 | ppl 1.16 | wps 7128.4 | ups 14.47 | wpb 492.6 | bsz 15.9 | num_updates 7524 | lr 0.000729131 | gnorm 0.559 | clip 100 | train_wall 2 | wall 537\n",
            "epoch 172:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:26 | INFO | fairseq.trainer | begin training epoch 172\n",
            "epoch 172:  98% 43/44 [00:02<00:00, 19.75it/s]2022-11-08 08:26:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 172 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 172 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.69it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:29 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 1.581 | nll_loss 0.574 | ppl 1.49 | wps 35932.5 | wpb 537.5 | bsz 16.7 | num_updates 7568 | best_loss 1.518\n",
            "2022-11-08 08:26:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint172.pt (epoch 172 @ 7568 updates, score 1.581) (writing took 0.3789955810000265 seconds)\n",
            "2022-11-08 08:26:29 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)\n",
            "2022-11-08 08:26:29 | INFO | train | epoch 172 | loss 1.161 | nll_loss 0.208 | ppl 1.15 | wps 7176.6 | ups 14.57 | wpb 492.6 | bsz 15.9 | num_updates 7568 | lr 0.000727008 | gnorm 0.67 | clip 95.5 | train_wall 2 | wall 540\n",
            "epoch 173:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:29 | INFO | fairseq.trainer | begin training epoch 173\n",
            "epoch 173:  95% 42/44 [00:02<00:00, 19.51it/s, loss=1.163, nll_loss=0.211, ppl=1.16, wps=7564.5, ups=14.83, wpb=510.2, bsz=15.9, num_updates=7600, lr=0.000725476, gnorm=0.652, clip=98, train_wall=5, wall=542]2022-11-08 08:26:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 173 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 173 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 18.35it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:32 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 1.559 | nll_loss 0.551 | ppl 1.47 | wps 30230.5 | wpb 537.5 | bsz 16.7 | num_updates 7612 | best_loss 1.518\n",
            "2022-11-08 08:26:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint173.pt (epoch 173 @ 7612 updates, score 1.559) (writing took 0.4161305439999978 seconds)\n",
            "2022-11-08 08:26:32 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)\n",
            "2022-11-08 08:26:32 | INFO | train | epoch 173 | loss 1.164 | nll_loss 0.211 | ppl 1.16 | wps 6988.7 | ups 14.19 | wpb 492.6 | bsz 15.9 | num_updates 7612 | lr 0.000724904 | gnorm 0.684 | clip 100 | train_wall 2 | wall 543\n",
            "epoch 174:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:32 | INFO | fairseq.trainer | begin training epoch 174\n",
            "epoch 174:  98% 43/44 [00:02<00:00, 19.67it/s]2022-11-08 08:26:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 174 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 174 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 18.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:35 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 1.563 | nll_loss 0.553 | ppl 1.47 | wps 34978.6 | wpb 537.5 | bsz 16.7 | num_updates 7656 | best_loss 1.518\n",
            "2022-11-08 08:26:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint174.pt (epoch 174 @ 7656 updates, score 1.563) (writing took 0.4020982050000157 seconds)\n",
            "2022-11-08 08:26:35 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)\n",
            "2022-11-08 08:26:35 | INFO | train | epoch 174 | loss 1.167 | nll_loss 0.213 | ppl 1.16 | wps 7016.7 | ups 14.24 | wpb 492.6 | bsz 15.9 | num_updates 7656 | lr 0.000722818 | gnorm 0.615 | clip 100 | train_wall 2 | wall 546\n",
            "epoch 175:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:35 | INFO | fairseq.trainer | begin training epoch 175\n",
            "epoch 175:  98% 43/44 [00:02<00:00, 19.09it/s]2022-11-08 08:26:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 175 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 175 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.93it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:38 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 1.571 | nll_loss 0.56 | ppl 1.47 | wps 28669.9 | wpb 537.5 | bsz 16.7 | num_updates 7700 | best_loss 1.518\n",
            "2022-11-08 08:26:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint175.pt (epoch 175 @ 7700 updates, score 1.571) (writing took 0.4076485880000291 seconds)\n",
            "2022-11-08 08:26:38 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)\n",
            "2022-11-08 08:26:38 | INFO | train | epoch 175 | loss 1.165 | nll_loss 0.213 | ppl 1.16 | wps 7004.6 | ups 14.22 | wpb 492.6 | bsz 15.9 | num_updates 7700 | lr 0.00072075 | gnorm 0.513 | clip 97.7 | train_wall 2 | wall 549\n",
            "epoch 176:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:38 | INFO | fairseq.trainer | begin training epoch 176\n",
            "epoch 176:  95% 42/44 [00:02<00:00, 19.20it/s]2022-11-08 08:26:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 176 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 176 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.68it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:41 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 1.583 | nll_loss 0.576 | ppl 1.49 | wps 38518.1 | wpb 537.5 | bsz 16.7 | num_updates 7744 | best_loss 1.518\n",
            "2022-11-08 08:26:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint176.pt (epoch 176 @ 7744 updates, score 1.583) (writing took 0.3919555479999417 seconds)\n",
            "2022-11-08 08:26:41 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)\n",
            "2022-11-08 08:26:41 | INFO | train | epoch 176 | loss 1.171 | nll_loss 0.219 | ppl 1.16 | wps 7153.2 | ups 14.52 | wpb 492.6 | bsz 15.9 | num_updates 7744 | lr 0.000718699 | gnorm 0.628 | clip 100 | train_wall 2 | wall 552\n",
            "epoch 177:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:41 | INFO | fairseq.trainer | begin training epoch 177\n",
            "epoch 177:  98% 43/44 [00:02<00:00, 19.55it/s]2022-11-08 08:26:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 177 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 177 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.50it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:44 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 1.572 | nll_loss 0.561 | ppl 1.48 | wps 34313.6 | wpb 537.5 | bsz 16.7 | num_updates 7788 | best_loss 1.518\n",
            "2022-11-08 08:26:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint177.pt (epoch 177 @ 7788 updates, score 1.572) (writing took 0.4420013190000418 seconds)\n",
            "2022-11-08 08:26:44 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)\n",
            "2022-11-08 08:26:44 | INFO | train | epoch 177 | loss 1.161 | nll_loss 0.208 | ppl 1.16 | wps 6952.1 | ups 14.11 | wpb 492.6 | bsz 15.9 | num_updates 7788 | lr 0.000716666 | gnorm 0.642 | clip 97.7 | train_wall 2 | wall 555\n",
            "epoch 178:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:44 | INFO | fairseq.trainer | begin training epoch 178\n",
            "epoch 178:  95% 42/44 [00:02<00:00, 19.54it/s, loss=1.167, nll_loss=0.215, ppl=1.16, wps=6607.6, ups=13.32, wpb=496.1, bsz=15.9, num_updates=7800, lr=0.000716115, gnorm=0.618, clip=99, train_wall=5, wall=556]2022-11-08 08:26:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 178 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 178 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.85it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:47 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 1.554 | nll_loss 0.538 | ppl 1.45 | wps 38357.6 | wpb 537.5 | bsz 16.7 | num_updates 7832 | best_loss 1.518\n",
            "2022-11-08 08:26:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint178.pt (epoch 178 @ 7832 updates, score 1.554) (writing took 0.3837779830000727 seconds)\n",
            "2022-11-08 08:26:47 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)\n",
            "2022-11-08 08:26:47 | INFO | train | epoch 178 | loss 1.16 | nll_loss 0.207 | ppl 1.15 | wps 7159.7 | ups 14.53 | wpb 492.6 | bsz 15.9 | num_updates 7832 | lr 0.00071465 | gnorm 0.759 | clip 100 | train_wall 2 | wall 558\n",
            "epoch 179:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:47 | INFO | fairseq.trainer | begin training epoch 179\n",
            "epoch 179:  95% 42/44 [00:02<00:00, 19.43it/s]2022-11-08 08:26:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 179 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 179 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.70it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:50 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 1.567 | nll_loss 0.554 | ppl 1.47 | wps 33422.3 | wpb 537.5 | bsz 16.7 | num_updates 7876 | best_loss 1.518\n",
            "2022-11-08 08:26:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint179.pt (epoch 179 @ 7876 updates, score 1.567) (writing took 0.41855924000003597 seconds)\n",
            "2022-11-08 08:26:51 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)\n",
            "2022-11-08 08:26:51 | INFO | train | epoch 179 | loss 1.161 | nll_loss 0.208 | ppl 1.16 | wps 6950.8 | ups 14.11 | wpb 492.6 | bsz 15.9 | num_updates 7876 | lr 0.000712651 | gnorm 0.652 | clip 97.7 | train_wall 2 | wall 561\n",
            "epoch 180:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:51 | INFO | fairseq.trainer | begin training epoch 180\n",
            "epoch 180:  98% 43/44 [00:02<00:00, 19.37it/s, loss=1.16, nll_loss=0.208, ppl=1.15, wps=7167.4, ups=14.66, wpb=489, bsz=15.9, num_updates=7900, lr=0.000711568, gnorm=0.677, clip=98, train_wall=5, wall=563]2022-11-08 08:26:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 180 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 180 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:53 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 1.561 | nll_loss 0.549 | ppl 1.46 | wps 30004.5 | wpb 537.5 | bsz 16.7 | num_updates 7920 | best_loss 1.518\n",
            "2022-11-08 08:26:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint180.pt (epoch 180 @ 7920 updates, score 1.561) (writing took 0.43052565100003903 seconds)\n",
            "2022-11-08 08:26:54 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)\n",
            "2022-11-08 08:26:54 | INFO | train | epoch 180 | loss 1.159 | nll_loss 0.207 | ppl 1.15 | wps 6962.4 | ups 14.13 | wpb 492.6 | bsz 15.9 | num_updates 7920 | lr 0.000710669 | gnorm 0.562 | clip 97.7 | train_wall 2 | wall 564\n",
            "epoch 181:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:54 | INFO | fairseq.trainer | begin training epoch 181\n",
            "epoch 181:  98% 43/44 [00:02<00:00, 19.96it/s]2022-11-08 08:26:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 181 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 181 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.67it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:56 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 1.566 | nll_loss 0.553 | ppl 1.47 | wps 30004.7 | wpb 537.5 | bsz 16.7 | num_updates 7964 | best_loss 1.518\n",
            "2022-11-08 08:26:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:26:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint181.pt (epoch 181 @ 7964 updates, score 1.566) (writing took 0.4571415549999074 seconds)\n",
            "2022-11-08 08:26:57 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)\n",
            "2022-11-08 08:26:57 | INFO | train | epoch 181 | loss 1.158 | nll_loss 0.204 | ppl 1.15 | wps 6969.6 | ups 14.15 | wpb 492.6 | bsz 15.9 | num_updates 7964 | lr 0.000708703 | gnorm 0.63 | clip 100 | train_wall 2 | wall 568\n",
            "epoch 182:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:26:57 | INFO | fairseq.trainer | begin training epoch 182\n",
            "epoch 182:  95% 42/44 [00:02<00:00, 20.23it/s, loss=1.156, nll_loss=0.203, ppl=1.15, wps=7147.6, ups=14.54, wpb=491.5, bsz=15.9, num_updates=8000, lr=0.000707107, gnorm=0.607, clip=99, train_wall=5, wall=570]2022-11-08 08:26:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 182 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 182 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.64it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:26:59 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 1.57 | nll_loss 0.561 | ppl 1.48 | wps 32990.6 | wpb 537.5 | bsz 16.7 | num_updates 8008 | best_loss 1.518\n",
            "2022-11-08 08:26:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint182.pt (epoch 182 @ 8008 updates, score 1.57) (writing took 0.42385912300005657 seconds)\n",
            "2022-11-08 08:27:00 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)\n",
            "2022-11-08 08:27:00 | INFO | train | epoch 182 | loss 1.16 | nll_loss 0.207 | ppl 1.15 | wps 7033.3 | ups 14.28 | wpb 492.6 | bsz 15.9 | num_updates 8008 | lr 0.000706753 | gnorm 0.555 | clip 97.7 | train_wall 2 | wall 571\n",
            "epoch 183:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:00 | INFO | fairseq.trainer | begin training epoch 183\n",
            "epoch 183:  95% 42/44 [00:02<00:00, 19.19it/s]2022-11-08 08:27:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 183 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 183 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.67it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:02 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 1.531 | nll_loss 0.512 | ppl 1.43 | wps 37579.2 | wpb 537.5 | bsz 16.7 | num_updates 8052 | best_loss 1.518\n",
            "2022-11-08 08:27:02 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint183.pt (epoch 183 @ 8052 updates, score 1.531) (writing took 0.4227707420000115 seconds)\n",
            "2022-11-08 08:27:03 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)\n",
            "2022-11-08 08:27:03 | INFO | train | epoch 183 | loss 1.16 | nll_loss 0.209 | ppl 1.16 | wps 7039 | ups 14.29 | wpb 492.6 | bsz 15.9 | num_updates 8052 | lr 0.00070482 | gnorm 0.493 | clip 97.7 | train_wall 2 | wall 574\n",
            "epoch 184:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:03 | INFO | fairseq.trainer | begin training epoch 184\n",
            "epoch 184:  95% 42/44 [00:02<00:00, 19.16it/s]2022-11-08 08:27:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 184 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 184 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.22it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:06 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 1.56 | nll_loss 0.548 | ppl 1.46 | wps 30961.2 | wpb 537.5 | bsz 16.7 | num_updates 8096 | best_loss 1.518\n",
            "2022-11-08 08:27:06 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint184.pt (epoch 184 @ 8096 updates, score 1.56) (writing took 0.41911964600001284 seconds)\n",
            "2022-11-08 08:27:06 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)\n",
            "2022-11-08 08:27:06 | INFO | train | epoch 184 | loss 1.157 | nll_loss 0.203 | ppl 1.15 | wps 7030.5 | ups 14.27 | wpb 492.6 | bsz 15.9 | num_updates 8096 | lr 0.000702902 | gnorm 0.517 | clip 97.7 | train_wall 2 | wall 577\n",
            "epoch 185:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:06 | INFO | fairseq.trainer | begin training epoch 185\n",
            "epoch 185:  93% 41/44 [00:02<00:00, 18.81it/s, loss=1.158, nll_loss=0.205, ppl=1.15, wps=6627.2, ups=13.37, wpb=495.6, bsz=15.9, num_updates=8100, lr=0.000702728, gnorm=0.511, clip=98, train_wall=5, wall=577]2022-11-08 08:27:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 185 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 185 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.45it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:09 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 1.564 | nll_loss 0.555 | ppl 1.47 | wps 29238.6 | wpb 537.5 | bsz 16.7 | num_updates 8140 | best_loss 1.518\n",
            "2022-11-08 08:27:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint185.pt (epoch 185 @ 8140 updates, score 1.564) (writing took 0.422721847000048 seconds)\n",
            "2022-11-08 08:27:09 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)\n",
            "2022-11-08 08:27:09 | INFO | train | epoch 185 | loss 1.16 | nll_loss 0.208 | ppl 1.16 | wps 7041.2 | ups 14.29 | wpb 492.6 | bsz 15.9 | num_updates 8140 | lr 0.000701 | gnorm 0.707 | clip 100 | train_wall 2 | wall 580\n",
            "epoch 186:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:09 | INFO | fairseq.trainer | begin training epoch 186\n",
            "epoch 186:  95% 42/44 [00:02<00:00, 20.16it/s]2022-11-08 08:27:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 186 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 186 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:12 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 1.543 | nll_loss 0.534 | ppl 1.45 | wps 39342.9 | wpb 537.5 | bsz 16.7 | num_updates 8184 | best_loss 1.518\n",
            "2022-11-08 08:27:12 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint186.pt (epoch 186 @ 8184 updates, score 1.543) (writing took 0.4221073069999193 seconds)\n",
            "2022-11-08 08:27:12 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)\n",
            "2022-11-08 08:27:12 | INFO | train | epoch 186 | loss 1.158 | nll_loss 0.206 | ppl 1.15 | wps 7105.9 | ups 14.43 | wpb 492.6 | bsz 15.9 | num_updates 8184 | lr 0.000699113 | gnorm 0.623 | clip 95.5 | train_wall 2 | wall 583\n",
            "epoch 187:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:12 | INFO | fairseq.trainer | begin training epoch 187\n",
            "epoch 187:  95% 42/44 [00:02<00:00, 20.60it/s, loss=1.163, nll_loss=0.212, ppl=1.16, wps=7448.6, ups=14.74, wpb=505.5, bsz=15.9, num_updates=8200, lr=0.00069843, gnorm=0.657, clip=98, train_wall=5, wall=584]2022-11-08 08:27:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 187 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 187 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 18.62it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:15 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 1.577 | nll_loss 0.564 | ppl 1.48 | wps 30022.7 | wpb 537.5 | bsz 16.7 | num_updates 8228 | best_loss 1.518\n",
            "2022-11-08 08:27:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint187.pt (epoch 187 @ 8228 updates, score 1.577) (writing took 0.40891788299995824 seconds)\n",
            "2022-11-08 08:27:15 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)\n",
            "2022-11-08 08:27:15 | INFO | train | epoch 187 | loss 1.156 | nll_loss 0.203 | ppl 1.15 | wps 7148 | ups 14.51 | wpb 492.6 | bsz 15.9 | num_updates 8228 | lr 0.000697241 | gnorm 0.576 | clip 95.5 | train_wall 2 | wall 586\n",
            "epoch 188:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:15 | INFO | fairseq.trainer | begin training epoch 188\n",
            "epoch 188:  98% 43/44 [00:02<00:00, 18.67it/s]2022-11-08 08:27:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 188 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 188 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.99it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:18 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 1.581 | nll_loss 0.573 | ppl 1.49 | wps 37315.2 | wpb 537.5 | bsz 16.7 | num_updates 8272 | best_loss 1.518\n",
            "2022-11-08 08:27:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint188.pt (epoch 188 @ 8272 updates, score 1.581) (writing took 0.39727538200008894 seconds)\n",
            "2022-11-08 08:27:18 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)\n",
            "2022-11-08 08:27:18 | INFO | train | epoch 188 | loss 1.162 | nll_loss 0.21 | ppl 1.16 | wps 7100.1 | ups 14.41 | wpb 492.6 | bsz 15.9 | num_updates 8272 | lr 0.000695384 | gnorm 0.636 | clip 97.7 | train_wall 2 | wall 589\n",
            "epoch 189:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:18 | INFO | fairseq.trainer | begin training epoch 189\n",
            "epoch 189:  95% 42/44 [00:02<00:00, 18.87it/s, loss=1.155, nll_loss=0.203, ppl=1.15, wps=7128.1, ups=14.95, wpb=476.9, bsz=15.9, num_updates=8300, lr=0.00069421, gnorm=0.606, clip=96, train_wall=5, wall=591]2022-11-08 08:27:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 189 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 189 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.26it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:21 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 1.551 | nll_loss 0.544 | ppl 1.46 | wps 36157.2 | wpb 537.5 | bsz 16.7 | num_updates 8316 | best_loss 1.518\n",
            "2022-11-08 08:27:21 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:21 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint189.pt (epoch 189 @ 8316 updates, score 1.551) (writing took 0.4620560910000222 seconds)\n",
            "2022-11-08 08:27:21 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)\n",
            "2022-11-08 08:27:21 | INFO | train | epoch 189 | loss 1.157 | nll_loss 0.206 | ppl 1.15 | wps 6971.1 | ups 14.15 | wpb 492.6 | bsz 15.9 | num_updates 8316 | lr 0.000693542 | gnorm 0.644 | clip 97.7 | train_wall 2 | wall 592\n",
            "epoch 190:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:21 | INFO | fairseq.trainer | begin training epoch 190\n",
            "epoch 190:  98% 43/44 [00:02<00:00, 19.91it/s]2022-11-08 08:27:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 190 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 190 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 15.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:24 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 1.547 | nll_loss 0.542 | ppl 1.46 | wps 31853.4 | wpb 537.5 | bsz 16.7 | num_updates 8360 | best_loss 1.518\n",
            "2022-11-08 08:27:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint190.pt (epoch 190 @ 8360 updates, score 1.547) (writing took 0.3895852809999951 seconds)\n",
            "2022-11-08 08:27:24 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)\n",
            "2022-11-08 08:27:24 | INFO | train | epoch 190 | loss 1.157 | nll_loss 0.206 | ppl 1.15 | wps 7049 | ups 14.31 | wpb 492.6 | bsz 15.9 | num_updates 8360 | lr 0.000691714 | gnorm 0.566 | clip 95.5 | train_wall 2 | wall 595\n",
            "epoch 191:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:24 | INFO | fairseq.trainer | begin training epoch 191\n",
            "epoch 191:  98% 43/44 [00:02<00:00, 19.96it/s, loss=1.16, nll_loss=0.209, ppl=1.16, wps=7159.1, ups=14.53, wpb=492.6, bsz=15.9, num_updates=8400, lr=0.000690066, gnorm=0.629, clip=97, train_wall=5, wall=597]2022-11-08 08:27:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 191 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 191 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.91it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:27 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 1.558 | nll_loss 0.546 | ppl 1.46 | wps 27913.4 | wpb 537.5 | bsz 16.7 | num_updates 8404 | best_loss 1.518\n",
            "2022-11-08 08:27:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint191.pt (epoch 191 @ 8404 updates, score 1.558) (writing took 0.4311760260000028 seconds)\n",
            "2022-11-08 08:27:27 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)\n",
            "2022-11-08 08:27:27 | INFO | train | epoch 191 | loss 1.165 | nll_loss 0.214 | ppl 1.16 | wps 7017 | ups 14.25 | wpb 492.6 | bsz 15.9 | num_updates 8404 | lr 0.000689901 | gnorm 0.662 | clip 97.7 | train_wall 2 | wall 598\n",
            "epoch 192:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:27 | INFO | fairseq.trainer | begin training epoch 192\n",
            "epoch 192:  95% 42/44 [00:02<00:00, 19.09it/s]2022-11-08 08:27:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 192 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 192 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 18.98it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:30 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 1.544 | nll_loss 0.53 | ppl 1.44 | wps 34337.9 | wpb 537.5 | bsz 16.7 | num_updates 8448 | best_loss 1.518\n",
            "2022-11-08 08:27:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint192.pt (epoch 192 @ 8448 updates, score 1.544) (writing took 0.4176344810000501 seconds)\n",
            "2022-11-08 08:27:31 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)\n",
            "2022-11-08 08:27:31 | INFO | train | epoch 192 | loss 1.154 | nll_loss 0.203 | ppl 1.15 | wps 6914.2 | ups 14.04 | wpb 492.6 | bsz 15.9 | num_updates 8448 | lr 0.000688102 | gnorm 0.536 | clip 95.5 | train_wall 2 | wall 601\n",
            "epoch 193:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:31 | INFO | fairseq.trainer | begin training epoch 193\n",
            "epoch 193:  93% 41/44 [00:02<00:00, 18.97it/s]2022-11-08 08:27:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 193 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 193 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.34it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:33 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 1.572 | nll_loss 0.564 | ppl 1.48 | wps 36137.8 | wpb 537.5 | bsz 16.7 | num_updates 8492 | best_loss 1.518\n",
            "2022-11-08 08:27:33 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint193.pt (epoch 193 @ 8492 updates, score 1.572) (writing took 0.45215641400000095 seconds)\n",
            "2022-11-08 08:27:34 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)\n",
            "2022-11-08 08:27:34 | INFO | train | epoch 193 | loss 1.155 | nll_loss 0.203 | ppl 1.15 | wps 6824.4 | ups 13.85 | wpb 492.6 | bsz 15.9 | num_updates 8492 | lr 0.000686317 | gnorm 0.427 | clip 93.2 | train_wall 2 | wall 605\n",
            "epoch 194:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:34 | INFO | fairseq.trainer | begin training epoch 194\n",
            "epoch 194:  93% 41/44 [00:02<00:00, 19.70it/s, loss=1.155, nll_loss=0.203, ppl=1.15, wps=6473.5, ups=13.07, wpb=495.3, bsz=15.9, num_updates=8500, lr=0.000685994, gnorm=0.478, clip=94, train_wall=6, wall=605]2022-11-08 08:27:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 194 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 194 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.34it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:36 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 1.563 | nll_loss 0.556 | ppl 1.47 | wps 33005.2 | wpb 537.5 | bsz 16.7 | num_updates 8536 | best_loss 1.518\n",
            "2022-11-08 08:27:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint194.pt (epoch 194 @ 8536 updates, score 1.563) (writing took 0.4034428580000622 seconds)\n",
            "2022-11-08 08:27:37 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)\n",
            "2022-11-08 08:27:37 | INFO | train | epoch 194 | loss 1.154 | nll_loss 0.202 | ppl 1.15 | wps 7041.4 | ups 14.29 | wpb 492.6 | bsz 15.9 | num_updates 8536 | lr 0.000684546 | gnorm 0.457 | clip 90.9 | train_wall 2 | wall 608\n",
            "epoch 195:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:37 | INFO | fairseq.trainer | begin training epoch 195\n",
            "epoch 195:  93% 41/44 [00:02<00:00, 18.97it/s]2022-11-08 08:27:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 195 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 195 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.97it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:40 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 1.563 | nll_loss 0.549 | ppl 1.46 | wps 31132.9 | wpb 537.5 | bsz 16.7 | num_updates 8580 | best_loss 1.518\n",
            "2022-11-08 08:27:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint195.pt (epoch 195 @ 8580 updates, score 1.563) (writing took 0.44332369300002483 seconds)\n",
            "2022-11-08 08:27:40 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)\n",
            "2022-11-08 08:27:40 | INFO | train | epoch 195 | loss 1.153 | nll_loss 0.201 | ppl 1.15 | wps 6876.2 | ups 13.96 | wpb 492.6 | bsz 15.9 | num_updates 8580 | lr 0.000682789 | gnorm 0.618 | clip 100 | train_wall 2 | wall 611\n",
            "epoch 196:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:40 | INFO | fairseq.trainer | begin training epoch 196\n",
            "epoch 196:  95% 42/44 [00:02<00:00, 19.50it/s, loss=1.155, nll_loss=0.203, ppl=1.15, wps=7275.4, ups=14.52, wpb=500.9, bsz=15.9, num_updates=8600, lr=0.000681994, gnorm=0.55, clip=96, train_wall=5, wall=612]2022-11-08 08:27:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 196 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 196 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 17.64it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:43 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 1.554 | nll_loss 0.544 | ppl 1.46 | wps 38775.4 | wpb 537.5 | bsz 16.7 | num_updates 8624 | best_loss 1.518\n",
            "2022-11-08 08:27:43 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:43 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint196.pt (epoch 196 @ 8624 updates, score 1.554) (writing took 0.4107532870000341 seconds)\n",
            "2022-11-08 08:27:43 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)\n",
            "2022-11-08 08:27:43 | INFO | train | epoch 196 | loss 1.156 | nll_loss 0.203 | ppl 1.15 | wps 7133.7 | ups 14.48 | wpb 492.6 | bsz 15.9 | num_updates 8624 | lr 0.000681045 | gnorm 0.55 | clip 95.5 | train_wall 2 | wall 614\n",
            "epoch 197:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:43 | INFO | fairseq.trainer | begin training epoch 197\n",
            "epoch 197:  95% 42/44 [00:02<00:00, 19.18it/s]2022-11-08 08:27:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 197 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 197 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.70it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:46 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 1.579 | nll_loss 0.572 | ppl 1.49 | wps 34155.1 | wpb 537.5 | bsz 16.7 | num_updates 8668 | best_loss 1.518\n",
            "2022-11-08 08:27:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint197.pt (epoch 197 @ 8668 updates, score 1.579) (writing took 0.4505511840000054 seconds)\n",
            "2022-11-08 08:27:46 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)\n",
            "2022-11-08 08:27:46 | INFO | train | epoch 197 | loss 1.158 | nll_loss 0.206 | ppl 1.15 | wps 6978.9 | ups 14.17 | wpb 492.6 | bsz 15.9 | num_updates 8668 | lr 0.000679314 | gnorm 0.67 | clip 97.7 | train_wall 2 | wall 617\n",
            "epoch 198:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:46 | INFO | fairseq.trainer | begin training epoch 198\n",
            "epoch 198:  98% 43/44 [00:02<00:00, 19.46it/s, loss=1.156, nll_loss=0.204, ppl=1.15, wps=7165.8, ups=14.65, wpb=489.1, bsz=15.9, num_updates=8700, lr=0.000678064, gnorm=0.621, clip=95, train_wall=5, wall=619]2022-11-08 08:27:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 198 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 198 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.49it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:49 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 1.533 | nll_loss 0.517 | ppl 1.43 | wps 29772 | wpb 537.5 | bsz 16.7 | num_updates 8712 | best_loss 1.518\n",
            "2022-11-08 08:27:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint198.pt (epoch 198 @ 8712 updates, score 1.533) (writing took 0.4606506210000134 seconds)\n",
            "2022-11-08 08:27:49 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)\n",
            "2022-11-08 08:27:49 | INFO | train | epoch 198 | loss 1.153 | nll_loss 0.201 | ppl 1.15 | wps 6917.9 | ups 14.04 | wpb 492.6 | bsz 15.9 | num_updates 8712 | lr 0.000677596 | gnorm 0.557 | clip 90.9 | train_wall 2 | wall 620\n",
            "epoch 199:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:49 | INFO | fairseq.trainer | begin training epoch 199\n",
            "epoch 199:  98% 43/44 [00:02<00:00, 19.14it/s]2022-11-08 08:27:52 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 199 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 199 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.26it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:52 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 1.569 | nll_loss 0.562 | ppl 1.48 | wps 38308.6 | wpb 537.5 | bsz 16.7 | num_updates 8756 | best_loss 1.518\n",
            "2022-11-08 08:27:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint199.pt (epoch 199 @ 8756 updates, score 1.569) (writing took 0.4015755609999587 seconds)\n",
            "2022-11-08 08:27:52 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)\n",
            "2022-11-08 08:27:52 | INFO | train | epoch 199 | loss 1.152 | nll_loss 0.2 | ppl 1.15 | wps 7106.2 | ups 14.43 | wpb 492.6 | bsz 15.9 | num_updates 8756 | lr 0.000675892 | gnorm 0.589 | clip 93.2 | train_wall 2 | wall 623\n",
            "epoch 200:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:52 | INFO | fairseq.trainer | begin training epoch 200\n",
            "epoch 200:  95% 42/44 [00:02<00:00, 18.33it/s]2022-11-08 08:27:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 200 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 200 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.37it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:55 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 1.557 | nll_loss 0.542 | ppl 1.46 | wps 26848.5 | wpb 537.5 | bsz 16.7 | num_updates 8800 | best_loss 1.518\n",
            "2022-11-08 08:27:55 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint200.pt (epoch 200 @ 8800 updates, score 1.557) (writing took 0.43390828999997666 seconds)\n",
            "2022-11-08 08:27:55 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)\n",
            "2022-11-08 08:27:55 | INFO | train | epoch 200 | loss 1.153 | nll_loss 0.201 | ppl 1.15 | wps 6909.1 | ups 14.03 | wpb 492.6 | bsz 15.9 | num_updates 8800 | lr 0.0006742 | gnorm 0.543 | clip 97.7 | train_wall 2 | wall 626\n",
            "epoch 201:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:55 | INFO | fairseq.trainer | begin training epoch 201\n",
            "epoch 201:  98% 43/44 [00:02<00:00, 19.77it/s]2022-11-08 08:27:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 201 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 201 | valid on 'valid' subset:  67% 4/6 [00:00<00:00, 35.66it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:27:58 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 1.55 | nll_loss 0.535 | ppl 1.45 | wps 32453.9 | wpb 537.5 | bsz 16.7 | num_updates 8844 | best_loss 1.518\n",
            "2022-11-08 08:27:58 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:27:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint201.pt (epoch 201 @ 8844 updates, score 1.55) (writing took 0.40056522500003666 seconds)\n",
            "2022-11-08 08:27:59 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)\n",
            "2022-11-08 08:27:59 | INFO | train | epoch 201 | loss 1.155 | nll_loss 0.202 | ppl 1.15 | wps 7172 | ups 14.56 | wpb 492.6 | bsz 15.9 | num_updates 8844 | lr 0.000672521 | gnorm 0.582 | clip 97.7 | train_wall 2 | wall 629\n",
            "epoch 202:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:27:59 | INFO | fairseq.trainer | begin training epoch 202\n",
            "epoch 202:  93% 41/44 [00:02<00:00, 19.44it/s]2022-11-08 08:28:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 202 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 202 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.68it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:01 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 1.565 | nll_loss 0.553 | ppl 1.47 | wps 36180.7 | wpb 537.5 | bsz 16.7 | num_updates 8888 | best_loss 1.518\n",
            "2022-11-08 08:28:01 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint202.pt (epoch 202 @ 8888 updates, score 1.565) (writing took 0.42879725800003143 seconds)\n",
            "2022-11-08 08:28:02 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)\n",
            "2022-11-08 08:28:02 | INFO | train | epoch 202 | loss 1.155 | nll_loss 0.204 | ppl 1.15 | wps 6965.9 | ups 14.14 | wpb 492.6 | bsz 15.9 | num_updates 8888 | lr 0.000670854 | gnorm 0.669 | clip 97.7 | train_wall 2 | wall 632\n",
            "epoch 203:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:02 | INFO | fairseq.trainer | begin training epoch 203\n",
            "epoch 203:  93% 41/44 [00:02<00:00, 19.06it/s, loss=1.153, nll_loss=0.201, ppl=1.15, wps=6571.5, ups=13.29, wpb=494.5, bsz=15.9, num_updates=8900, lr=0.000670402, gnorm=0.651, clip=98, train_wall=5, wall=633]2022-11-08 08:28:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 203 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 203 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.37it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:04 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 1.562 | nll_loss 0.554 | ppl 1.47 | wps 28711.3 | wpb 537.5 | bsz 16.7 | num_updates 8932 | best_loss 1.518\n",
            "2022-11-08 08:28:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:05 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint203.pt (epoch 203 @ 8932 updates, score 1.562) (writing took 0.425405287999979 seconds)\n",
            "2022-11-08 08:28:05 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)\n",
            "2022-11-08 08:28:05 | INFO | train | epoch 203 | loss 1.147 | nll_loss 0.193 | ppl 1.14 | wps 6995.6 | ups 14.2 | wpb 492.6 | bsz 15.9 | num_updates 8932 | lr 0.0006692 | gnorm 0.625 | clip 90.9 | train_wall 2 | wall 635\n",
            "epoch 204:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:05 | INFO | fairseq.trainer | begin training epoch 204\n",
            "epoch 204:  95% 42/44 [00:02<00:00, 19.00it/s]2022-11-08 08:28:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 204 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 204 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.59it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:07 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 1.566 | nll_loss 0.554 | ppl 1.47 | wps 30049.9 | wpb 537.5 | bsz 16.7 | num_updates 8976 | best_loss 1.518\n",
            "2022-11-08 08:28:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint204.pt (epoch 204 @ 8976 updates, score 1.566) (writing took 0.44118125900001814 seconds)\n",
            "2022-11-08 08:28:08 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)\n",
            "2022-11-08 08:28:08 | INFO | train | epoch 204 | loss 1.148 | nll_loss 0.196 | ppl 1.15 | wps 6993.1 | ups 14.2 | wpb 492.6 | bsz 15.9 | num_updates 8976 | lr 0.000667557 | gnorm 0.466 | clip 93.2 | train_wall 2 | wall 639\n",
            "epoch 205:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:08 | INFO | fairseq.trainer | begin training epoch 205\n",
            "epoch 205:  98% 43/44 [00:02<00:00, 18.78it/s, loss=1.149, nll_loss=0.197, ppl=1.15, wps=7219.4, ups=14.58, wpb=495, bsz=15.9, num_updates=9000, lr=0.000666667, gnorm=0.497, clip=92, train_wall=5, wall=640]2022-11-08 08:28:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 205 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 205 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 18.58it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:11 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 1.562 | nll_loss 0.553 | ppl 1.47 | wps 34179.2 | wpb 537.5 | bsz 16.7 | num_updates 9020 | best_loss 1.518\n",
            "2022-11-08 08:28:11 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint205.pt (epoch 205 @ 9020 updates, score 1.562) (writing took 0.41653755000004367 seconds)\n",
            "2022-11-08 08:28:11 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)\n",
            "2022-11-08 08:28:11 | INFO | train | epoch 205 | loss 1.148 | nll_loss 0.197 | ppl 1.15 | wps 6971.6 | ups 14.15 | wpb 492.6 | bsz 15.9 | num_updates 9020 | lr 0.000665927 | gnorm 0.478 | clip 95.5 | train_wall 2 | wall 642\n",
            "epoch 206:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:11 | INFO | fairseq.trainer | begin training epoch 206\n",
            "epoch 206:  95% 42/44 [00:02<00:00, 19.72it/s]2022-11-08 08:28:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 206 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 206 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.86it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:14 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 1.561 | nll_loss 0.548 | ppl 1.46 | wps 29601.7 | wpb 537.5 | bsz 16.7 | num_updates 9064 | best_loss 1.518\n",
            "2022-11-08 08:28:14 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint206.pt (epoch 206 @ 9064 updates, score 1.561) (writing took 0.4221632750000026 seconds)\n",
            "2022-11-08 08:28:14 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)\n",
            "2022-11-08 08:28:14 | INFO | train | epoch 206 | loss 1.149 | nll_loss 0.195 | ppl 1.15 | wps 7108.3 | ups 14.43 | wpb 492.6 | bsz 15.9 | num_updates 9064 | lr 0.000664309 | gnorm 0.54 | clip 95.5 | train_wall 2 | wall 645\n",
            "epoch 207:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:14 | INFO | fairseq.trainer | begin training epoch 207\n",
            "epoch 207:  95% 42/44 [00:02<00:00, 19.00it/s, loss=1.15, nll_loss=0.198, ppl=1.15, wps=7166.9, ups=14.6, wpb=491, bsz=15.9, num_updates=9100, lr=0.000662994, gnorm=0.488, clip=95, train_wall=5, wall=647]2022-11-08 08:28:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 207 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 207 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.94it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:17 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 1.545 | nll_loss 0.534 | ppl 1.45 | wps 30912.9 | wpb 537.5 | bsz 16.7 | num_updates 9108 | best_loss 1.518\n",
            "2022-11-08 08:28:17 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint207.pt (epoch 207 @ 9108 updates, score 1.545) (writing took 0.41540764299998045 seconds)\n",
            "2022-11-08 08:28:17 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)\n",
            "2022-11-08 08:28:17 | INFO | train | epoch 207 | loss 1.153 | nll_loss 0.201 | ppl 1.15 | wps 6971.6 | ups 14.15 | wpb 492.6 | bsz 15.9 | num_updates 9108 | lr 0.000662702 | gnorm 0.483 | clip 95.5 | train_wall 2 | wall 648\n",
            "epoch 208:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:17 | INFO | fairseq.trainer | begin training epoch 208\n",
            "epoch 208:  98% 43/44 [00:02<00:00, 19.38it/s]2022-11-08 08:28:20 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 208 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 208 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 17.08it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:20 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 1.558 | nll_loss 0.548 | ppl 1.46 | wps 27722.4 | wpb 537.5 | bsz 16.7 | num_updates 9152 | best_loss 1.518\n",
            "2022-11-08 08:28:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint208.pt (epoch 208 @ 9152 updates, score 1.558) (writing took 0.4310218549999263 seconds)\n",
            "2022-11-08 08:28:20 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)\n",
            "2022-11-08 08:28:20 | INFO | train | epoch 208 | loss 1.15 | nll_loss 0.199 | ppl 1.15 | wps 6970.3 | ups 14.15 | wpb 492.6 | bsz 15.9 | num_updates 9152 | lr 0.000661107 | gnorm 0.466 | clip 95.5 | train_wall 2 | wall 651\n",
            "epoch 209:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:20 | INFO | fairseq.trainer | begin training epoch 209\n",
            "epoch 209:  93% 41/44 [00:02<00:00, 19.17it/s]2022-11-08 08:28:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 209 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 209 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 17.93it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:23 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 1.564 | nll_loss 0.555 | ppl 1.47 | wps 36163.9 | wpb 537.5 | bsz 16.7 | num_updates 9196 | best_loss 1.518\n",
            "2022-11-08 08:28:23 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint209.pt (epoch 209 @ 9196 updates, score 1.564) (writing took 0.43197505399996317 seconds)\n",
            "2022-11-08 08:28:23 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)\n",
            "2022-11-08 08:28:23 | INFO | train | epoch 209 | loss 1.148 | nll_loss 0.196 | ppl 1.15 | wps 6941 | ups 14.09 | wpb 492.6 | bsz 15.9 | num_updates 9196 | lr 0.000659524 | gnorm 0.49 | clip 95.5 | train_wall 2 | wall 654\n",
            "epoch 210:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:23 | INFO | fairseq.trainer | begin training epoch 210\n",
            "epoch 210:  95% 42/44 [00:02<00:00, 18.74it/s, loss=1.148, nll_loss=0.195, ppl=1.15, wps=6477.9, ups=13.25, wpb=488.9, bsz=15.9, num_updates=9200, lr=0.00065938, gnorm=0.492, clip=96, train_wall=5, wall=654]2022-11-08 08:28:26 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 210 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 210 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.69it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:26 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 1.565 | nll_loss 0.558 | ppl 1.47 | wps 33762.5 | wpb 537.5 | bsz 16.7 | num_updates 9240 | best_loss 1.518\n",
            "2022-11-08 08:28:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint210.pt (epoch 210 @ 9240 updates, score 1.565) (writing took 0.43387913899994146 seconds)\n",
            "2022-11-08 08:28:26 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)\n",
            "2022-11-08 08:28:26 | INFO | train | epoch 210 | loss 1.148 | nll_loss 0.197 | ppl 1.15 | wps 7065.7 | ups 14.34 | wpb 492.6 | bsz 15.9 | num_updates 9240 | lr 0.000657952 | gnorm 0.507 | clip 90.9 | train_wall 2 | wall 657\n",
            "epoch 211:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:26 | INFO | fairseq.trainer | begin training epoch 211\n",
            "epoch 211:  93% 41/44 [00:02<00:00, 19.23it/s]2022-11-08 08:28:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 211 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 211 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.81it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:29 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 1.554 | nll_loss 0.545 | ppl 1.46 | wps 32920.9 | wpb 537.5 | bsz 16.7 | num_updates 9284 | best_loss 1.518\n",
            "2022-11-08 08:28:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint211.pt (epoch 211 @ 9284 updates, score 1.554) (writing took 0.426091778 seconds)\n",
            "2022-11-08 08:28:29 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)\n",
            "2022-11-08 08:28:29 | INFO | train | epoch 211 | loss 1.142 | nll_loss 0.19 | ppl 1.14 | wps 7063.1 | ups 14.34 | wpb 492.6 | bsz 15.9 | num_updates 9284 | lr 0.000656391 | gnorm 0.467 | clip 88.6 | train_wall 2 | wall 660\n",
            "epoch 212:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:29 | INFO | fairseq.trainer | begin training epoch 212\n",
            "epoch 212:  95% 42/44 [00:02<00:00, 19.17it/s, loss=1.144, nll_loss=0.192, ppl=1.14, wps=7206.9, ups=14.54, wpb=495.8, bsz=15.9, num_updates=9300, lr=0.000655826, gnorm=0.494, clip=90, train_wall=5, wall=661]2022-11-08 08:28:32 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 212 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 212 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.63it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:32 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 1.579 | nll_loss 0.571 | ppl 1.49 | wps 28433.8 | wpb 537.5 | bsz 16.7 | num_updates 9328 | best_loss 1.518\n",
            "2022-11-08 08:28:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint212.pt (epoch 212 @ 9328 updates, score 1.579) (writing took 0.43394174800005203 seconds)\n",
            "2022-11-08 08:28:33 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)\n",
            "2022-11-08 08:28:33 | INFO | train | epoch 212 | loss 1.148 | nll_loss 0.196 | ppl 1.15 | wps 6763.3 | ups 13.73 | wpb 492.6 | bsz 15.9 | num_updates 9328 | lr 0.000654841 | gnorm 0.523 | clip 86.4 | train_wall 2 | wall 663\n",
            "epoch 213:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:33 | INFO | fairseq.trainer | begin training epoch 213\n",
            "epoch 213:  95% 42/44 [00:02<00:00, 18.98it/s]2022-11-08 08:28:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 213 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 213 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.69it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:35 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 1.581 | nll_loss 0.569 | ppl 1.48 | wps 29017 | wpb 537.5 | bsz 16.7 | num_updates 9372 | best_loss 1.518\n",
            "2022-11-08 08:28:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint213.pt (epoch 213 @ 9372 updates, score 1.581) (writing took 0.4680969940000068 seconds)\n",
            "2022-11-08 08:28:36 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)\n",
            "2022-11-08 08:28:36 | INFO | train | epoch 213 | loss 1.148 | nll_loss 0.197 | ppl 1.15 | wps 6934.4 | ups 14.08 | wpb 492.6 | bsz 15.9 | num_updates 9372 | lr 0.000653302 | gnorm 0.517 | clip 88.6 | train_wall 2 | wall 667\n",
            "epoch 214:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:36 | INFO | fairseq.trainer | begin training epoch 214\n",
            "epoch 214:  98% 43/44 [00:02<00:00, 19.39it/s, loss=1.15, nll_loss=0.199, ppl=1.15, wps=7060.8, ups=14.45, wpb=488.8, bsz=15.9, num_updates=9400, lr=0.000652328, gnorm=0.595, clip=89, train_wall=5, wall=668]2022-11-08 08:28:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 214 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 214 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.16it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:38 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 1.587 | nll_loss 0.578 | ppl 1.49 | wps 33309.6 | wpb 537.5 | bsz 16.7 | num_updates 9416 | best_loss 1.518\n",
            "2022-11-08 08:28:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint214.pt (epoch 214 @ 9416 updates, score 1.587) (writing took 0.45139778600002955 seconds)\n",
            "2022-11-08 08:28:39 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)\n",
            "2022-11-08 08:28:39 | INFO | train | epoch 214 | loss 1.146 | nll_loss 0.193 | ppl 1.14 | wps 6974.1 | ups 14.16 | wpb 492.6 | bsz 15.9 | num_updates 9416 | lr 0.000651774 | gnorm 0.723 | clip 95.5 | train_wall 2 | wall 670\n",
            "epoch 215:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:39 | INFO | fairseq.trainer | begin training epoch 215\n",
            "epoch 215:  98% 43/44 [00:02<00:00, 19.42it/s]2022-11-08 08:28:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 215 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 215 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.30it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:42 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 1.554 | nll_loss 0.541 | ppl 1.46 | wps 31766.2 | wpb 537.5 | bsz 16.7 | num_updates 9460 | best_loss 1.518\n",
            "2022-11-08 08:28:42 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint215.pt (epoch 215 @ 9460 updates, score 1.554) (writing took 0.4465060029999677 seconds)\n",
            "2022-11-08 08:28:42 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)\n",
            "2022-11-08 08:28:42 | INFO | train | epoch 215 | loss 1.146 | nll_loss 0.194 | ppl 1.14 | wps 6906.1 | ups 14.02 | wpb 492.6 | bsz 15.9 | num_updates 9460 | lr 0.000650256 | gnorm 0.656 | clip 95.5 | train_wall 2 | wall 673\n",
            "epoch 216:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:42 | INFO | fairseq.trainer | begin training epoch 216\n",
            "epoch 216:  95% 42/44 [00:02<00:00, 19.39it/s, loss=1.148, nll_loss=0.196, ppl=1.15, wps=7176.3, ups=14.45, wpb=496.7, bsz=15.9, num_updates=9500, lr=0.000648886, gnorm=0.612, clip=96, train_wall=5, wall=675]2022-11-08 08:28:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 216 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 216 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.44it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:45 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 1.567 | nll_loss 0.557 | ppl 1.47 | wps 34650.2 | wpb 537.5 | bsz 16.7 | num_updates 9504 | best_loss 1.518\n",
            "2022-11-08 08:28:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint216.pt (epoch 216 @ 9504 updates, score 1.567) (writing took 0.46494292400007 seconds)\n",
            "2022-11-08 08:28:45 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)\n",
            "2022-11-08 08:28:45 | INFO | train | epoch 216 | loss 1.151 | nll_loss 0.2 | ppl 1.15 | wps 6898.4 | ups 14 | wpb 492.6 | bsz 15.9 | num_updates 9504 | lr 0.000648749 | gnorm 0.554 | clip 97.7 | train_wall 2 | wall 676\n",
            "epoch 217:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:45 | INFO | fairseq.trainer | begin training epoch 217\n",
            "epoch 217:  98% 43/44 [00:02<00:00, 19.66it/s]2022-11-08 08:28:48 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 217 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 217 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 17.28it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:48 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 1.536 | nll_loss 0.526 | ppl 1.44 | wps 34432.1 | wpb 537.5 | bsz 16.7 | num_updates 9548 | best_loss 1.518\n",
            "2022-11-08 08:28:48 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint217.pt (epoch 217 @ 9548 updates, score 1.536) (writing took 0.4351120809999429 seconds)\n",
            "2022-11-08 08:28:48 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)\n",
            "2022-11-08 08:28:48 | INFO | train | epoch 217 | loss 1.142 | nll_loss 0.191 | ppl 1.14 | wps 6867.9 | ups 13.94 | wpb 492.6 | bsz 15.9 | num_updates 9548 | lr 0.000647253 | gnorm 0.49 | clip 88.6 | train_wall 2 | wall 679\n",
            "epoch 218:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:48 | INFO | fairseq.trainer | begin training epoch 218\n",
            "epoch 218:  95% 42/44 [00:02<00:00, 19.12it/s]2022-11-08 08:28:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 218 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 218 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.50it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:51 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 1.546 | nll_loss 0.538 | ppl 1.45 | wps 32608.9 | wpb 537.5 | bsz 16.7 | num_updates 9592 | best_loss 1.518\n",
            "2022-11-08 08:28:51 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint218.pt (epoch 218 @ 9592 updates, score 1.546) (writing took 0.43723568500001875 seconds)\n",
            "2022-11-08 08:28:52 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)\n",
            "2022-11-08 08:28:52 | INFO | train | epoch 218 | loss 1.146 | nll_loss 0.193 | ppl 1.14 | wps 6742.4 | ups 13.69 | wpb 492.6 | bsz 15.9 | num_updates 9592 | lr 0.000645766 | gnorm 0.495 | clip 95.5 | train_wall 2 | wall 682\n",
            "epoch 219:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:52 | INFO | fairseq.trainer | begin training epoch 219\n",
            "epoch 219:  98% 43/44 [00:02<00:00, 19.56it/s, loss=1.143, nll_loss=0.191, ppl=1.14, wps=6311, ups=12.93, wpb=488.3, bsz=15.9, num_updates=9600, lr=0.000645497, gnorm=0.496, clip=92, train_wall=6, wall=683]2022-11-08 08:28:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 219 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 219 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.72it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:54 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 1.584 | nll_loss 0.576 | ppl 1.49 | wps 30935.9 | wpb 537.5 | bsz 16.7 | num_updates 9636 | best_loss 1.518\n",
            "2022-11-08 08:28:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint219.pt (epoch 219 @ 9636 updates, score 1.584) (writing took 0.4150300789999619 seconds)\n",
            "2022-11-08 08:28:55 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)\n",
            "2022-11-08 08:28:55 | INFO | train | epoch 219 | loss 1.14 | nll_loss 0.188 | ppl 1.14 | wps 6817.4 | ups 13.84 | wpb 492.6 | bsz 15.9 | num_updates 9636 | lr 0.00064429 | gnorm 0.453 | clip 90.9 | train_wall 2 | wall 686\n",
            "epoch 220:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:55 | INFO | fairseq.trainer | begin training epoch 220\n",
            "epoch 220:  95% 42/44 [00:02<00:00, 19.96it/s]2022-11-08 08:28:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 220 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 220 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.19it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:28:57 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 1.553 | nll_loss 0.543 | ppl 1.46 | wps 35994.5 | wpb 537.5 | bsz 16.7 | num_updates 9680 | best_loss 1.518\n",
            "2022-11-08 08:28:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:28:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint220.pt (epoch 220 @ 9680 updates, score 1.553) (writing took 0.4295544469999868 seconds)\n",
            "2022-11-08 08:28:58 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)\n",
            "2022-11-08 08:28:58 | INFO | train | epoch 220 | loss 1.145 | nll_loss 0.193 | ppl 1.14 | wps 7115.5 | ups 14.45 | wpb 492.6 | bsz 15.9 | num_updates 9680 | lr 0.000642824 | gnorm 0.465 | clip 93.2 | train_wall 2 | wall 689\n",
            "epoch 221:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:28:58 | INFO | fairseq.trainer | begin training epoch 221\n",
            "epoch 221:  98% 43/44 [00:02<00:00, 20.10it/s, loss=1.144, nll_loss=0.192, ppl=1.14, wps=7299.3, ups=14.55, wpb=501.8, bsz=15.9, num_updates=9700, lr=0.000642161, gnorm=0.457, clip=92, train_wall=5, wall=690]2022-11-08 08:29:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 221 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 221 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.82it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:00 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 1.584 | nll_loss 0.574 | ppl 1.49 | wps 29062 | wpb 537.5 | bsz 16.7 | num_updates 9724 | best_loss 1.518\n",
            "2022-11-08 08:29:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:01 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint221.pt (epoch 221 @ 9724 updates, score 1.584) (writing took 0.4335908779999045 seconds)\n",
            "2022-11-08 08:29:01 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)\n",
            "2022-11-08 08:29:01 | INFO | train | epoch 221 | loss 1.142 | nll_loss 0.19 | ppl 1.14 | wps 7064 | ups 14.34 | wpb 492.6 | bsz 15.9 | num_updates 9724 | lr 0.000641368 | gnorm 0.526 | clip 93.2 | train_wall 2 | wall 692\n",
            "epoch 222:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:01 | INFO | fairseq.trainer | begin training epoch 222\n",
            "epoch 222:  98% 43/44 [00:02<00:00, 19.71it/s]2022-11-08 08:29:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 222 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 222 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.84it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:03 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 1.541 | nll_loss 0.53 | ppl 1.44 | wps 36622.9 | wpb 537.5 | bsz 16.7 | num_updates 9768 | best_loss 1.518\n",
            "2022-11-08 08:29:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint222.pt (epoch 222 @ 9768 updates, score 1.541) (writing took 0.4361426240000128 seconds)\n",
            "2022-11-08 08:29:04 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)\n",
            "2022-11-08 08:29:04 | INFO | train | epoch 222 | loss 1.146 | nll_loss 0.194 | ppl 1.14 | wps 7072.6 | ups 14.36 | wpb 492.6 | bsz 15.9 | num_updates 9768 | lr 0.000639922 | gnorm 0.573 | clip 81.8 | train_wall 2 | wall 695\n",
            "epoch 223:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:04 | INFO | fairseq.trainer | begin training epoch 223\n",
            "epoch 223:  98% 43/44 [00:02<00:00, 20.37it/s, loss=1.142, nll_loss=0.19, ppl=1.14, wps=7100, ups=14.65, wpb=484.6, bsz=15.9, num_updates=9800, lr=0.000638877, gnorm=0.559, clip=91, train_wall=5, wall=697]2022-11-08 08:29:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 223 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 223 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.16it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:07 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 1.557 | nll_loss 0.548 | ppl 1.46 | wps 29486.8 | wpb 537.5 | bsz 16.7 | num_updates 9812 | best_loss 1.518\n",
            "2022-11-08 08:29:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint223.pt (epoch 223 @ 9812 updates, score 1.557) (writing took 0.4363711769999554 seconds)\n",
            "2022-11-08 08:29:07 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)\n",
            "2022-11-08 08:29:07 | INFO | train | epoch 223 | loss 1.14 | nll_loss 0.187 | ppl 1.14 | wps 6985 | ups 14.18 | wpb 492.6 | bsz 15.9 | num_updates 9812 | lr 0.000638486 | gnorm 0.558 | clip 97.7 | train_wall 2 | wall 698\n",
            "epoch 224:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:07 | INFO | fairseq.trainer | begin training epoch 224\n",
            "epoch 224:  93% 41/44 [00:02<00:00, 18.88it/s]2022-11-08 08:29:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 224 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 224 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 18.78it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:10 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 1.548 | nll_loss 0.536 | ppl 1.45 | wps 38945 | wpb 537.5 | bsz 16.7 | num_updates 9856 | best_loss 1.518\n",
            "2022-11-08 08:29:10 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint224.pt (epoch 224 @ 9856 updates, score 1.548) (writing took 0.43037666400005037 seconds)\n",
            "2022-11-08 08:29:10 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)\n",
            "2022-11-08 08:29:10 | INFO | train | epoch 224 | loss 1.147 | nll_loss 0.197 | ppl 1.15 | wps 6971.5 | ups 14.15 | wpb 492.6 | bsz 15.9 | num_updates 9856 | lr 0.000637059 | gnorm 0.537 | clip 95.5 | train_wall 2 | wall 701\n",
            "epoch 225:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:10 | INFO | fairseq.trainer | begin training epoch 225\n",
            "epoch 225:  95% 42/44 [00:02<00:00, 19.62it/s]2022-11-08 08:29:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 225 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 225 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.92it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:13 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 1.538 | nll_loss 0.525 | ppl 1.44 | wps 32979.3 | wpb 537.5 | bsz 16.7 | num_updates 9900 | best_loss 1.518\n",
            "2022-11-08 08:29:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint225.pt (epoch 225 @ 9900 updates, score 1.538) (writing took 0.4454182869999386 seconds)\n",
            "2022-11-08 08:29:13 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)\n",
            "2022-11-08 08:29:13 | INFO | train | epoch 225 | loss 1.14 | nll_loss 0.188 | ppl 1.14 | wps 6986.8 | ups 14.18 | wpb 492.6 | bsz 15.9 | num_updates 9900 | lr 0.000635642 | gnorm 0.513 | clip 86.4 | train_wall 2 | wall 704\n",
            "epoch 226:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:13 | INFO | fairseq.trainer | begin training epoch 226\n",
            "epoch 226:  93% 41/44 [00:02<00:00, 19.50it/s]2022-11-08 08:29:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 226 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 226 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.07it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:16 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 1.538 | nll_loss 0.524 | ppl 1.44 | wps 34641.2 | wpb 537.5 | bsz 16.7 | num_updates 9944 | best_loss 1.518\n",
            "2022-11-08 08:29:16 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint226.pt (epoch 226 @ 9944 updates, score 1.538) (writing took 0.43472749600005045 seconds)\n",
            "2022-11-08 08:29:16 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)\n",
            "2022-11-08 08:29:16 | INFO | train | epoch 226 | loss 1.141 | nll_loss 0.187 | ppl 1.14 | wps 7018 | ups 14.25 | wpb 492.6 | bsz 15.9 | num_updates 9944 | lr 0.000634234 | gnorm 0.52 | clip 90.9 | train_wall 2 | wall 707\n",
            "epoch 227:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:16 | INFO | fairseq.trainer | begin training epoch 227\n",
            "epoch 227:  95% 42/44 [00:02<00:00, 18.24it/s]2022-11-08 08:29:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 227 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 227 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.54it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:19 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 1.541 | nll_loss 0.532 | ppl 1.45 | wps 34216.2 | wpb 537.5 | bsz 16.7 | num_updates 9988 | best_loss 1.518\n",
            "2022-11-08 08:29:19 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint227.pt (epoch 227 @ 9988 updates, score 1.541) (writing took 0.4419704829999773 seconds)\n",
            "2022-11-08 08:29:19 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)\n",
            "2022-11-08 08:29:19 | INFO | train | epoch 227 | loss 1.139 | nll_loss 0.187 | ppl 1.14 | wps 6862.9 | ups 13.93 | wpb 492.6 | bsz 15.9 | num_updates 9988 | lr 0.000632835 | gnorm 0.464 | clip 90.9 | train_wall 2 | wall 710\n",
            "epoch 228:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:19 | INFO | fairseq.trainer | begin training epoch 228\n",
            "epoch 228:  98% 43/44 [00:02<00:00, 19.48it/s, loss=1.14, nll_loss=0.187, ppl=1.14, wps=6445.6, ups=13.1, wpb=491.9, bsz=15.9, num_updates=10000, lr=0.000632456, gnorm=0.526, clip=91, train_wall=6, wall=711]2022-11-08 08:29:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 228 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 228 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.09it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:22 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 1.579 | nll_loss 0.568 | ppl 1.48 | wps 35505.8 | wpb 537.5 | bsz 16.7 | num_updates 10032 | best_loss 1.518\n",
            "2022-11-08 08:29:22 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint228.pt (epoch 228 @ 10032 updates, score 1.579) (writing took 0.43798314000002847 seconds)\n",
            "2022-11-08 08:29:23 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)\n",
            "2022-11-08 08:29:23 | INFO | train | epoch 228 | loss 1.141 | nll_loss 0.19 | ppl 1.14 | wps 6967.3 | ups 14.14 | wpb 492.6 | bsz 15.9 | num_updates 10032 | lr 0.000631446 | gnorm 0.503 | clip 88.6 | train_wall 2 | wall 713\n",
            "epoch 229:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:23 | INFO | fairseq.trainer | begin training epoch 229\n",
            "epoch 229:  98% 43/44 [00:02<00:00, 19.78it/s]2022-11-08 08:29:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 229 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 229 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 17.95it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:25 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 1.574 | nll_loss 0.561 | ppl 1.48 | wps 41415.7 | wpb 537.5 | bsz 16.7 | num_updates 10076 | best_loss 1.518\n",
            "2022-11-08 08:29:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint229.pt (epoch 229 @ 10076 updates, score 1.574) (writing took 0.44082757299997866 seconds)\n",
            "2022-11-08 08:29:26 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)\n",
            "2022-11-08 08:29:26 | INFO | train | epoch 229 | loss 1.142 | nll_loss 0.19 | ppl 1.14 | wps 6967.4 | ups 14.14 | wpb 492.6 | bsz 15.9 | num_updates 10076 | lr 0.000630066 | gnorm 0.548 | clip 93.2 | train_wall 2 | wall 716\n",
            "epoch 230:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:26 | INFO | fairseq.trainer | begin training epoch 230\n",
            "epoch 230:  95% 42/44 [00:02<00:00, 19.18it/s, loss=1.143, nll_loss=0.19, ppl=1.14, wps=7210.8, ups=14.53, wpb=496.2, bsz=15.9, num_updates=10100, lr=0.000629317, gnorm=0.509, clip=92, train_wall=5, wall=718]2022-11-08 08:29:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 230 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 230 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.89it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:28 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 1.559 | nll_loss 0.55 | ppl 1.46 | wps 29653.3 | wpb 537.5 | bsz 16.7 | num_updates 10120 | best_loss 1.518\n",
            "2022-11-08 08:29:28 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:29 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint230.pt (epoch 230 @ 10120 updates, score 1.559) (writing took 0.4392222540000148 seconds)\n",
            "2022-11-08 08:29:29 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)\n",
            "2022-11-08 08:29:29 | INFO | train | epoch 230 | loss 1.14 | nll_loss 0.187 | ppl 1.14 | wps 7050.3 | ups 14.31 | wpb 492.6 | bsz 15.9 | num_updates 10120 | lr 0.000628695 | gnorm 0.543 | clip 97.7 | train_wall 2 | wall 720\n",
            "epoch 231:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:29 | INFO | fairseq.trainer | begin training epoch 231\n",
            "epoch 231:  98% 43/44 [00:02<00:00, 20.35it/s]2022-11-08 08:29:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 231 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 231 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 17.36it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:31 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 1.575 | nll_loss 0.569 | ppl 1.48 | wps 39559.2 | wpb 537.5 | bsz 16.7 | num_updates 10164 | best_loss 1.518\n",
            "2022-11-08 08:29:31 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint231.pt (epoch 231 @ 10164 updates, score 1.575) (writing took 0.44630297200001223 seconds)\n",
            "2022-11-08 08:29:32 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)\n",
            "2022-11-08 08:29:32 | INFO | train | epoch 231 | loss 1.142 | nll_loss 0.19 | ppl 1.14 | wps 7011.1 | ups 14.23 | wpb 492.6 | bsz 15.9 | num_updates 10164 | lr 0.000627332 | gnorm 0.46 | clip 84.1 | train_wall 2 | wall 723\n",
            "epoch 232:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:32 | INFO | fairseq.trainer | begin training epoch 232\n",
            "epoch 232:  98% 43/44 [00:02<00:00, 18.89it/s, loss=1.139, nll_loss=0.187, ppl=1.14, wps=7048.9, ups=14.62, wpb=482.1, bsz=16, num_updates=10200, lr=0.000626224, gnorm=0.481, clip=91, train_wall=5, wall=725]2022-11-08 08:29:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 232 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 232 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.61it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:35 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 1.573 | nll_loss 0.559 | ppl 1.47 | wps 30034.2 | wpb 537.5 | bsz 16.7 | num_updates 10208 | best_loss 1.518\n",
            "2022-11-08 08:29:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint232.pt (epoch 232 @ 10208 updates, score 1.573) (writing took 0.44237936600006833 seconds)\n",
            "2022-11-08 08:29:35 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)\n",
            "2022-11-08 08:29:35 | INFO | train | epoch 232 | loss 1.142 | nll_loss 0.19 | ppl 1.14 | wps 6964 | ups 14.14 | wpb 492.6 | bsz 15.9 | num_updates 10208 | lr 0.000625979 | gnorm 0.505 | clip 93.2 | train_wall 2 | wall 726\n",
            "epoch 233:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:35 | INFO | fairseq.trainer | begin training epoch 233\n",
            "epoch 233:  95% 42/44 [00:02<00:00, 19.20it/s]2022-11-08 08:29:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 233 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 233 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.75it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:38 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 1.569 | nll_loss 0.558 | ppl 1.47 | wps 27752.9 | wpb 537.5 | bsz 16.7 | num_updates 10252 | best_loss 1.518\n",
            "2022-11-08 08:29:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint233.pt (epoch 233 @ 10252 updates, score 1.569) (writing took 0.38723405600001115 seconds)\n",
            "2022-11-08 08:29:38 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)\n",
            "2022-11-08 08:29:38 | INFO | train | epoch 233 | loss 1.137 | nll_loss 0.184 | ppl 1.14 | wps 7128.8 | ups 14.47 | wpb 492.6 | bsz 15.9 | num_updates 10252 | lr 0.000624634 | gnorm 0.388 | clip 86.4 | train_wall 2 | wall 729\n",
            "epoch 234:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:38 | INFO | fairseq.trainer | begin training epoch 234\n",
            "epoch 234:  98% 43/44 [00:02<00:00, 19.40it/s]2022-11-08 08:29:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 234 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 234 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.71it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:41 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 1.562 | nll_loss 0.553 | ppl 1.47 | wps 38376.1 | wpb 537.5 | bsz 16.7 | num_updates 10296 | best_loss 1.518\n",
            "2022-11-08 08:29:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint234.pt (epoch 234 @ 10296 updates, score 1.562) (writing took 0.4582135279999875 seconds)\n",
            "2022-11-08 08:29:41 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)\n",
            "2022-11-08 08:29:41 | INFO | train | epoch 234 | loss 1.137 | nll_loss 0.185 | ppl 1.14 | wps 6839.2 | ups 13.88 | wpb 492.6 | bsz 15.9 | num_updates 10296 | lr 0.000623298 | gnorm 0.589 | clip 84.1 | train_wall 2 | wall 732\n",
            "epoch 235:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:41 | INFO | fairseq.trainer | begin training epoch 235\n",
            "epoch 235:  98% 43/44 [00:02<00:00, 19.51it/s, loss=1.142, nll_loss=0.191, ppl=1.14, wps=6694.9, ups=13.25, wpb=505.3, bsz=15.8, num_updates=10300, lr=0.000623177, gnorm=0.502, clip=86, train_wall=5, wall=732]2022-11-08 08:29:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 235 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 235 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 28.51it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:44 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 1.549 | nll_loss 0.536 | ppl 1.45 | wps 34518.9 | wpb 537.5 | bsz 16.7 | num_updates 10340 | best_loss 1.518\n",
            "2022-11-08 08:29:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint235.pt (epoch 235 @ 10340 updates, score 1.549) (writing took 0.43221512299999176 seconds)\n",
            "2022-11-08 08:29:44 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)\n",
            "2022-11-08 08:29:44 | INFO | train | epoch 235 | loss 1.14 | nll_loss 0.188 | ppl 1.14 | wps 7022.4 | ups 14.26 | wpb 492.6 | bsz 15.9 | num_updates 10340 | lr 0.00062197 | gnorm 0.413 | clip 95.5 | train_wall 2 | wall 735\n",
            "epoch 236:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:44 | INFO | fairseq.trainer | begin training epoch 236\n",
            "epoch 236:  98% 43/44 [00:02<00:00, 19.94it/s]2022-11-08 08:29:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 236 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 236 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 18.07it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:47 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 1.57 | nll_loss 0.56 | ppl 1.47 | wps 35726.6 | wpb 537.5 | bsz 16.7 | num_updates 10384 | best_loss 1.518\n",
            "2022-11-08 08:29:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint236.pt (epoch 236 @ 10384 updates, score 1.57) (writing took 0.481821031000095 seconds)\n",
            "2022-11-08 08:29:47 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)\n",
            "2022-11-08 08:29:47 | INFO | train | epoch 236 | loss 1.143 | nll_loss 0.191 | ppl 1.14 | wps 6986.7 | ups 14.18 | wpb 492.6 | bsz 15.9 | num_updates 10384 | lr 0.000620651 | gnorm 0.638 | clip 95.5 | train_wall 2 | wall 738\n",
            "epoch 237:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:47 | INFO | fairseq.trainer | begin training epoch 237\n",
            "epoch 237:  98% 43/44 [00:02<00:00, 19.58it/s, loss=1.14, nll_loss=0.189, ppl=1.14, wps=7206.5, ups=14.48, wpb=497.6, bsz=15.9, num_updates=10400, lr=0.000620174, gnorm=0.522, clip=96, train_wall=5, wall=739]2022-11-08 08:29:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 237 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 237 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 17.33it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:50 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 1.574 | nll_loss 0.564 | ppl 1.48 | wps 34188.3 | wpb 537.5 | bsz 16.7 | num_updates 10428 | best_loss 1.518\n",
            "2022-11-08 08:29:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint237.pt (epoch 237 @ 10428 updates, score 1.574) (writing took 0.42664171100000203 seconds)\n",
            "2022-11-08 08:29:51 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)\n",
            "2022-11-08 08:29:51 | INFO | train | epoch 237 | loss 1.137 | nll_loss 0.185 | ppl 1.14 | wps 6744.4 | ups 13.69 | wpb 492.6 | bsz 15.9 | num_updates 10428 | lr 0.000619341 | gnorm 0.401 | clip 84.1 | train_wall 2 | wall 741\n",
            "epoch 238:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:51 | INFO | fairseq.trainer | begin training epoch 238\n",
            "epoch 238:  98% 43/44 [00:02<00:00, 19.54it/s]2022-11-08 08:29:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 238 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 238 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.01it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:53 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 1.591 | nll_loss 0.585 | ppl 1.5 | wps 34549.8 | wpb 537.5 | bsz 16.7 | num_updates 10472 | best_loss 1.518\n",
            "2022-11-08 08:29:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint238.pt (epoch 238 @ 10472 updates, score 1.591) (writing took 0.421491919999994 seconds)\n",
            "2022-11-08 08:29:54 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)\n",
            "2022-11-08 08:29:54 | INFO | train | epoch 238 | loss 1.14 | nll_loss 0.189 | ppl 1.14 | wps 6833.2 | ups 13.87 | wpb 492.6 | bsz 15.9 | num_updates 10472 | lr 0.000618038 | gnorm 0.604 | clip 90.9 | train_wall 2 | wall 745\n",
            "epoch 239:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:54 | INFO | fairseq.trainer | begin training epoch 239\n",
            "epoch 239:  98% 43/44 [00:02<00:00, 19.59it/s, loss=1.136, nll_loss=0.184, ppl=1.14, wps=6881.5, ups=14.21, wpb=484.3, bsz=15.9, num_updates=10500, lr=0.000617213, gnorm=0.479, clip=87, train_wall=6, wall=746]2022-11-08 08:29:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 239 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 239 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.74it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:29:56 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 1.551 | nll_loss 0.54 | ppl 1.45 | wps 28442.5 | wpb 537.5 | bsz 16.7 | num_updates 10516 | best_loss 1.518\n",
            "2022-11-08 08:29:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:29:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint239.pt (epoch 239 @ 10516 updates, score 1.551) (writing took 0.428169490000073 seconds)\n",
            "2022-11-08 08:29:57 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)\n",
            "2022-11-08 08:29:57 | INFO | train | epoch 239 | loss 1.137 | nll_loss 0.185 | ppl 1.14 | wps 6933.3 | ups 14.08 | wpb 492.6 | bsz 15.9 | num_updates 10516 | lr 0.000616744 | gnorm 0.504 | clip 93.2 | train_wall 2 | wall 748\n",
            "epoch 240:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:29:57 | INFO | fairseq.trainer | begin training epoch 240\n",
            "epoch 240:  98% 43/44 [00:02<00:00, 19.72it/s]2022-11-08 08:29:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 240 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 240 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.51it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:30:00 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 1.568 | nll_loss 0.558 | ppl 1.47 | wps 34528.8 | wpb 537.5 | bsz 16.7 | num_updates 10560 | best_loss 1.518\n",
            "2022-11-08 08:30:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:30:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint240.pt (epoch 240 @ 10560 updates, score 1.568) (writing took 0.43879681299995354 seconds)\n",
            "2022-11-08 08:30:00 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)\n",
            "2022-11-08 08:30:00 | INFO | train | epoch 240 | loss 1.14 | nll_loss 0.188 | ppl 1.14 | wps 7023.2 | ups 14.26 | wpb 492.6 | bsz 15.9 | num_updates 10560 | lr 0.000615457 | gnorm 0.594 | clip 90.9 | train_wall 2 | wall 751\n",
            "epoch 241:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:30:00 | INFO | fairseq.trainer | begin training epoch 241\n",
            "epoch 241:  98% 43/44 [00:02<00:00, 18.79it/s, loss=1.139, nll_loss=0.187, ppl=1.14, wps=7163.6, ups=14.57, wpb=491.7, bsz=15.9, num_updates=10600, lr=0.000614295, gnorm=0.531, clip=90, train_wall=5, wall=753]2022-11-08 08:30:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 241 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 241 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.71it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:30:03 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 1.572 | nll_loss 0.565 | ppl 1.48 | wps 29559.1 | wpb 537.5 | bsz 16.7 | num_updates 10604 | best_loss 1.518\n",
            "2022-11-08 08:30:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:30:03 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint241.pt (epoch 241 @ 10604 updates, score 1.572) (writing took 0.44145912500005124 seconds)\n",
            "2022-11-08 08:30:03 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)\n",
            "2022-11-08 08:30:03 | INFO | train | epoch 241 | loss 1.14 | nll_loss 0.188 | ppl 1.14 | wps 6863.7 | ups 13.93 | wpb 492.6 | bsz 15.9 | num_updates 10604 | lr 0.000614179 | gnorm 0.444 | clip 86.4 | train_wall 2 | wall 754\n",
            "epoch 242:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:30:03 | INFO | fairseq.trainer | begin training epoch 242\n",
            "epoch 242:  98% 43/44 [00:02<00:00, 18.86it/s]2022-11-08 08:30:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 242 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 242 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.27it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:30:06 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 1.563 | nll_loss 0.552 | ppl 1.47 | wps 32417.9 | wpb 537.5 | bsz 16.7 | num_updates 10648 | best_loss 1.518\n",
            "2022-11-08 08:30:06 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:30:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint242.pt (epoch 242 @ 10648 updates, score 1.563) (writing took 0.4505900010000232 seconds)\n",
            "2022-11-08 08:30:06 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)\n",
            "2022-11-08 08:30:06 | INFO | train | epoch 242 | loss 1.138 | nll_loss 0.187 | ppl 1.14 | wps 6912.3 | ups 14.03 | wpb 492.6 | bsz 15.9 | num_updates 10648 | lr 0.000612909 | gnorm 0.517 | clip 90.9 | train_wall 2 | wall 757\n",
            "epoch 243:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:30:06 | INFO | fairseq.trainer | begin training epoch 243\n",
            "epoch 243:  95% 42/44 [00:02<00:00, 18.68it/s]2022-11-08 08:30:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 243 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 243 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.69it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:30:09 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 1.555 | nll_loss 0.544 | ppl 1.46 | wps 28915.1 | wpb 537.5 | bsz 16.7 | num_updates 10692 | best_loss 1.518\n",
            "2022-11-08 08:30:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:30:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint243.pt (epoch 243 @ 10692 updates, score 1.555) (writing took 0.4335603470000251 seconds)\n",
            "2022-11-08 08:30:09 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)\n",
            "2022-11-08 08:30:09 | INFO | train | epoch 243 | loss 1.137 | nll_loss 0.184 | ppl 1.14 | wps 6817.8 | ups 13.84 | wpb 492.6 | bsz 15.9 | num_updates 10692 | lr 0.000611647 | gnorm 0.543 | clip 95.5 | train_wall 2 | wall 760\n",
            "epoch 244:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:30:09 | INFO | fairseq.trainer | begin training epoch 244\n",
            "epoch 244:  95% 42/44 [00:02<00:00, 19.44it/s, loss=1.137, nll_loss=0.185, ppl=1.14, wps=6446.2, ups=13.03, wpb=494.8, bsz=15.9, num_updates=10700, lr=0.000611418, gnorm=0.517, clip=92, train_wall=6, wall=761]2022-11-08 08:30:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 244 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 244 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.51it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:30:12 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 1.56 | nll_loss 0.551 | ppl 1.46 | wps 33806.7 | wpb 537.5 | bsz 16.7 | num_updates 10736 | best_loss 1.518\n",
            "2022-11-08 08:30:12 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:30:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint244.pt (epoch 244 @ 10736 updates, score 1.56) (writing took 0.4521906790000685 seconds)\n",
            "2022-11-08 08:30:13 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)\n",
            "2022-11-08 08:30:13 | INFO | train | epoch 244 | loss 1.14 | nll_loss 0.188 | ppl 1.14 | wps 6868.2 | ups 13.94 | wpb 492.6 | bsz 15.9 | num_updates 10736 | lr 0.000610392 | gnorm 0.406 | clip 90.9 | train_wall 2 | wall 763\n",
            "epoch 245:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:30:13 | INFO | fairseq.trainer | begin training epoch 245\n",
            "epoch 245:  95% 42/44 [00:02<00:00, 19.78it/s]2022-11-08 08:30:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 245 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 245 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.61it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:30:15 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 1.58 | nll_loss 0.572 | ppl 1.49 | wps 32764.1 | wpb 537.5 | bsz 16.7 | num_updates 10780 | best_loss 1.518\n",
            "2022-11-08 08:30:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:30:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint245.pt (epoch 245 @ 10780 updates, score 1.58) (writing took 0.45214803700002903 seconds)\n",
            "2022-11-08 08:30:16 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)\n",
            "2022-11-08 08:30:16 | INFO | train | epoch 245 | loss 1.142 | nll_loss 0.191 | ppl 1.14 | wps 7037.3 | ups 14.29 | wpb 492.6 | bsz 15.9 | num_updates 10780 | lr 0.000609145 | gnorm 0.513 | clip 95.5 | train_wall 2 | wall 766\n",
            "epoch 246:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:30:16 | INFO | fairseq.trainer | begin training epoch 246\n",
            "epoch 246:  98% 43/44 [00:02<00:00, 19.35it/s, loss=1.139, nll_loss=0.188, ppl=1.14, wps=7105.3, ups=14.5, wpb=490.1, bsz=15.9, num_updates=10800, lr=0.000608581, gnorm=0.444, clip=90, train_wall=5, wall=768]2022-11-08 08:30:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 246 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 246 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.14it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:30:18 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 1.586 | nll_loss 0.58 | ppl 1.5 | wps 33155.1 | wpb 537.5 | bsz 16.7 | num_updates 10824 | best_loss 1.518\n",
            "2022-11-08 08:30:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:30:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint246.pt (epoch 246 @ 10824 updates, score 1.586) (writing took 0.42037593099996684 seconds)\n",
            "2022-11-08 08:30:19 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)\n",
            "2022-11-08 08:30:19 | INFO | train | epoch 246 | loss 1.136 | nll_loss 0.185 | ppl 1.14 | wps 7070.1 | ups 14.35 | wpb 492.6 | bsz 15.9 | num_updates 10824 | lr 0.000607906 | gnorm 0.46 | clip 84.1 | train_wall 2 | wall 770\n",
            "epoch 247:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:30:19 | INFO | fairseq.trainer | begin training epoch 247\n",
            "epoch 247:  98% 43/44 [00:02<00:00, 19.61it/s]2022-11-08 08:30:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 247 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 247 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.53it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:30:21 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 1.556 | nll_loss 0.547 | ppl 1.46 | wps 29886.1 | wpb 537.5 | bsz 16.7 | num_updates 10868 | best_loss 1.518\n",
            "2022-11-08 08:30:21 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:30:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint247.pt (epoch 247 @ 10868 updates, score 1.556) (writing took 0.43093445199997404 seconds)\n",
            "2022-11-08 08:30:22 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)\n",
            "2022-11-08 08:30:22 | INFO | train | epoch 247 | loss 1.134 | nll_loss 0.181 | ppl 1.13 | wps 6892.7 | ups 13.99 | wpb 492.6 | bsz 15.9 | num_updates 10868 | lr 0.000606674 | gnorm 0.377 | clip 81.8 | train_wall 2 | wall 773\n",
            "epoch 248:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:30:22 | INFO | fairseq.trainer | begin training epoch 248\n",
            "epoch 248:  98% 43/44 [00:02<00:00, 19.68it/s, loss=1.137, nll_loss=0.185, ppl=1.14, wps=7246.2, ups=14.48, wpb=500.5, bsz=15.9, num_updates=10900, lr=0.000605783, gnorm=0.412, clip=83, train_wall=5, wall=775]2022-11-08 08:30:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 248 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 248 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.26it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:30:25 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 1.548 | nll_loss 0.537 | ppl 1.45 | wps 24768.8 | wpb 537.5 | bsz 16.7 | num_updates 10912 | best_loss 1.518\n",
            "2022-11-08 08:30:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:30:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint248.pt (epoch 248 @ 10912 updates, score 1.548) (writing took 0.42230033800001365 seconds)\n",
            "2022-11-08 08:30:25 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)\n",
            "2022-11-08 08:30:25 | INFO | train | epoch 248 | loss 1.135 | nll_loss 0.183 | ppl 1.14 | wps 6942.8 | ups 14.09 | wpb 492.6 | bsz 15.9 | num_updates 10912 | lr 0.000605449 | gnorm 0.355 | clip 79.5 | train_wall 2 | wall 776\n",
            "epoch 249:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:30:25 | INFO | fairseq.trainer | begin training epoch 249\n",
            "epoch 249:  95% 42/44 [00:02<00:00, 19.08it/s]2022-11-08 08:30:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 249 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 249 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 27.35it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:30:28 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 1.545 | nll_loss 0.534 | ppl 1.45 | wps 27163.6 | wpb 537.5 | bsz 16.7 | num_updates 10956 | best_loss 1.518\n",
            "2022-11-08 08:30:28 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:30:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint249.pt (epoch 249 @ 10956 updates, score 1.545) (writing took 0.4145735820000027 seconds)\n",
            "2022-11-08 08:30:28 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)\n",
            "2022-11-08 08:30:28 | INFO | train | epoch 249 | loss 1.134 | nll_loss 0.181 | ppl 1.13 | wps 6994.3 | ups 14.2 | wpb 492.6 | bsz 15.9 | num_updates 10956 | lr 0.000604232 | gnorm 0.343 | clip 77.3 | train_wall 2 | wall 779\n",
            "epoch 250:   0% 0/44 [00:00<?, ?it/s]2022-11-08 08:30:28 | INFO | fairseq.trainer | begin training epoch 250\n",
            "epoch 250:  98% 43/44 [00:02<00:00, 19.61it/s]2022-11-08 08:30:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 250 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 250 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 29.32it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:30:31 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 1.55 | nll_loss 0.54 | ppl 1.45 | wps 36217 | wpb 537.5 | bsz 16.7 | num_updates 11000 | best_loss 1.518\n",
            "2022-11-08 08:30:31 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:30:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint250.pt (epoch 250 @ 11000 updates, score 1.55) (writing took 0.4510203460000639 seconds)\n",
            "2022-11-08 08:30:31 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)\n",
            "2022-11-08 08:30:31 | INFO | train | epoch 250 | loss 1.138 | nll_loss 0.187 | ppl 1.14 | wps 6981.7 | ups 14.17 | wpb 492.6 | bsz 15.9 | num_updates 11000 | lr 0.000603023 | gnorm 0.536 | clip 90.9 | train_wall 2 | wall 782\n",
            "2022-11-08 08:30:31 | INFO | fairseq_cli.train | done training in 782.0 seconds\n",
            "processed 10000 lines\n",
            "processed 20000 lines\n",
            "processed 30000 lines\n",
            "processed 40000 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "processed 10000 lines\n",
            "processed 20000 lines\n",
            "processed 30000 lines\n",
            "processed 40000 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "2022-11-08 08:30:37 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/all.tokenized.norm-casaccia', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='norm', srcdict='data-bin/all.tokenized.norm-casaccia/dict.norm.txt', target_lang='casaccia', task='translation', tensorboard_logdir=None, testpref='all.tokenized.norm-casaccia/test', tgtdict='data-bin/all.tokenized.norm-casaccia/dict.casaccia.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=1)\n",
            "2022-11-08 08:30:37 | INFO | fairseq_cli.preprocess | [norm] Dictionary: 88 types\n",
            "2022-11-08 08:30:48 | INFO | fairseq_cli.preprocess | [norm] all.tokenized.norm-casaccia/test.norm: 48814 sents, 2635554 tokens, 1.04% replaced by <unk>\n",
            "2022-11-08 08:30:48 | INFO | fairseq_cli.preprocess | [casaccia] Dictionary: 88 types\n",
            "2022-11-08 08:30:59 | INFO | fairseq_cli.preprocess | [casaccia] all.tokenized.norm-casaccia/test.casaccia: 48814 sents, 2635554 tokens, 1.04% replaced by <unk>\n",
            "2022-11-08 08:30:59 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/all.tokenized.norm-casaccia\n",
            "  0% 0/382 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  beams_buf = indices_buf // vocab_size\n",
            "/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = idx // beam_size\n",
            "pre 48814 48814\n",
            "mid 31037 31037\n",
            "after 30629 30629\n",
            "14.8442 49.7772\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "2022-11-08 08:41:23 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/all.tokenized.norm-casaccia', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='norm', srcdict='data-bin/all.tokenized.norm-casaccia/dict.norm.txt', target_lang='casaccia', task='translation', tensorboard_logdir=None, testpref='all.tokenized.norm-casaccia/test', tgtdict='data-bin/all.tokenized.norm-casaccia/dict.casaccia.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=1)\n",
            "2022-11-08 08:41:23 | INFO | fairseq_cli.preprocess | [norm] Dictionary: 88 types\n",
            "2022-11-08 08:41:23 | INFO | fairseq_cli.preprocess | [norm] all.tokenized.norm-casaccia/test.norm: 100 sents, 2963 tokens, 0.0% replaced by <unk>\n",
            "2022-11-08 08:41:23 | INFO | fairseq_cli.preprocess | [casaccia] Dictionary: 88 types\n",
            "2022-11-08 08:41:23 | INFO | fairseq_cli.preprocess | [casaccia] all.tokenized.norm-casaccia/test.casaccia: 100 sents, 3006 tokens, 0.0% replaced by <unk>\n",
            "2022-11-08 08:41:23 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/all.tokenized.norm-casaccia\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n",
            "Cloning Moses github repository (for tokenization scripts)...\n",
            "fatal: destination path 'mosesdecoder' already exists and is not an empty directory.\n",
            "pre-processing data...\n",
            "old new\n",
            "train.tags.old-new.old\n",
            "train.tags.old-new.tok.old\n",
            "\n",
            "train.tags.old-new.new\n",
            "train.tags.old-new.tok.new\n",
            "\n",
            "norm casaccia\n",
            "train.tags.norm-casaccia.norm\n",
            "train.tags.norm-casaccia.tok.norm\n",
            "\n",
            "train.tags.norm-casaccia.casaccia\n",
            "train.tags.norm-casaccia.tok.casaccia\n",
            "\n",
            "train1...\n",
            "old-new\n",
            "norm-casaccia\n",
            "len vocab on 79...\n",
            "BPE_TOKENS on 82...\n",
            "encoding train/valid/test with learned BPE...\n",
            "processed 10000 lines\n",
            "processed 20000 lines\n",
            "processed 30000 lines\n",
            "processed 40000 lines\n",
            "processed 50000 lines\n",
            "processed 60000 lines\n",
            "skipped 1 empty lines\n",
            "filtered 0 lines\n",
            "skipped 1 empty lines\n",
            "filtered 0 lines\n",
            "processed 10000 lines\n",
            "processed 20000 lines\n",
            "processed 30000 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "processed 10000 lines\n",
            "processed 20000 lines\n",
            "processed 30000 lines\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "final preprocessing...\n",
            "2022-11-08 08:41:33 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/tmp/all.tokenized.old-new', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='old', srcdict='data-bin/all.tokenized.old-new/dict.old.txt', target_lang='new', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='data-bin/all.tokenized.old-new/dict.new.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='all.tokenized.old-new/train1', user_dir=None, validpref=None, workers=1)\n",
            "2022-11-08 08:41:33 | INFO | fairseq_cli.preprocess | [old] Dictionary: 88 types\n",
            "2022-11-08 08:41:46 | INFO | fairseq_cli.preprocess | [old] all.tokenized.old-new/train1.old: 61257 sents, 3335946 tokens, 1.83% replaced by <unk>\n",
            "2022-11-08 08:41:46 | INFO | fairseq_cli.preprocess | [new] Dictionary: 88 types\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-preprocess\", line 8, in <module>\n",
            "    sys.exit(cli_main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 394, in cli_main\n",
            "    main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 286, in main\n",
            "    make_all(args.target_lang, tgt_dict)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 252, in make_all\n",
            "    make_dataset(vocab, args.trainpref, \"train\", lang, num_workers=args.workers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 248, in make_dataset\n",
            "    make_binary_dataset(vocab, input_prefix, output_prefix, lang, num_workers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 181, in make_binary_dataset\n",
            "    100 * sum(replaced.values()) / n_seq_tok[1],\n",
            "ZeroDivisionError: division by zero\n",
            "2022-11-08 08:41:47 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/tmp/all.tokenized.old-new', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='old', srcdict='data-bin/all.tokenized.old-new/dict.old.txt', target_lang='new', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='data-bin/all.tokenized.old-new/dict.new.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='all.tokenized.old-new/train1', user_dir=None, validpref=None, workers=1)\n",
            "2022-11-08 08:41:47 | INFO | fairseq_cli.preprocess | [old] Dictionary: 88 types\n",
            "2022-11-08 08:42:01 | INFO | fairseq_cli.preprocess | [old] all.tokenized.old-new/train1.old: 61257 sents, 3335946 tokens, 1.83% replaced by <unk>\n",
            "2022-11-08 08:42:01 | INFO | fairseq_cli.preprocess | [new] Dictionary: 88 types\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-preprocess\", line 8, in <module>\n",
            "    sys.exit(cli_main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 394, in cli_main\n",
            "    main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 286, in main\n",
            "    make_all(args.target_lang, tgt_dict)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 252, in make_all\n",
            "    make_dataset(vocab, args.trainpref, \"train\", lang, num_workers=args.workers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 248, in make_dataset\n",
            "    make_binary_dataset(vocab, input_prefix, output_prefix, lang, num_workers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fairseq_cli/preprocess.py\", line 181, in make_binary_dataset\n",
            "    100 * sum(replaced.values()) / n_seq_tok[1],\n",
            "ZeroDivisionError: division by zero\n",
            "2022-11-08 08:42:02 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/tmp/all.tokenized.norm-casaccia', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='norm', srcdict='data-bin/all.tokenized.norm-casaccia/dict.norm.txt', target_lang='casaccia', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='data-bin/all.tokenized.norm-casaccia/dict.casaccia.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='all.tokenized.norm-casaccia/train1', user_dir=None, validpref=None, workers=1)\n",
            "2022-11-08 08:42:02 | INFO | fairseq_cli.preprocess | [norm] Dictionary: 88 types\n",
            "2022-11-08 08:42:08 | INFO | fairseq_cli.preprocess | [norm] all.tokenized.norm-casaccia/train1.norm: 30629 sents, 1673918 tokens, 1.83% replaced by <unk>\n",
            "2022-11-08 08:42:08 | INFO | fairseq_cli.preprocess | [casaccia] Dictionary: 88 types\n",
            "2022-11-08 08:42:15 | INFO | fairseq_cli.preprocess | [casaccia] all.tokenized.norm-casaccia/train1.casaccia: 30629 sents, 1662030 tokens, 1.84% replaced by <unk>\n",
            "2022-11-08 08:42:15 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/tmp/all.tokenized.norm-casaccia\n",
            "2022-11-08 08:42:16 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/tmp/all.tokenized.norm-casaccia', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='norm', srcdict='data-bin/all.tokenized.norm-casaccia/dict.norm.txt', target_lang='casaccia', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='data-bin/all.tokenized.norm-casaccia/dict.casaccia.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='all.tokenized.norm-casaccia/train1', user_dir=None, validpref=None, workers=1)\n",
            "2022-11-08 08:42:16 | INFO | fairseq_cli.preprocess | [norm] Dictionary: 88 types\n",
            "2022-11-08 08:42:23 | INFO | fairseq_cli.preprocess | [norm] all.tokenized.norm-casaccia/train1.norm: 30629 sents, 1673918 tokens, 1.83% replaced by <unk>\n",
            "2022-11-08 08:42:23 | INFO | fairseq_cli.preprocess | [casaccia] Dictionary: 88 types\n",
            "2022-11-08 08:42:29 | INFO | fairseq_cli.preprocess | [casaccia] all.tokenized.norm-casaccia/train1.casaccia: 30629 sents, 1662030 tokens, 1.84% replaced by <unk>\n",
            "2022-11-08 08:42:29 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/tmp/all.tokenized.norm-casaccia\n",
            "2022-11-08 08:42:30 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, batch_size=20, batch_size_valid=20, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/all.tokenized.norm-casaccia', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=256, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=256, decoder_layerdrop=0, decoder_layers=4, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=256, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=256, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=30, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=20, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/fconv', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='casaccia', stop_time_hours=0, target_lang='norm', task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=12, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none')\n",
            "2022-11-08 08:42:30 | INFO | fairseq.tasks.translation | [casaccia] dictionary: 88 types\n",
            "2022-11-08 08:42:30 | INFO | fairseq.tasks.translation | [norm] dictionary: 88 types\n",
            "2022-11-08 08:42:30 | INFO | fairseq.data.data_utils | loaded 100 examples from: data-bin/all.tokenized.norm-casaccia/valid.norm-casaccia.casaccia\n",
            "2022-11-08 08:42:30 | INFO | fairseq.data.data_utils | loaded 100 examples from: data-bin/all.tokenized.norm-casaccia/valid.norm-casaccia.norm\n",
            "2022-11-08 08:42:30 | INFO | fairseq.tasks.translation | data-bin/all.tokenized.norm-casaccia valid casaccia-norm 100 examples\n",
            "2022-11-08 08:42:30 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(88, 256, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(88, 256, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=256, out_features=88, bias=False)\n",
            "  )\n",
            ")\n",
            "2022-11-08 08:42:30 | INFO | fairseq_cli.train | task: translation (TranslationTask)\n",
            "2022-11-08 08:42:30 | INFO | fairseq_cli.train | model: transformer (TransformerModel)\n",
            "2022-11-08 08:42:30 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)\n",
            "2022-11-08 08:42:30 | INFO | fairseq_cli.train | num. model params: 7396352 (num. trained: 7396352)\n",
            "2022-11-08 08:42:32 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
            "2022-11-08 08:42:32 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n",
            "2022-11-08 08:42:32 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-11-08 08:42:32 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n",
            "2022-11-08 08:42:32 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-11-08 08:42:32 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2022-11-08 08:42:32 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 20\n",
            "2022-11-08 08:42:32 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/fconv/checkpoint_last.pt\n",
            "2022-11-08 08:42:32 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2022-11-08 08:42:32 | INFO | fairseq.data.data_utils | loaded 700 examples from: data-bin/all.tokenized.norm-casaccia/train.norm-casaccia.casaccia\n",
            "2022-11-08 08:42:32 | INFO | fairseq.data.data_utils | loaded 700 examples from: data-bin/all.tokenized.norm-casaccia/train.norm-casaccia.norm\n",
            "2022-11-08 08:42:32 | INFO | fairseq.tasks.translation | data-bin/all.tokenized.norm-casaccia train casaccia-norm 700 examples\n",
            "2022-11-08 08:42:32 | INFO | fairseq.data.data_utils | loaded 30629 examples from: data-bin/all.tokenized.norm-casaccia/train1.norm-casaccia.casaccia\n",
            "2022-11-08 08:42:32 | INFO | fairseq.data.data_utils | loaded 30629 examples from: data-bin/all.tokenized.norm-casaccia/train1.norm-casaccia.norm\n",
            "2022-11-08 08:42:32 | INFO | fairseq.tasks.translation | data-bin/all.tokenized.norm-casaccia train1 casaccia-norm 30629 examples\n",
            "2022-11-08 08:42:32 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16\n",
            "epoch 001:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 08:42:32 | INFO | fairseq.trainer | begin training epoch 1\n",
            "/usr/local/lib/python3.7/dist-packages/fairseq/utils.py:342: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "epoch 001: 100% 2438/2440 [02:16<00:00, 18.82it/s, loss=1.707, nll_loss=0.813, ppl=1.76, wps=14359.7, ups=17.75, wpb=809.2, bsz=16, num_updates=2400, lr=0.00060004, gnorm=1.001, clip=100, train_wall=5, wall=134]2022-11-08 08:44:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.70it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:44:49 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 1.478 | nll_loss 0.448 | ppl 1.36 | wps 32194 | wpb 528.2 | bsz 16.7 | num_updates 2440\n",
            "2022-11-08 08:44:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:44:49 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint1.pt (epoch 1 @ 2440 updates, score 1.478) (writing took 0.4967776869998488 seconds)\n",
            "2022-11-08 08:44:49 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2022-11-08 08:44:49 | INFO | train | epoch 001 | loss 2.999 | nll_loss 2.296 | ppl 4.91 | wps 14156.3 | ups 17.89 | wpb 791.1 | bsz 16 | num_updates 2440 | lr 0.000610039 | gnorm 1.455 | clip 100 | train_wall 132 | wall 137\n",
            "epoch 002:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 08:44:49 | INFO | fairseq.trainer | begin training epoch 2\n",
            "epoch 002: 100% 2439/2440 [02:15<00:00, 19.33it/s, loss=1.521, nll_loss=0.619, ppl=1.54, wps=14344.4, ups=17.73, wpb=809.3, bsz=16, num_updates=4800, lr=0.000912871, gnorm=0.631, clip=100, train_wall=5, wall=268]2022-11-08 08:47:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 18.21it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:47:05 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 1.357 | nll_loss 0.34 | ppl 1.27 | wps 36739.3 | wpb 528.2 | bsz 16.7 | num_updates 4880 | best_loss 1.357\n",
            "2022-11-08 08:47:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:47:06 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint2.pt (epoch 2 @ 4880 updates, score 1.357) (writing took 0.5724394320000101 seconds)\n",
            "2022-11-08 08:47:06 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2022-11-08 08:47:06 | INFO | train | epoch 002 | loss 1.536 | nll_loss 0.63 | ppl 1.55 | wps 14141.6 | ups 17.88 | wpb 791.1 | bsz 16 | num_updates 4880 | lr 0.000905357 | gnorm 0.74 | clip 100 | train_wall 132 | wall 274\n",
            "epoch 003:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 08:47:06 | INFO | fairseq.trainer | begin training epoch 3\n",
            "epoch 003: 100% 2439/2440 [02:15<00:00, 18.47it/s, loss=1.378, nll_loss=0.459, ppl=1.37, wps=13942.7, ups=18.03, wpb=773.4, bsz=16, num_updates=7300, lr=0.000740233, gnorm=0.447, clip=100, train_wall=5, wall=408]2022-11-08 08:49:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 003 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.76it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:49:22 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 1.313 | nll_loss 0.284 | ppl 1.22 | wps 38391.5 | wpb 528.2 | bsz 16.7 | num_updates 7320 | best_loss 1.313\n",
            "2022-11-08 08:49:22 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:49:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint3.pt (epoch 3 @ 7320 updates, score 1.313) (writing took 0.5334344510001756 seconds)\n",
            "2022-11-08 08:49:22 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2022-11-08 08:49:22 | INFO | train | epoch 003 | loss 1.428 | nll_loss 0.516 | ppl 1.43 | wps 14135.3 | ups 17.87 | wpb 791.1 | bsz 16 | num_updates 7320 | lr 0.000739221 | gnorm 0.496 | clip 100 | train_wall 132 | wall 410\n",
            "epoch 004:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 08:49:22 | INFO | fairseq.trainer | begin training epoch 4\n",
            "epoch 004: 100% 2438/2440 [02:16<00:00, 19.26it/s, loss=1.349, nll_loss=0.428, ppl=1.35, wps=13327.3, ups=17.6, wpb=757.4, bsz=16, num_updates=9700, lr=0.000642161, gnorm=0.37, clip=99, train_wall=6, wall=543]2022-11-08 08:51:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 004 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 004 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 17.87it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:51:39 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 1.297 | nll_loss 0.265 | ppl 1.2 | wps 36418.2 | wpb 528.2 | bsz 16.7 | num_updates 9760 | best_loss 1.297\n",
            "2022-11-08 08:51:39 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:51:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint4.pt (epoch 4 @ 9760 updates, score 1.297) (writing took 0.5343867840001622 seconds)\n",
            "2022-11-08 08:51:39 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2022-11-08 08:51:39 | INFO | train | epoch 004 | loss 1.382 | nll_loss 0.465 | ppl 1.38 | wps 14069 | ups 17.78 | wpb 791.1 | bsz 16 | num_updates 9760 | lr 0.000640184 | gnorm 0.395 | clip 99.8 | train_wall 132 | wall 547\n",
            "epoch 005:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 08:51:39 | INFO | fairseq.trainer | begin training epoch 5\n",
            "epoch 005: 100% 2439/2440 [02:16<00:00, 19.23it/s, loss=1.346, nll_loss=0.426, ppl=1.34, wps=14097, ups=18.03, wpb=782, bsz=16, num_updates=12100, lr=0.00057496, gnorm=0.286, clip=96, train_wall=5, wall=678]2022-11-08 08:53:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 005 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 005 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.08it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:53:56 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 1.291 | nll_loss 0.257 | ppl 1.2 | wps 24090.1 | wpb 528.2 | bsz 16.7 | num_updates 12200 | best_loss 1.291\n",
            "2022-11-08 08:53:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:53:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint5.pt (epoch 5 @ 12200 updates, score 1.291) (writing took 0.5866053519998786 seconds)\n",
            "2022-11-08 08:53:57 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2022-11-08 08:53:57 | INFO | train | epoch 005 | loss 1.354 | nll_loss 0.434 | ppl 1.35 | wps 14070.1 | ups 17.78 | wpb 791.1 | bsz 16 | num_updates 12200 | lr 0.000572598 | gnorm 0.338 | clip 98.5 | train_wall 132 | wall 685\n",
            "epoch 006:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 08:53:57 | INFO | fairseq.trainer | begin training epoch 6\n",
            "epoch 006: 100% 2439/2440 [02:16<00:00, 19.53it/s, loss=1.311, nll_loss=0.387, ppl=1.31, wps=13814.1, ups=17.82, wpb=775.1, bsz=16, num_updates=14600, lr=0.000523424, gnorm=0.256, clip=92, train_wall=5, wall=819]2022-11-08 08:56:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 006 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 006 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 17.75it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:56:13 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 1.286 | nll_loss 0.248 | ppl 1.19 | wps 38196.4 | wpb 528.2 | bsz 16.7 | num_updates 14640 | best_loss 1.286\n",
            "2022-11-08 08:56:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:56:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint6.pt (epoch 6 @ 14640 updates, score 1.286) (writing took 0.5688853000001473 seconds)\n",
            "2022-11-08 08:56:14 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n",
            "2022-11-08 08:56:14 | INFO | train | epoch 006 | loss 1.334 | nll_loss 0.412 | ppl 1.33 | wps 14084.3 | ups 17.8 | wpb 791.1 | bsz 16 | num_updates 14640 | lr 0.000522708 | gnorm 0.301 | clip 97.5 | train_wall 132 | wall 822\n",
            "epoch 007:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 08:56:14 | INFO | fairseq.trainer | begin training epoch 7\n",
            "epoch 007: 100% 2437/2440 [02:15<00:00, 18.72it/s, loss=1.323, nll_loss=0.399, ppl=1.32, wps=14567.7, ups=18.02, wpb=808.2, bsz=16, num_updates=17000, lr=0.000485071, gnorm=0.287, clip=97, train_wall=5, wall=953]2022-11-08 08:58:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 007 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 007 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 18.04it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 08:58:29 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 1.273 | nll_loss 0.234 | ppl 1.18 | wps 30923.4 | wpb 528.2 | bsz 16.7 | num_updates 17080 | best_loss 1.273\n",
            "2022-11-08 08:58:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 08:58:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint7.pt (epoch 7 @ 17080 updates, score 1.273) (writing took 0.5912821719998647 seconds)\n",
            "2022-11-08 08:58:30 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)\n",
            "2022-11-08 08:58:30 | INFO | train | epoch 007 | loss 1.318 | nll_loss 0.395 | ppl 1.31 | wps 14156.3 | ups 17.89 | wpb 791.1 | bsz 16 | num_updates 17080 | lr 0.000483934 | gnorm 0.276 | clip 95.5 | train_wall 131 | wall 958\n",
            "epoch 008:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 08:58:30 | INFO | fairseq.trainer | begin training epoch 8\n",
            "epoch 008: 100% 2439/2440 [02:16<00:00, 19.33it/s, loss=1.333, nll_loss=0.412, ppl=1.33, wps=14784.8, ups=17.97, wpb=822.6, bsz=16, num_updates=19500, lr=0.000452911, gnorm=0.237, clip=93, train_wall=5, wall=1093]2022-11-08 09:00:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 008 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 008 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 24.17it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:00:46 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 1.284 | nll_loss 0.24 | ppl 1.18 | wps 24635 | wpb 528.2 | bsz 16.7 | num_updates 19520 | best_loss 1.273\n",
            "2022-11-08 09:00:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:00:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint8.pt (epoch 8 @ 19520 updates, score 1.284) (writing took 0.4244233889999123 seconds)\n",
            "2022-11-08 09:00:47 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)\n",
            "2022-11-08 09:00:47 | INFO | train | epoch 008 | loss 1.306 | nll_loss 0.381 | ppl 1.3 | wps 14119.4 | ups 17.85 | wpb 791.1 | bsz 16 | num_updates 19520 | lr 0.000452679 | gnorm 0.267 | clip 94.7 | train_wall 132 | wall 1095\n",
            "epoch 009:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:00:47 | INFO | fairseq.trainer | begin training epoch 9\n",
            "epoch 009: 100% 2439/2440 [02:16<00:00, 19.14it/s, loss=1.285, nll_loss=0.357, ppl=1.28, wps=14280.5, ups=17.84, wpb=800.7, bsz=16, num_updates=21900, lr=0.000427374, gnorm=0.214, clip=91, train_wall=5, wall=1228]2022-11-08 09:03:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 009 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 009 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.07it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:03:03 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 1.279 | nll_loss 0.233 | ppl 1.17 | wps 27861.1 | wpb 528.2 | bsz 16.7 | num_updates 21960 | best_loss 1.273\n",
            "2022-11-08 09:03:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:03:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint9.pt (epoch 9 @ 21960 updates, score 1.279) (writing took 0.4433459799997763 seconds)\n",
            "2022-11-08 09:03:04 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)\n",
            "2022-11-08 09:03:04 | INFO | train | epoch 009 | loss 1.296 | nll_loss 0.37 | ppl 1.29 | wps 14084.9 | ups 17.8 | wpb 791.1 | bsz 16 | num_updates 21960 | lr 0.00042679 | gnorm 0.254 | clip 92.4 | train_wall 132 | wall 1232\n",
            "epoch 010:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:03:04 | INFO | fairseq.trainer | begin training epoch 10\n",
            "epoch 010: 100% 2437/2440 [02:15<00:00, 19.21it/s, loss=1.308, nll_loss=0.384, ppl=1.31, wps=14433.1, ups=18.08, wpb=798.1, bsz=16, num_updates=24300, lr=0.00040572, gnorm=0.23, clip=90, train_wall=5, wall=1362]2022-11-08 09:05:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 010 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 010 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 25.38it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:05:20 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 1.284 | nll_loss 0.241 | ppl 1.18 | wps 32348.1 | wpb 528.2 | bsz 16.7 | num_updates 24400 | best_loss 1.273\n",
            "2022-11-08 09:05:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:05:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint10.pt (epoch 10 @ 24400 updates, score 1.284) (writing took 0.4228111589995933 seconds)\n",
            "2022-11-08 09:05:20 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)\n",
            "2022-11-08 09:05:20 | INFO | train | epoch 010 | loss 1.288 | nll_loss 0.36 | ppl 1.28 | wps 14180.9 | ups 17.93 | wpb 791.1 | bsz 16 | num_updates 24400 | lr 0.000404888 | gnorm 0.244 | clip 91.6 | train_wall 131 | wall 1368\n",
            "epoch 011:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:05:20 | INFO | fairseq.trainer | begin training epoch 11\n",
            "epoch 011: 100% 2439/2440 [02:15<00:00, 19.74it/s, loss=1.275, nll_loss=0.345, ppl=1.27, wps=14446.1, ups=18.22, wpb=792.8, bsz=16, num_updates=26800, lr=0.000386334, gnorm=0.234, clip=95, train_wall=5, wall=1501]2022-11-08 09:07:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 011 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 011 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 16.43it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:07:36 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 1.289 | nll_loss 0.241 | ppl 1.18 | wps 23916.5 | wpb 528.2 | bsz 16.7 | num_updates 26840 | best_loss 1.273\n",
            "2022-11-08 09:07:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:07:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint11.pt (epoch 11 @ 26840 updates, score 1.289) (writing took 0.43076434600016 seconds)\n",
            "2022-11-08 09:07:36 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)\n",
            "2022-11-08 09:07:36 | INFO | train | epoch 011 | loss 1.28 | nll_loss 0.352 | ppl 1.28 | wps 14182.5 | ups 17.93 | wpb 791.1 | bsz 16 | num_updates 26840 | lr 0.000386046 | gnorm 0.241 | clip 91 | train_wall 131 | wall 1504\n",
            "epoch 012:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:07:36 | INFO | fairseq.trainer | begin training epoch 12\n",
            "epoch 012: 100% 2439/2440 [02:15<00:00, 19.25it/s, loss=1.282, nll_loss=0.354, ppl=1.28, wps=14427.2, ups=17.95, wpb=803.9, bsz=16, num_updates=29200, lr=0.000370117, gnorm=0.246, clip=92, train_wall=5, wall=1635]2022-11-08 09:09:52 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 012 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 012 | valid on 'valid' subset:  50% 3/6 [00:00<00:00, 26.70it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:09:52 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 1.288 | nll_loss 0.243 | ppl 1.18 | wps 30855.3 | wpb 528.2 | bsz 16.7 | num_updates 29280 | best_loss 1.273\n",
            "2022-11-08 09:09:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:09:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint12.pt (epoch 12 @ 29280 updates, score 1.288) (writing took 0.4545963370001118 seconds)\n",
            "2022-11-08 09:09:52 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)\n",
            "2022-11-08 09:09:52 | INFO | train | epoch 012 | loss 1.273 | nll_loss 0.344 | ppl 1.27 | wps 14176.7 | ups 17.92 | wpb 791.1 | bsz 16 | num_updates 29280 | lr 0.000369611 | gnorm 0.244 | clip 89.9 | train_wall 131 | wall 1640\n",
            "epoch 013:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:09:52 | INFO | fairseq.trainer | begin training epoch 13\n",
            "epoch 013: 100% 2438/2440 [02:15<00:00, 18.67it/s, loss=1.271, nll_loss=0.341, ppl=1.27, wps=13987.3, ups=17.52, wpb=798.3, bsz=16, num_updates=31700, lr=0.000355222, gnorm=0.221, clip=90, train_wall=6, wall=1775]2022-11-08 09:12:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 013 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 013 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 16.49it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:12:08 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 1.281 | nll_loss 0.231 | ppl 1.17 | wps 25611.8 | wpb 528.2 | bsz 16.7 | num_updates 31720 | best_loss 1.273\n",
            "2022-11-08 09:12:08 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:12:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint13.pt (epoch 13 @ 31720 updates, score 1.281) (writing took 0.42670338600009927 seconds)\n",
            "2022-11-08 09:12:08 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)\n",
            "2022-11-08 09:12:08 | INFO | train | epoch 013 | loss 1.267 | nll_loss 0.337 | ppl 1.26 | wps 14174.8 | ups 17.92 | wpb 791.1 | bsz 16 | num_updates 31720 | lr 0.00035511 | gnorm 0.224 | clip 88.9 | train_wall 131 | wall 1776\n",
            "epoch 014:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:12:08 | INFO | fairseq.trainer | begin training epoch 14\n",
            "epoch 014: 100% 2438/2440 [02:14<00:00, 19.93it/s, loss=1.267, nll_loss=0.336, ppl=1.26, wps=14179.7, ups=18.24, wpb=777.2, bsz=16, num_updates=34100, lr=0.000342494, gnorm=0.239, clip=87, train_wall=5, wall=1908]2022-11-08 09:14:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 014 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 014 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.10it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:14:23 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 1.287 | nll_loss 0.236 | ppl 1.18 | wps 27130.6 | wpb 528.2 | bsz 16.7 | num_updates 34160 | best_loss 1.273\n",
            "2022-11-08 09:14:23 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:14:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint14.pt (epoch 14 @ 34160 updates, score 1.287) (writing took 0.40945781400023407 seconds)\n",
            "2022-11-08 09:14:24 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)\n",
            "2022-11-08 09:14:24 | INFO | train | epoch 014 | loss 1.262 | nll_loss 0.331 | ppl 1.26 | wps 14278.2 | ups 18.05 | wpb 791.1 | bsz 16 | num_updates 34160 | lr 0.000342193 | gnorm 0.224 | clip 88.3 | train_wall 130 | wall 1912\n",
            "epoch 015:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:14:24 | INFO | fairseq.trainer | begin training epoch 15\n",
            "epoch 015: 100% 2439/2440 [02:14<00:00, 19.60it/s, loss=1.265, nll_loss=0.335, ppl=1.26, wps=14285.5, ups=18.27, wpb=781.8, bsz=16, num_updates=36500, lr=0.000331042, gnorm=0.214, clip=83, train_wall=5, wall=2041]2022-11-08 09:16:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 015 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 015 | valid on 'valid' subset:  17% 1/6 [00:00<00:00,  9.00it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:16:39 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 1.294 | nll_loss 0.246 | ppl 1.19 | wps 36416.7 | wpb 528.2 | bsz 16.7 | num_updates 36600 | best_loss 1.273\n",
            "2022-11-08 09:16:39 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:16:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint15.pt (epoch 15 @ 36600 updates, score 1.294) (writing took 0.4259041079999406 seconds)\n",
            "2022-11-08 09:16:39 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)\n",
            "2022-11-08 09:16:39 | INFO | train | epoch 015 | loss 1.257 | nll_loss 0.325 | ppl 1.25 | wps 14240.3 | ups 18 | wpb 791.1 | bsz 16 | num_updates 36600 | lr 0.00033059 | gnorm 0.228 | clip 88.5 | train_wall 131 | wall 2047\n",
            "epoch 016:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:16:39 | INFO | fairseq.trainer | begin training epoch 16\n",
            "epoch 016: 100% 2438/2440 [02:15<00:00, 18.57it/s, loss=1.248, nll_loss=0.315, ppl=1.24, wps=14249, ups=18.25, wpb=780.8, bsz=16, num_updates=39000, lr=0.000320256, gnorm=0.204, clip=87, train_wall=5, wall=2180]2022-11-08 09:18:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 016 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 016 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 16.05it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:18:54 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 1.287 | nll_loss 0.237 | ppl 1.18 | wps 28842 | wpb 528.2 | bsz 16.7 | num_updates 39040 | best_loss 1.273\n",
            "2022-11-08 09:18:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:18:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint16.pt (epoch 16 @ 39040 updates, score 1.287) (writing took 0.40044532199999594 seconds)\n",
            "2022-11-08 09:18:55 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)\n",
            "2022-11-08 09:18:55 | INFO | train | epoch 016 | loss 1.253 | nll_loss 0.321 | ppl 1.25 | wps 14224 | ups 17.98 | wpb 791.1 | bsz 16 | num_updates 39040 | lr 0.000320092 | gnorm 0.226 | clip 87.2 | train_wall 131 | wall 2183\n",
            "epoch 017:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:18:55 | INFO | fairseq.trainer | begin training epoch 17\n",
            "epoch 017: 100% 2438/2440 [02:14<00:00, 19.16it/s, loss=1.241, nll_loss=0.307, ppl=1.24, wps=14481.3, ups=17.96, wpb=806.1, bsz=15.9, num_updates=41400, lr=0.000310835, gnorm=0.216, clip=90, train_wall=5, wall=2313]2022-11-08 09:21:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 017 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 017 | valid on 'valid' subset:  17% 1/6 [00:00<00:00,  9.16it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:21:09 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 1.303 | nll_loss 0.252 | ppl 1.19 | wps 36782.5 | wpb 528.2 | bsz 16.7 | num_updates 41480 | best_loss 1.273\n",
            "2022-11-08 09:21:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:21:10 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint17.pt (epoch 17 @ 41480 updates, score 1.303) (writing took 0.4231291260002763 seconds)\n",
            "2022-11-08 09:21:10 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)\n",
            "2022-11-08 09:21:10 | INFO | train | epoch 017 | loss 1.249 | nll_loss 0.316 | ppl 1.24 | wps 14299.9 | ups 18.08 | wpb 791.1 | bsz 16 | num_updates 41480 | lr 0.000310535 | gnorm 0.22 | clip 86.6 | train_wall 130 | wall 2318\n",
            "epoch 018:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:21:10 | INFO | fairseq.trainer | begin training epoch 18\n",
            "epoch 018: 100% 2438/2440 [02:14<00:00, 19.44it/s, loss=1.251, nll_loss=0.318, ppl=1.25, wps=13968.6, ups=17.92, wpb=779.3, bsz=16, num_updates=43900, lr=0.000301855, gnorm=0.229, clip=87, train_wall=5, wall=2451]2022-11-08 09:23:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 018 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 018 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 18.74it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:23:24 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 1.296 | nll_loss 0.245 | ppl 1.19 | wps 30033.1 | wpb 528.2 | bsz 16.7 | num_updates 43920 | best_loss 1.273\n",
            "2022-11-08 09:23:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:23:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint18.pt (epoch 18 @ 43920 updates, score 1.296) (writing took 0.378951077000238 seconds)\n",
            "2022-11-08 09:23:25 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)\n",
            "2022-11-08 09:23:25 | INFO | train | epoch 018 | loss 1.245 | nll_loss 0.311 | ppl 1.24 | wps 14307.6 | ups 18.09 | wpb 791.1 | bsz 16 | num_updates 43920 | lr 0.000301786 | gnorm 0.219 | clip 86.8 | train_wall 130 | wall 2453\n",
            "epoch 019:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:23:25 | INFO | fairseq.trainer | begin training epoch 19\n",
            "epoch 019: 100% 2437/2440 [02:15<00:00, 20.16it/s, loss=1.234, nll_loss=0.298, ppl=1.23, wps=13980.5, ups=17.78, wpb=786.5, bsz=16, num_updates=46300, lr=0.000293927, gnorm=0.228, clip=90, train_wall=5, wall=2585]2022-11-08 09:25:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 019 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 019 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.78it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:25:40 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 1.299 | nll_loss 0.247 | ppl 1.19 | wps 35855.3 | wpb 528.2 | bsz 16.7 | num_updates 46360 | best_loss 1.273\n",
            "2022-11-08 09:25:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:25:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint19.pt (epoch 19 @ 46360 updates, score 1.299) (writing took 0.385923916000138 seconds)\n",
            "2022-11-08 09:25:41 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)\n",
            "2022-11-08 09:25:41 | INFO | train | epoch 019 | loss 1.242 | nll_loss 0.308 | ppl 1.24 | wps 14182.7 | ups 17.93 | wpb 791.1 | bsz 16 | num_updates 46360 | lr 0.000293737 | gnorm 0.225 | clip 87.1 | train_wall 131 | wall 2589\n",
            "epoch 020:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:25:41 | INFO | fairseq.trainer | begin training epoch 20\n",
            "epoch 020: 100% 2439/2440 [02:15<00:00, 18.59it/s, loss=1.261, nll_loss=0.329, ppl=1.26, wps=14366.9, ups=17.74, wpb=810, bsz=16, num_updates=48700, lr=0.000286593, gnorm=0.225, clip=87, train_wall=5, wall=2719]2022-11-08 09:27:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 020 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 020 | valid on 'valid' subset:  17% 1/6 [00:00<00:00,  9.25it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:27:57 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 1.301 | nll_loss 0.249 | ppl 1.19 | wps 32688.9 | wpb 528.2 | bsz 16.7 | num_updates 48800 | best_loss 1.273\n",
            "2022-11-08 09:27:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:27:57 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint20.pt (epoch 20 @ 48800 updates, score 1.301) (writing took 0.37823104100061755 seconds)\n",
            "2022-11-08 09:27:57 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)\n",
            "2022-11-08 09:27:57 | INFO | train | epoch 020 | loss 1.238 | nll_loss 0.304 | ppl 1.23 | wps 14140 | ups 17.87 | wpb 791.1 | bsz 16 | num_updates 48800 | lr 0.000286299 | gnorm 0.219 | clip 85.3 | train_wall 132 | wall 2725\n",
            "epoch 021:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:27:57 | INFO | fairseq.trainer | begin training epoch 21\n",
            "epoch 021: 100% 2438/2440 [02:16<00:00, 19.01it/s, loss=1.258, nll_loss=0.326, ppl=1.25, wps=14130.8, ups=17.65, wpb=800.6, bsz=16, num_updates=51200, lr=0.000279508, gnorm=0.215, clip=85, train_wall=5, wall=2860]2022-11-08 09:30:14 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 021 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 021 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.12it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:30:14 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 1.306 | nll_loss 0.255 | ppl 1.19 | wps 32936.4 | wpb 528.2 | bsz 16.7 | num_updates 51240 | best_loss 1.273\n",
            "2022-11-08 09:30:14 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:30:15 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint21.pt (epoch 21 @ 51240 updates, score 1.306) (writing took 0.3997590720000517 seconds)\n",
            "2022-11-08 09:30:15 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)\n",
            "2022-11-08 09:30:15 | INFO | train | epoch 021 | loss 1.235 | nll_loss 0.3 | ppl 1.23 | wps 14053.3 | ups 17.76 | wpb 791.1 | bsz 16 | num_updates 51240 | lr 0.000279399 | gnorm 0.215 | clip 85.4 | train_wall 132 | wall 2863\n",
            "epoch 022:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:30:15 | INFO | fairseq.trainer | begin training epoch 22\n",
            "epoch 022: 100% 2437/2440 [02:17<00:00, 18.70it/s, loss=1.23, nll_loss=0.294, ppl=1.23, wps=13858.7, ups=17.71, wpb=782.3, bsz=16, num_updates=53600, lr=0.000273179, gnorm=0.2, clip=80, train_wall=5, wall=2996]2022-11-08 09:32:32 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 022 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 022 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.04it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:32:33 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 1.302 | nll_loss 0.251 | ppl 1.19 | wps 30135.6 | wpb 528.2 | bsz 16.7 | num_updates 53680 | best_loss 1.273\n",
            "2022-11-08 09:32:33 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:32:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint22.pt (epoch 22 @ 53680 updates, score 1.302) (writing took 0.391163007000614 seconds)\n",
            "2022-11-08 09:32:33 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)\n",
            "2022-11-08 09:32:33 | INFO | train | epoch 022 | loss 1.232 | nll_loss 0.296 | ppl 1.23 | wps 13961.8 | ups 17.65 | wpb 791.1 | bsz 16 | num_updates 53680 | lr 0.000272976 | gnorm 0.216 | clip 85.4 | train_wall 133 | wall 3001\n",
            "epoch 023:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:32:33 | INFO | fairseq.trainer | begin training epoch 23\n",
            "epoch 023: 100% 2438/2440 [02:16<00:00, 19.39it/s, loss=1.219, nll_loss=0.281, ppl=1.22, wps=13633.6, ups=17.9, wpb=761.8, bsz=16, num_updates=56100, lr=0.000267023, gnorm=0.226, clip=84, train_wall=5, wall=3137]2022-11-08 09:34:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 023 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 023 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 18.04it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:34:50 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 1.291 | nll_loss 0.238 | ppl 1.18 | wps 24623.7 | wpb 528.2 | bsz 16.7 | num_updates 56120 | best_loss 1.273\n",
            "2022-11-08 09:34:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:34:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint23.pt (epoch 23 @ 56120 updates, score 1.291) (writing took 0.37587505400006194 seconds)\n",
            "2022-11-08 09:34:50 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)\n",
            "2022-11-08 09:34:50 | INFO | train | epoch 023 | loss 1.23 | nll_loss 0.294 | ppl 1.23 | wps 14068 | ups 17.78 | wpb 791.1 | bsz 16 | num_updates 56120 | lr 0.000266975 | gnorm 0.218 | clip 85.1 | train_wall 132 | wall 3138\n",
            "epoch 024:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:34:50 | INFO | fairseq.trainer | begin training epoch 24\n",
            "epoch 024: 100% 2437/2440 [02:16<00:00, 18.53it/s, loss=1.221, nll_loss=0.283, ppl=1.22, wps=13713.6, ups=17.87, wpb=767.5, bsz=16, num_updates=58500, lr=0.000261488, gnorm=0.234, clip=85, train_wall=5, wall=3272]2022-11-08 09:37:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 024 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 024 | valid on 'valid' subset:  17% 1/6 [00:00<00:00,  9.83it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:37:07 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 1.295 | nll_loss 0.24 | ppl 1.18 | wps 36460.1 | wpb 528.2 | bsz 16.7 | num_updates 58560 | best_loss 1.273\n",
            "2022-11-08 09:37:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:37:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint24.pt (epoch 24 @ 58560 updates, score 1.295) (writing took 0.3845860190003805 seconds)\n",
            "2022-11-08 09:37:08 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)\n",
            "2022-11-08 09:37:08 | INFO | train | epoch 024 | loss 1.227 | nll_loss 0.29 | ppl 1.22 | wps 14040 | ups 17.75 | wpb 791.1 | bsz 16 | num_updates 58560 | lr 0.000261354 | gnorm 0.222 | clip 84.6 | train_wall 133 | wall 3276\n",
            "epoch 025:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:37:08 | INFO | fairseq.trainer | begin training epoch 25\n",
            "epoch 025: 100% 2439/2440 [02:17<00:00, 19.25it/s, loss=1.21, nll_loss=0.272, ppl=1.21, wps=13232.6, ups=18, wpb=735.3, bsz=16, num_updates=60900, lr=0.000256284, gnorm=0.215, clip=81, train_wall=5, wall=3408]2022-11-08 09:39:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 025 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 025 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 19.47it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:39:25 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 1.305 | nll_loss 0.252 | ppl 1.19 | wps 33846 | wpb 528.2 | bsz 16.7 | num_updates 61000 | best_loss 1.273\n",
            "2022-11-08 09:39:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:39:26 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint25.pt (epoch 25 @ 61000 updates, score 1.305) (writing took 0.37049800699969637 seconds)\n",
            "2022-11-08 09:39:26 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)\n",
            "2022-11-08 09:39:26 | INFO | train | epoch 025 | loss 1.225 | nll_loss 0.288 | ppl 1.22 | wps 13990.1 | ups 17.68 | wpb 791.1 | bsz 16 | num_updates 61000 | lr 0.000256074 | gnorm 0.218 | clip 85.5 | train_wall 133 | wall 3414\n",
            "epoch 026:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:39:26 | INFO | fairseq.trainer | begin training epoch 26\n",
            "epoch 026: 100% 2438/2440 [02:18<00:00, 20.03it/s, loss=1.23, nll_loss=0.294, ppl=1.23, wps=14277.6, ups=18.32, wpb=779.2, bsz=16, num_updates=63400, lr=0.00025118, gnorm=0.2, clip=85, train_wall=5, wall=3550]2022-11-08 09:41:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 026 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 026 | valid on 'valid' subset:  17% 1/6 [00:00<00:00,  7.83it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:41:45 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 1.299 | nll_loss 0.242 | ppl 1.18 | wps 29450.8 | wpb 528.2 | bsz 16.7 | num_updates 63440 | best_loss 1.273\n",
            "2022-11-08 09:41:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:41:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint26.pt (epoch 26 @ 63440 updates, score 1.299) (writing took 0.39096794899978704 seconds)\n",
            "2022-11-08 09:41:45 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)\n",
            "2022-11-08 09:41:45 | INFO | train | epoch 026 | loss 1.223 | nll_loss 0.285 | ppl 1.22 | wps 13863.7 | ups 17.52 | wpb 791.1 | bsz 16 | num_updates 63440 | lr 0.000251101 | gnorm 0.218 | clip 85.3 | train_wall 134 | wall 3553\n",
            "epoch 027:   0% 0/2440 [00:00<?, ?it/s]2022-11-08 09:41:45 | INFO | fairseq.trainer | begin training epoch 27\n",
            "epoch 027: 100% 2439/2440 [02:18<00:00, 19.78it/s, loss=1.212, nll_loss=0.273, ppl=1.21, wps=14305, ups=17.87, wpb=800.5, bsz=16, num_updates=65800, lr=0.000246557, gnorm=0.202, clip=86, train_wall=5, wall=3687]2022-11-08 09:44:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 027 | valid on 'valid' subset:   0% 0/6 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 027 | valid on 'valid' subset:  33% 2/6 [00:00<00:00, 18.09it/s]\u001b[A\n",
            "                                                                      \u001b[A2022-11-08 09:44:04 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 1.285 | nll_loss 0.229 | ppl 1.17 | wps 32654.6 | wpb 528.2 | bsz 16.7 | num_updates 65880 | best_loss 1.273\n",
            "2022-11-08 09:44:04 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 20 runs\n",
            "2022-11-08 09:44:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2022-11-08 09:44:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/fconv/checkpoint27.pt (epoch 27 @ 65880 updates, score 1.285) (writing took 0.4341354850002972 seconds)\n",
            "2022-11-08 09:44:04 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)\n",
            "2022-11-08 09:44:04 | INFO | train | epoch 027 | loss 1.22 | nll_loss 0.282 | ppl 1.22 | wps 13851.5 | ups 17.51 | wpb 791.1 | bsz 16 | num_updates 65880 | lr 0.000246407 | gnorm 0.216 | clip 83.8 | train_wall 134 | wall 3692\n",
            "2022-11-08 09:44:04 | INFO | fairseq_cli.train | done training in 3692.3 seconds\n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  beams_buf = indices_buf // vocab_size\n",
            "/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = idx // beam_size\n",
            "CER: 2.3879 WER: 5.3262\n"
          ]
        }
      ],
      "source": [
        "!sh train.sh 1 12 casaccia norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ3uL7mWH1Qd"
      },
      "source": [
        "# Predict\n",
        "\n",
        "Install newly created normalizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnC7XmQReNUo",
        "outputId": "d857923c-2d25-441e-da5e-e071428ff27d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/trascricion/casaccia-norm-normalizer\n",
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 33393, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 33393 (delta 0), reused 0 (delta 0), pack-reused 33392\u001b[K\n",
            "Receiving objects: 100% (33393/33393), 23.28 MiB | 11.69 MiB/s, done.\n",
            "Resolving deltas: 100% (24400/24400), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fairseq==0.10.2 in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (1.21.6)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (1.15.1)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (0.6)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (2.3.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (0.29.32)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (1.12.1+cu113)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (1.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (2022.6.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==0.10.2) (4.9.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==0.10.2) (0.4.6)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==0.10.2) (2.6.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==0.10.2) (0.8.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==0.10.2) (2.21)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq==0.10.2) (4.9.3)\n",
            "Requirement already satisfied: omegaconf~=2.2 in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq==0.10.2) (2.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq==0.10.2) (21.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq==0.10.2) (5.10.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf~=2.2->hydra-core->fairseq==0.10.2) (6.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core->fairseq==0.10.2) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core->fairseq==0.10.2) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq==0.10.2) (4.1.1)\n",
            "Cloning into 'fastwer'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 33 (delta 9), reused 26 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.7/dist-packages (2.10.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fastwer in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.7/dist-packages (from fastwer) (2.10.1)\n"
          ]
        }
      ],
      "source": [
        "%cd casaccia-norm-normalizer\n",
        "!sh setup.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIF9AcfYhKeo"
      },
      "source": [
        "Create dataset for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PCVXIxWhSfP"
      },
      "outputs": [],
      "source": [
        "!echo -e \"In ta côa ghe sta ō venin\\nGarsōn da massacan\" > text.casaccia\n",
        "!echo -e \"Inta coa ghe stà o venin\\nGarson da massacan\" > text.expected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHpWJal-hQJ1"
      },
      "source": [
        "Actually infer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZINQsA_jsvA",
        "outputId": "5b763323-1849-4e1f-e46d-93f05a7a1796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n",
            "Cloning Moses github repository (for tokenization scripts)...\n",
            "fatal: destination path 'mosesdecoder' already exists and is not an empty directory.\n",
            "text.casaccia\n",
            "text.casaccia.tok\n",
            "\n",
            "skipped 0 empty lines\n",
            "filtered 0 lines\n",
            "2022-11-08 10:30:46 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='.', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='old', srcdict='dict.old.txt', target_lang='new', task='translation', tensorboard_logdir=None, testpref='text.casaccia.sub', tgtdict='dict.new.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, user_dir=None, validpref=None, workers=1)\n",
            "2022-11-08 10:30:46 | INFO | fairseq_cli.preprocess | [old] Dictionary: 88 types\n",
            "2022-11-08 10:30:46 | INFO | fairseq_cli.preprocess | [old] text.casaccia.sub.old: 2 sents, 47 tokens, 0.0% replaced by <unk>\n",
            "2022-11-08 10:30:46 | INFO | fairseq_cli.preprocess | [new] Dictionary: 88 types\n",
            "2022-11-08 10:30:46 | INFO | fairseq_cli.preprocess | [new] text.casaccia.sub.new: 2 sents, 47 tokens, 0.0% replaced by <unk>\n",
            "2022-11-08 10:30:46 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to .\n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  beams_buf = indices_buf // vocab_size\n",
            "/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = idx // beam_size\n"
          ]
        }
      ],
      "source": [
        "!sh translate.sh text.casaccia text.norm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check result"
      ],
      "metadata": {
        "id": "JFMs17uusk7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cmp --silent text.norm text.expected && echo 'TEST PASSED' || echo 'TEST FAILED'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4keWn3Jsp-c",
        "outputId": "a17c9a9f-43e8-4b03-ac6f-179cf31c9bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST PASSED\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "12_fgBjIDtOuwdnS4ton6CuDXLhxKX7Za",
      "authorship_tag": "ABX9TyOW/CDZ1Gn4xp3S5UMYd9/y",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}